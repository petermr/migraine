<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="review-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Physiol</journal-id><journal-id journal-id-type="iso-abbrev">Front Physiol</journal-id><journal-id journal-id-type="publisher-id">Front. Physiol.</journal-id><journal-title-group><journal-title>Frontiers in Physiology</journal-title></journal-title-group><issn pub-type="epub">1664-042X</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">5972278</article-id><article-id pub-id-type="doi">10.3389/fphys.2018.00525</article-id><article-categories><subj-group subj-group-type="heading"><subject>Physiology</subject><subj-group><subject>Review</subject></subj-group></subj-group></article-categories><title-group><article-title>Different Types of Sounds and Their Relationship With the Electrocardiographic Signals and the Cardiovascular System &#x02013; Review</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Idrobo-&#x000c1;vila</surname><given-names>Ennio H.</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="corresp" rid="c001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/473619/overview"/></contrib><contrib contrib-type="author"><name><surname>Loaiza-Correa</surname><given-names>Humberto</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/509534/overview"/></contrib><contrib contrib-type="author"><name><surname>van Noorden</surname><given-names>Leon</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/58461/overview"/></contrib><contrib contrib-type="author"><name><surname>Mu&#x000f1;oz-Bola&#x000f1;os</surname><given-names>Flavio G.</given-names></name><xref ref-type="aff" rid="aff3"><sup>3</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/504067/overview"/></contrib><contrib contrib-type="author"><name><surname>Vargas-Ca&#x000f1;as</surname><given-names>Rubiel</given-names></name><xref ref-type="aff" rid="aff4"><sup>4</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/504619/overview"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Percepci&#x000f3;n y Sistemas Inteligentes, Escuela de Ingenier&#x000ed;a El&#x000e9;ctrica y Electr&#x000f3;nica, Universidad del Valle</institution>, <addr-line>Cali</addr-line>, <country>Colombia</country></aff><aff id="aff2"><sup>2</sup><institution>Institute of Psychoacoustics and Electronic Music for Systematic Musicology, Department of Art, Music and Theatre Sciences, Ghent University</institution>, <addr-line>Ghent</addr-line>, <country>Belgium</country></aff><aff id="aff3"><sup>3</sup><institution>Ciencias Fisiol&#x000f3;gicas Experimentales, Departamento de Ciencias Fisiol&#x000f3;gicas, Universidad del Cauca</institution>, <addr-line>Popay&#x000e1;n</addr-line>, <country>Colombia</country></aff><aff id="aff4"><sup>4</sup><institution>Sistemas Din&#x000e1;micos de Instrumentaci&#x000f3;n y Control, Departamento de F&#x000ed;sica, Universidad del Cauca</institution>, <addr-line>Popay&#x000e1;n</addr-line>, <country>Colombia</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Antonio Colantuoni, University of Naples Federico II, Italy</p></fn><fn fn-type="edited-by"><p>Reviewed by: Dominga Lapi, Universit&#x000e0; degli Studi di Pisa, Italy; Giovanni Messina, University of Foggia, Italy</p></fn><corresp id="c001">*Correspondence: Ennio H. Idrobo-&#x000c1;vila, <email>ennio.idrobo@correounivalle.edu.co</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Vascular Physiology, a section of the journal Frontiers in Physiology</p></fn></author-notes><pub-date pub-type="epub"><day>22</day><month>5</month><year>2018</year></pub-date><pub-date pub-type="collection"><year>2018</year></pub-date><volume>9</volume><elocation-id>525</elocation-id><history><date date-type="received"><day>22</day><month>12</month><year>2017</year></date><date date-type="accepted"><day>24</day><month>4</month><year>2018</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2018 Idrobo-&#x000c1;vila, Loaiza-Correa, van Noorden, Mu&#x000f1;oz-Bola&#x000f1;os and Vargas-Ca&#x000f1;as.</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Idrobo-&#x000c1;vila, Loaiza-Correa, van Noorden, Mu&#x000f1;oz-Bola&#x000f1;os and Vargas-Ca&#x000f1;as</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) and the copyright owner are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p><bold>Background:</bold> For some time now, the effects of sound, noise, and music on the human body have been studied. However, despite research done through time, it is still not completely clear what influence, interaction, and effects sounds have on human body. That is why it is necessary to conduct new research on this topic. Thus, in this paper, a systematic review is undertaken in order to integrate research related to several types of sound, both pleasant and unpleasant, specifically noise and music. In addition, it includes as much research as possible to give stakeholders a more general vision about relevant elements regarding methodologies, study subjects, stimulus, analysis, and experimental designs in general. This study has been conducted in order to make a genuine contribution to this area and to perhaps to raise the quality of future research about sound and its effects over ECG signals.</p><p><bold>Methods:</bold> This review was carried out by independent researchers, through three search equations, in four different databases, including: engineering, medicine, and psychology. Inclusion and exclusion criteria were applied and studies published between 1999 and 2017 were considered. The selected documents were read and analyzed independently by each group of researchers and subsequently conclusions were established between all of them.</p><p><bold>Results:</bold> Despite the differences between the outcomes of selected studies, some common factors were found among them. Thus, in noise studies where both BP and HR increased or tended to increase, it was noted that HRV (HF and LF/HF) changes with both sound and noise stimuli, whereas GSR changes with sound and musical stimuli. Furthermore, LF also showed changes with exposure to noise.</p><p><bold>Conclusion:</bold> In many cases, samples displayed a limitation in experimental design, and in diverse studies, there was a lack of a control group. There was a lot of variability in the presented stimuli providing a wide overview of the effects they could produce in humans. In the listening sessions, there were numerous examples of good practice in experimental design, such as the use of headphones and comfortable positions for study subjects, while the listening sessions lasted 20 min in most of the studies.</p></abstract><kwd-group><kwd>sound</kwd><kwd>music</kwd><kwd>noise</kwd><kwd>electrocardiogram</kwd><kwd>electrocardiography</kwd><kwd>signals</kwd></kwd-group><counts><fig-count count="9"/><table-count count="1"/><equation-count count="0"/><ref-count count="75"/><page-count count="18"/><word-count count="0"/></counts></article-meta></front><body><sec><title>Introduction</title><p>Sound is a mechanical vibration which travels through an elastic medium, as a variation in the pressure exerted on the particles which comprise it (<xref rid="B29" ref-type="bibr">Hewitt, 2015</xref>). Sound can be perceived as pleasant or unpleasant, although the boundary that separates music and noise can be very thin and subjective. Most unpleasant sounds are several noise types, and, despite some elements and preferences, pleasant sounds are frequently related to music (<xref rid="B29" ref-type="bibr">Hewitt, 2015</xref>). However, the task of differentiating different types of music from noise becomes a question of esthetics, outside the scope of this document. Normally, noise (e.g., traffic and factory noises) is linked to unpleasant sounds; nonetheless, sometimes it is not directly associated with them (white noise or background noise, i.e., ambient sound; <xref rid="B43" ref-type="bibr">McDermott, 2012</xref>). On the other hand, music is associated with pleasant sounds (frequently music types as classical, relaxing, or sedative) although they are conditioned by preferences and familiarity (<xref rid="B43" ref-type="bibr">McDermott, 2012</xref>) or the listener&#x02019;s cultural association (<xref rid="B44" ref-type="bibr">McDermott et al., 2016</xref>). Regarding sound effects, research has shown sound produces effects on human health, in both physically and psychologically (<xref rid="B13" ref-type="bibr">Cowan, 2016</xref>). However, the effects on human health have not been fully understood and explained, or how sound may contribute to improve human beings quality of life.</p><p>As sound may generate both positive and negative effects on humans (<xref rid="B13" ref-type="bibr">Cowan, 2016</xref>), it may also contribute to the treatment of some diseases. It can also be a control instrument in such cases. Therefore, it is worth studying the relationship and effects of sound on human health (<xref rid="B36" ref-type="bibr">Koelsch and Jancke, 2015</xref>) and to address this topic in order to understand whether those effects are related to pleasant and unpleasant sounds (<xref rid="B43" ref-type="bibr">McDermott, 2012</xref>), or if they respond to specific structures of the sound. In general, previous work has shown that negative effects could be related to exposure to unpleasant sounds, such as noise (<xref rid="B4" ref-type="bibr">Basner et al., 2013</xref>), whereas in many cases, the positive effects could be related to interaction or to listening to pleasant sounds, such as music (<xref rid="B66" ref-type="bibr">Trappe, 2012</xref>; <xref rid="B45" ref-type="bibr">Mofredj et al., 2016</xref>).</p><p>Understanding these relationships may make it possible to achieve benefits in several areas. Thus, in health, it may be possible to prevent or reduce harmful effects which may be produced by exposure to harmful noises. Additionally, it may be possible to improve the use of music therapy in several physiological and psychological conditions such as hypertension, cardiovascular disease (<xref rid="B72" ref-type="bibr">Watkins, 1997</xref>), migraine, headaches, gastrointestinal ulcers, autism, dementia, depression, pain and stress management, and mental disorders (<xref rid="B47" ref-type="bibr">Mont&#x000e1;nchez Torres et al., 2016</xref>). Another important element of considerable interest currently is the relationship between the brain and the heart. Sound and music research may provide relevant tools to contribute to this topic, since music is a stimulus which can affect the whole brain and promotes interaction between its hemispheres. Improvements in health also have economic benefits, specifically in the health sector, since it is probable that application of sounds and music may able to reduce consumption of some medicines. Similarly, in the IT sector, topics related to emotions and relationships between people and machines may be improved where music could be a way to study them. Also, understanding the relationship between sound and humans and knowing the mechanisms related to how sound affects the human body could improve and promote new applications in emergent technologies, such as the Internet of things and virtual reality.</p><p>Some types of sound, such as noise, can also produce harmful effects whereas other types of sound, particularly music, can contribute to improving physiological and psychological health. However, it is not completely clear yet what the effects or the mechanisms of musical sounds are on the human body. Thus, it has been observed that exposure to noise increases BP and HR (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>), whereas music evokes emotions and has effects on mood, memory, stress levels, and anxiety. The effects of noise have also been seen on several of the body&#x02019;s systems, such as nervous, cardiovascular, respiratory, and endocrine, where it can influence physiological variables, such as respiration, HR, BP, and many more (<xref rid="B36" ref-type="bibr">Koelsch and Jancke, 2015</xref>).</p><p>Since the early 20th century, the effects produced by sounds, such as music, have been registered using measurement equipment (<xref rid="B31" ref-type="bibr">Hyde, 1924</xref>). Current technology can now be used to register the effects produced by different sound stimulus in more detail to move toward a clearer understanding of how the human body is affected by them. Considering the positive and negative effects of sounds on human health, it is important to carry out new research to reduce the negative effects and understand the ways in which we can take advantage of the positive effects.</p><p>Nevertheless, previous research has gaps which need to be addressed. One of the most important is related to the size of the sample. In many cases, the sample is very small and the conclusions do not allow us to make generalizations. However, as in much medical research, this problem has a complex solution. It is difficult to find a sample with all the necessary elements under control and wide homogeneity, such as, age, current diseases, gender, education level, conditions, and lifestyle.</p><p>Other difficulties are related to experimental design, specifically the control group. A lot of research has used a control group in silence, but in these situations, the effects obtained in all groups could be not compared since the control group does not have an auditory stimulus (<xref rid="B36" ref-type="bibr">Koelsch and Jancke, 2015</xref>). On the other hand, most of the previous reviews related to this topic have included very few studies, so it is difficult to have a wide view their common and uncommon results, and a general vision of their advances and gaps.</p><p>Focusing on this review, sound can be classified in different ways according to its characteristics. However, for this paper, it is important to differentiate between sounds that are pleasing to the ear, including music, and noise. In general, although music and noise are mixtures of different frequencies, pleasant sounds and music can be distinguished from noise. In the case of music, there is a certain order, its frequencies are discrete (separable) and rational (their relationships from simple fractions) with a discernible dominant frequency. This can be described mathematically by an infinite sum of sines and cosines multiplied by appropriate coefficients. On the other hand, noise has no set order. Its frequencies are continuous (each frequency will be present in some range) and random (described by a probability distribution) with no discernible dominant frequency.</p><p>In this paper, a systematic review is conducted in order to integrate research related to several sound types both pleasant and unpleasant, specifically noise and music. In this review, infrasound and ultrasound were not considered. Moreover, this paper seeks to include as much research as possible to create a more general vision about relevant elements regarding methodologies, study subjects, stimulus, analysis, and experimental designs in general. By doing so, it will be possible to find common elements and gaps in research between studies; common responses between different stimulus. Therefore, this review explores sound as a general element of particular aspects like noise and music types and their effects on physiological and psychological variables.</p><p>This approach differs from previous ones because here the stimuli are considered as a sound or auditory entity. In other studies, the effects of particular stimuli, such as noise or music, are only included. However, it is important to have a wide panorama in which it is possible to find common and different aspects among the outcomes and applied stimulus. Hence, this approach could contribute to the development of methodologies of future research related to the effects of sound on the human body.</p><sec><title>Rationale</title><p>Nowadays, there has been an increase in research to understand the influence of sound, noise, and music on the human body, and in this case, electrocardiographic signals on the cardiovascular system. There is also a trend to study interaction between humans and the machine, where understanding, processing, and classifying emotions play an important role. In this case, music is a relevant tool because it can evoke emotions and memories through auditory memory. Thus, it is necessary to understand how music influences human physiology and psychology.</p></sec><sec><title>Objectives</title><p>The aim in this review is to understand previous research in this topic, in such a way that the main findings will be highlighted and research gaps and important issues will also be found to be considered in new studies related to this topic.</p></sec><sec><title>Research Questions</title><p>This review intends to answer the questions below:</p><list list-type="simple" prefix-word="simple"><list-item><label>1.</label><p>How sound, noise, and music influence electrocardiographic signals and the cardiovascular system?</p></list-item></list><p>Four secondary questions were formulated related to the sample, the sound types, the listening sessions, and the tools for analysis:</p><list list-type="simple" prefix-word="simple"><list-item><label>1.</label><p>Which characteristics related to gender, age, health condition, and size have the samples considered in the selected studies?</p></list-item><list-item><label>2.</label><p>What types of sounds have been used most frequently?</p></list-item><list-item><label>3.</label><p>What characteristics do the listening sessions have in the selected studies?</p></list-item><list-item><label>4.</label><p>What mathematical, processing, and analysis tools have been used to analyze the results?</p></list-item></list></sec></sec><sec sec-type="materials|methods" id="s1"><title>Materials and Methods</title><p>This section describes the review methodology. Thus, details of participants, interventions, and comparators are shown. In addition, it explains the review protocol, search strategy and register, and inclusion and exclusion criteria. It also lists the data sources, studies&#x02019; sections, and data extraction.</p><sec><title>Participants, Interventions, and Comparators</title><p>The search, assessment, and selection of documents were performed independently by four research groups from different universities. In this case, researchers belonging to IPEM Institute for Systematic Musicology, Ghent University, SIDICO and SIFIEX &#x02013; Universidad del Cauca, and PSI &#x02013; Universidad del Valle participated in this review. Within each group, there were one or more researchers who participated in search, selection, evaluation, or analysis of documents independently. At the end of the review, a comparison was made between results obtained by each one of the researchers. Decisions were made about non-concordant results (such as inclusion and exclusion criteria and paper selection) between the research groups. The information was then extracted and synthesized to respond to the formulated research questions. Finally, the results, analysis, and conclusions were organized in a document for the drafting of this article.</p></sec><sec><title>Systematic Review Protocol</title><p>The systematic review in this paper followed some sequential steps so that they can be reproduced in further research. First, searches about the topic were made in different databases and carried out following the same procedures to establish the same search conditions. Thus, the same filters and inclusion&#x02013;exclusion criteria were used. Second, classification by categories of searched documents was made to find an answer to the research question raised. At this point, a reading of these documents was done and those which did not satisfy all inclusion criteria were discarded. Next, the documents collected by each group of researchers were collected together in a unique database and duplicates were removed. Finally, the selected documents were read and analyzed independently by each group of researchers and subsequently conclusions were established between them. In this way, the proposed review protocol allows carrying out a more complete search with less risk of bias and which can be reproduced in several contexts.</p></sec><sec><title>Search Strategy</title><p>The search strategy was made through an initial selection of keywords and construction of three different search equations. In order to search the documents, the following keywords were used: ECG, EKG, electrocardiogram, electrocardiography, electrocardiograph, sound, noise, and music. With keywords, they were constructed three search equations, which are referenced as SE1, SE2, and SE3:</p><list list-type="simple" prefix-word="simple"><list-item><label>SE1.</label><p>TITLE-ABS-KEY [sound<sup>&#x02217;</sup> AND (electrocardiogra<sup>&#x02217;</sup> OR ecg OR ekg)]</p></list-item><list-item><label>SE2.</label><p>TITLE-ABS-KEY [music<sup>&#x02217;</sup> AND (electrocardiogra<sup>&#x02217;</sup> OR ecg OR ekg)]</p></list-item><list-item><label>SE3.</label><p>TITLE-ABS-KEY [nois<sup>&#x02217;</sup> AND (electrocardiogra<sup>&#x02217;</sup> OR ecg OR ekg)].</p></list-item></list><p>In these cases, an asterisk (<sup>&#x02217;</sup>) was used as a wildcard element; for instance, &#x0201c;electrocardiogra<sup>&#x02217;</sup>&#x0201d; includes results relate to electrocardiogram, electrocardiography, or electrocardiograph. Furthermore, logical operators were used, such as AND to restrict and OR to extend the search. This way, with these keywords, logical operators, and search equations, documents were searched using selected databases.</p></sec><sec><title>Search Register</title><p>Search register was made individually in each research group, and in the final stage, an average was taken with the registers. Initially, a unique search in Scopus with first search equation was made and 3457 documents published between 1912 and 2017 were found. In this search, it was noted that the first big peak in publications happened in the 1970s, when there was an increase in research into this topic. However, most of the research into this area was published between 1999 and 2017, with a peak in 2015. This paper focuses on only the most recent studies, between 1999 and 2017. Thus, documents published before 1999 were filtered. The amount of papers per year in Scopus related to sound and music is graphed in <bold>Figure <xref ref-type="fig" rid="F1">1</xref></bold>.</p><fig id="F1" position="float"><label>FIGURE 1</label><caption><p>Amount of papers per year in Scopus and related to sound and music.</p></caption><graphic xlink:href="fphys-09-00525-g001"/></fig></sec><sec><title>Inclusion Criteria</title><p>In this review, the inclusion criteria relate to: document types, language, and year of publication. Stimuli and variables of interest were considered. Thus, document types included were those produced as original and review papers written in English, Spanish, or Portuguese and published between 1999 and 2017. Additionally, the human population according to the exclusion criteria and studies related to the influence of listening to sound on electrocardiographic signals or variables of cardiovascular system were considered uniquely. Moreover, documents relating to HR and HRV were included. There is a particular interest in research with an experimental design which includes sound reproduction. In these types of studies, subjects hear an acoustic or auditory stimulus and their effects on electrocardiographic signals or the cardiovascular system are studied.</p></sec><sec><title>Exclusion Criteria</title><p>As in inclusion criteria, document types, population sample, stimuli, and experimental design were considered. Documents with opinions, points of views, or anecdotes were discarded. In addition, studies with subjects younger than 18 years, children, newborns, and fetuses were discarded. Also, research with study subjects in a state of depression or with pathologies such as dementia, cognitive disability, disorders of consciousness, cerebrovascular disease, and vegetative state were discarded. In the same way, studies in which visual stimuli were presented were discarded. Therefore, research which presented stimuli with video or moving images were discarded. Studies which considered active music therapy where subjects make music in any way were excluded. This way, with these exclusion criteria, researchers excluded research which deviated from the analysis and the conclusions related to the main topic and research question.</p></sec><sec><title>Data Sources, Studies&#x02019; Sections, and Data Extraction</title><p>To answer the proposed questions, a search in several scientific literature databases was made. A search was carried out in databases relating to engineering, medicine, and psychology. Databases like IEEE, PubMed, and Frontiers were consulted. Moreover, Scopus as a general database was consulted. Searching databases from different disciplines allowed us to have different viewpoints and perspectives.</p></sec></sec><sec><title>Results</title><p>After presenting the methods to carry out this review, the obtained results are shown. The selected studies in this review present some characteristics with significant variability. Thus, the observed effects, the most common elements, and some differences between research are presented. First, characteristics of samples used in the selected studies are shown. Then, a section about different stimuli provided in included research is presented. Once the presentation has occurred, the results relating to stimuli show the listening sessions&#x02019; characteristics. After this, mathematical, processing, and analysis tools often used in selected research are revealed. Lastly, the more common measured variables in this review are presented.</p><sec><title>Flow Diagram of the Studies Retrieved for the Review</title><p><bold>Figure <xref ref-type="fig" rid="F2">2</xref></bold> shows the flow diagram of the studies retrieved for the review from the selected databases with a number of documents.</p><fig id="F2" position="float"><label>FIGURE 2</label><caption><p>Flow diagram of the studies retrieved for the review.</p></caption><graphic xlink:href="fphys-09-00525-g002"/></fig></sec><sec><title>Effects of Stimuli</title><p>Selected research in this review has provided some effects with slight trends between them. Changes observed in measured variables as a result of presented stimuli are shown in <bold>Figure <xref ref-type="fig" rid="F3">3</xref></bold>. In this case, general and significant changes in some variables as a product of exposure to stimuli are noted. However, most of these changes did not present a trend in most cases, with the exception of noise studies where both BP (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>) and HR (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>) increase or tended to increase. Additionally, an increased risk of myocardial infarction (MI) was noted as levels of noise intensity increased (<xref rid="B3" ref-type="bibr">Babisch et al., 1993</xref>).</p><fig id="F3" position="float"><label>FIGURE 3</label><caption><p>Changes observed in measured variables as a result of presented stimuli. HRV, heart rate variability; GSR, galvanic skin response; LF, low-frequency power &#x02013; HRV; HF, high-frequency power &#x02013; HRV; HR, heart rate; BP, blood pressure; ECG, electrocardiography &#x02013; electrocardiogram; EMG, electromyography &#x02013; electromyogram.</p></caption><graphic xlink:href="fphys-09-00525-g003"/></fig><p>Another element to note is related to changes in common variables between different stimuli. HRV (HF and LF/HF) changes with both sound (<xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>) and noise (<xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>) stimuli, whereas GSR changes with sound (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>) and musical (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>) stimuli. Moreover, LF also showed changes with exposure to noise (<xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>). Here, it is important to note that both sound and musical stimuli can affect memory and emotions. Perhaps they are related to GSR and HRV, particularly HF, which has been linked with the parasympathetic nervous system, whereas noise can affect both stress and anxiety levels; they are possibly related with BP and HR.</p></sec><sec><title>Sample Characteristics</title><p>In this review, the selected research presents a great diversity of samples. Most frequently characteristics in used samples are shown in <bold>Figure <xref ref-type="fig" rid="F4">4</xref></bold>. It is possible to see that most selected studies used a sample with healthy subjects (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B10" ref-type="bibr">Chen et al., 2014b</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>; <xref rid="B23" ref-type="bibr">Goshvarpour et al., 2017</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>). Samples are also used with a combination of males and females (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>; <xref rid="B23" ref-type="bibr">Goshvarpour et al., 2017</xref>). There were few studies with just males (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>) or just females (<xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>). With respect to the sample size, many of the studies used a size between 20 and 33 (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>) or 35 and 88 (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>) subjects. There were few studies with a sample larger than 100 subjects (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>). Similarly, most of the research considered subjects between 18 and 41 (<xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>), and a few studies used subjects older than 42 (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>) as part of the sample.</p><fig id="F4" position="float"><label>FIGURE 4</label><caption><p>Most frequently characteristics in used samples.</p></caption><graphic xlink:href="fphys-09-00525-g004"/></fig></sec><sec><title>Type of Sounds, Noise, and Music</title><p>As well as sample characteristics, the studies considered have different types of sound stimuli. Thus, most used stimuli in selected research according to categories of sound (S), noise (N), and music (M) are shown in <bold>Figure <xref ref-type="fig" rid="F5">5</xref></bold>. There, it is noted that both pleasant (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>) and unpleasant (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>) sound were the most used stimuli in sound research; traffic (<xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>), white (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>), factory (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>), background (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B10" ref-type="bibr">Chen et al., 2014b</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>), and low-frequency (<xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>) noises were used with more frequency in noise studies, whereas classical (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>) and relaxing or sedative music (<xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>) were most used in music research. It is important to observe that classical music was the most used stimulus. Some studies considered music selected by study subject, and in many cases, specifications about the music used were not given.</p><fig id="F5" position="float"><label>FIGURE 5</label><caption><p>Most used stimulus in selected research according to categories of sound (S), noise (N), and music (M).</p></caption><graphic xlink:href="fphys-09-00525-g005"/></fig></sec><sec><title>Listening Session Characteristics</title><p>In the same way as stimuli and sample, the listening sessions present a wide diversity due to the nature of the research. Most frequently characteristics in the listening sessions are shown in <bold>Figure <xref ref-type="fig" rid="F6">6</xref></bold>. In most of the cases, it is not considered a control group (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>), just few studies had a control group (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>). In much of the research, stimuli were presented through headphones (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>). It is interesting to note that some studies asked subjects to close their eyes (<xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>) to concentrate on presented stimulus. A seated position was also used (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>) more frequently with respect to a supine position (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>). Moreover, in some cases, some environmental elements were controlled (<xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B22" ref-type="bibr">Goshvarpour et al., 2016b</xref>). Another element to note is related to the length of the listening sessions. Many studies had a listening time between 15 and 30 min (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B16" ref-type="bibr">Das et al., 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>). Others lasted between 2 and 15 min (<xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>). Only a few listenings lasted between 30 and 60 min (<xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>), or more than 60 min (<xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>).</p><fig id="F6" position="float"><label>FIGURE 6</label><caption><p>Most frequently characteristics in the listening sessions.</p></caption><graphic xlink:href="fphys-09-00525-g006"/></fig></sec><sec><title>Mathematical, Processing, and Analysis Tools</title><p>In the selected studies for this review, diverse mathematical, processing, and analysis tools were used. The most frequently used analysis tools in the selected studies are shown in <bold>Figure <xref ref-type="fig" rid="F7">7</xref></bold>. There, common statistical tools are observed as mean (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>) and SD (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>), which are used frequently; moreover, the most frequent used elements are considered to compare between groups, such as ANOVA (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>) and <italic>t</italic>-test (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>). Tools with less frequently used, such as Mann&#x02013;Whitney <italic>U</italic>-test (<xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B10" ref-type="bibr">Chen et al., 2014b</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>), Chi-square test (<xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>), linear regression (<xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>), and classification elements as k-nearest neighbors (kNN; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>) and multilayer perceptron (MLP; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>).</p><fig id="F7" position="float"><label>FIGURE 7</label><caption><p>Analysis tools used with most frequency in the selected researches.</p></caption><graphic xlink:href="fphys-09-00525-g007"/></fig></sec><sec><title>Measured Variables</title><p>In this review, studies were selected which researched the effects of music on several physiological variables, especially those related to the cardiovascular system, and psychological variables. The most used physiological and psychological variables in selected researches are shown in <bold>Figure <xref ref-type="fig" rid="F8">8</xref></bold>. According to search criteria, it is noted that most studies measured the ECG signal (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>) In the same way, in many cases, the variables derived from ECG as HR (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>, <xref rid="B23" ref-type="bibr">2017</xref>) and HRV were selected (<xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>). In addition, other physiological variables, such as BP (<xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>) and respiration (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>), were contemplated, as well as GSR (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>), audiometry (<xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>), and EMG (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>) with less frequency. On the other hand, the most used psychological variables were valence and arousal (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>). Here it is important to note how psychological variables were measured with less frequency than physiological variables. Thus, it is important to consider the psychological elements in future research.</p><fig id="F8" position="float"><label>FIGURE 8</label><caption><p>Most used physiological and psychological variables in the selected researches. ECG, electrocardiography &#x02013; electrocardiogram; HRV, heart rate variability; HR, heart rate; BP, blood pressure; GSR, galvanic skin response; EMG, electromyography &#x02013; electromyogram.</p></caption><graphic xlink:href="fphys-09-00525-g008"/></fig></sec></sec><sec><title>Discussion</title><sec><title>Summary of Main Findings</title><p>In this section, the main findings according to physiological and psychological responses and its stimuli are presented. It is important to observe that the psychological elements are used in a reduced way respect to physiological variables.</p></sec><sec><title>Sample Characteristics</title><p>In studies related to sound, most of them considered normal or healthy subjects (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>); with respect to the sample size, most studies had a sample between 10 and 27 subjects (<xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>) and others between 30 and 52 subjects (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>). Most research considered a sample with a mix of males and females (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>), and the subjects aged between 18 and 35 (<xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>). Here, most of the studies did not have a control group (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>).</p><p>In research related to noise, most considered normal or healthy subjects (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>), and others with hypertension (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>). The sample size varied widely among the studies. There were studies with samples between 10 and 25 subjects (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>), between 36 and 88 subjects (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>), and between 100 and 396 subjects (<xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>). Most of the studies used a mix of males and females (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>) and other studies considered only males (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>). The age variable in the sample was wide, with subjects from 18 to 46 years (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>), and studies with subjects with broader age ranges, between 18 and 62 years (<xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>), 19 and 50 years (<xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>), 17 and 41 years (<xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>), and 34 and 74 years (<xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>). In these studies, some had a control group (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>) but most did not (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>).</p><p>In research related to music, most studies used a sample with normal or healthy subjects (<xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>; <xref rid="B23" ref-type="bibr">Goshvarpour et al., 2017</xref>). Moreover, some studies considered subjects with several health conditions (<xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>). It is important to note that some studies did not provide a subject specification (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>). With respect to sample size, it was noted that the sample size varies between 3 and 18 subjects (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B16" ref-type="bibr">Das et al., 2015</xref>; <xref rid="B22" ref-type="bibr">Goshvarpour et al., 2016b</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>), 20 and 28 subjects (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>), 30 and 44 subjects (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>, <xref rid="B23" ref-type="bibr">2017</xref>), and 60 and 125 subjects (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>). Moreover, most research has had a sample with age ranges between 18 and 41 years (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B16" ref-type="bibr">Das et al., 2015</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>), and other studies had a broader age range, 31&#x02013;74 years (<xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>), 18&#x02013;65 years (<xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>), and 20&#x02013;57 years (<xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>). Many studies also considered a sample with males and females (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>), and others with just males (<xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>) or females (<xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>). In these cases, most research did not have a control group (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B16" ref-type="bibr">Das et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>) and only a few considered a control group (<xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>).</p><p>Most studies considered samples with healthy subjects. Therefore, it is interesting to determine whether healthy subjects respond to sound stimuli in different ways to people with health problems and to investigate how health issues can interfere with reactions to sound stimuli. A lack of control group was also noted in most research, probably due to samples with few subjects which could obstruct both data analysis and conclusion extraction related to stimuli effects. Another point to note is that a lot of research had a sample made up of males and females. Therefore, it will be interesting to establish if males and females are affected by sound stimuli in different ways. If that is the case, it should be taken into account in future research. In studies related with music, it is noted in some studies that there was a sample with a wide age range. In such cases, we can consider how the musical perception, appreciation, and hence the registered effects of different people might be affected by their generations&#x02019; tastes (<xref rid="B74" ref-type="bibr">Yang and Kang, 2005</xref>). Thus, sample is an important restriction in experimental design for researches in the health area. A sample could present limitations both in its size as in its characteristics, as age and gender, among others.</p></sec><sec><title>Types of Sounds, Noise, and Music</title><p>In studies with sounds, it has been observed that most studies used pleasant (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>) and unpleasant sounds (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>), as well as white noise (<xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>); however, other sounds, such as neutral (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>), pure tone (<xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>), daily life sounds (<xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>), wasp buzzing (<xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>), engine sound (<xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>), drum sound (<xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>), Tibetan singing bowls (<xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>), and some types of music, such as classical and house music, have been applied (<xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>). In studies with noise, most studies took into account traffic noise (<xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>), background noise (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B10" ref-type="bibr">Chen et al., 2014b</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>), white noise (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>), factory noise (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>), and low-frequency noise (<xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>). Additionally, noises such as impulsive noise (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>), train noise (<xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>), and various noise intensities (<xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>) were applied among others (<xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>). In research related to music, most studies used classical music (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>), relaxing or sedative music (<xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>), emotional music (<xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>), pleasant music (<xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>), and unpleasant music (<xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>); also, new age music and Persian music were taken into account (<xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>), among other kinds of music or stimulus (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B16" ref-type="bibr">Das et al., 2015</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>). It is important to note that many studies used music selected by study subjects (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>), and other studies did not give enough information about the music used (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>).</p><p>In studies related to sound and noise, it was noted that there was a considerable variety in the stimuli. In these cases, the use of daily life sounds and noises is highlighted since it is possible be aware of their positive or negative consequences on humans. Regarding research carried out with music, it is important to note how several types of music have been used, including music selected by study subjects. It is worth mentioning that in studies with little information about the music used, it is hard to associate it with the registered effects. At this point, this paper encourages future research to promote the use of artificial and electronic music, where possible to control its components efficiently. That way, conclusions regarding the produced effects could provide more information and increase confidence levels. Hence, stimuli used in the selected studies present a great variety stimulus providing a general vision about its effects on the study subjects.</p></sec><sec><title>Listening Session Characteristics</title><p>In studies associated with sound, most of them used headphones (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>), in other studies, subjects were seated (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>), and some research controlled some environmental elements (<xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>). Moreover, listening sessions lasted between 20 and 60 min (<xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>).</p><p>In studies with noise, most used headphones (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>) and others used loudspeakers (<xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>). In some studies, subjects were seated (<xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>). Many studies had a control for environmental elements (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>). With respect to the length of the listening sessions, most of researches had a period between 20 and 100 min (<xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>).</p><p>In studies related to music, most of them used headphones (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>). Here, it is important to note that some studies did not provide information about stimulus presentation (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B16" ref-type="bibr">Das et al., 2015</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>). With respect to the stimulus volume, in some cases, the amplifier volume was controlled by the subject (<xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B22" ref-type="bibr">Goshvarpour et al., 2016b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>) whereas in other cases, it was fixed or controlled by the research members (<xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>). With regard to the subjects&#x02019; position, in many cases, subjects were in supine position (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>) but in other cases were seated (<xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>). One element to note is that, in many studies, subjects had their eyes closed (<xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>). Also, some studies controlled the environmental elements (<xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>). In many cases, the listening period was between 3 and 13 min (<xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>), and also, in other cases, this period was longer, between 20 and 60 min (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B16" ref-type="bibr">Das et al., 2015</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>).</p><p>In this section, it was noted that most studies used headphones to present stimuli. This is a good method since headphones reduced the perception of external stimuli which could negatively affect research outcomes. Additionally, through the use of headphones, the stimuli are presented in a more intimate way. With respect to the position of study subjects, it is critical that their position allows them to concentrate or focus in the listening of the stimuli comfortably. Thus, the seated position and the supine position used in many music studies are ideal. So, where possible it is also important to control environmental elements in the experiment room in such a way that it does not distract people in the study, as happened in some selected studies. It is important to note that in some studies with music, subjects had their eyes closed, eliminating the effects of visual stimuli. This is a valuable element to replicate in future studies related to sound stimuli. Finally, it is noted that most of the selected studies had a minimum listening time session of 20 min. This is a crucial factor which requires critical assessment and discussion between specialists in the health area to determine the minimum listening session time to guarantee the presence of the effects produced by sound stimuli.</p></sec><sec><title>Mathematical, Processing, and Analysis Tools</title><p>Regarding studies with sound, it was noted that ANOVA (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>) and the Wilcoxon signed-rank test (<xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>) were the most used statistics tools. In studies related to noise, the most used analysis tools were ANOVA (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>), <italic>T</italic>-test (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>), Chi-square test (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>), linear regression (<xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>), Mann&#x02013;Whitney <italic>U</italic>-test (<xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B10" ref-type="bibr">Chen et al., 2014b</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>), and common statistical elements, such as mean (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>) and SD (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>). In research related to music, several statistical tools were taken into account, among them ANOVA (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>), <italic>T</italic>-test (<xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>) and paired <italic>t</italic>-test (<xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>), Shapiro&#x02013;Wilk statistic (<xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>), and common elements in statistics, such as mean (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>) and SD (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>). Moreover, some elements of machine learning and digital signal processing were employed, including kNN (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>), MLP (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>), and support vector machine (<xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>; <xref rid="B23" ref-type="bibr">Goshvarpour et al., 2017</xref>).</p><p>Most of the studies presented in this section used ANOVA to analyze data along with some classic statistical tools such as <italic>T</italic>-test. However, in studies with music, other analysis elements, such as machine learning and digital signal processing, were used. This trend in the use of analysis tools is in great part due to the fact that many studies in health are developed using classic statistics. This paper encourages the application of new data analysis techniques in future research relating to sound stimuli and its effects, such as machine/statistical learning and data mining.</p></sec><sec><title>Measured Variables</title><p>With regard to measured variables, because this review was focused on ECG signals, most studies considered ECG signals and some derived variables as HR and HRV. Thus, ECG was measured in studies with sound (<xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>), noise (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>), and music (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B16" ref-type="bibr">Das et al., 2015</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>). In the same way, HR was present in research with sound (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>), noise (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>), and music (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>). It also occurred with HRV in research in sound (<xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>), noise (<xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>), and music (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B16" ref-type="bibr">Das et al., 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B23" ref-type="bibr">Goshvarpour et al., 2017</xref>). In these cases, it is can be seen that ECG is the measured variable, which has a broader frequency in most research.</p><p>Respiration was another variable measured in a lot of research. This variable was measured both in studies with noise (<xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>), such as music (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>). Although, respiration was observed in much research it was not as frequent as ECG or its derived variables.</p><p>In addition to respiration and ECG variables, other elements were considered for measuring or observation. Thus, in studies related to noise, the variables BP (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>) and electrooculography (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>) were used. Moreover, it is important to note that some research used audiometry (<xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>). Additionally, in studies with music, the measured variables, such as GSR (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>), EMG (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>), and BP (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>), were used.</p><p>Most studies took into account the measurement of physiological variables as well as some psychological elements, such as valence and arousal. Thus, valence (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B48" ref-type="bibr">Naji et al., 2014a</xref>,<xref rid="B49" ref-type="bibr">b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>) and arousal (<xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B48" ref-type="bibr">Naji et al., 2014a</xref>,<xref rid="B49" ref-type="bibr">b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>) were measured in studies with music. These variables were also measured in studies with sound (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>). In this way, these studies reveal that both valence and arousal represent important variables relating to human psychology.</p><p>In this point, it is important to note that many studies where HRV was considered used some elements relating to digital signal processing, due to the natural analysis of this signal. Thus, in many cases elements such as Fourier or wavelet transform, power spectrum, linear, and frequency analysis are used. Finally, with respect to ECG acquisition, in most cases where the ECG signal was used, it was acquired from a device with three electrodes (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref>).</p></sec><sec><title>Physiological Variables</title><p>In studies related to sound, it is noteworthy that there are just a small number of studies, but they vary significantly. In these cases, they considered different sound stimuli and produced responses which differ from each other. As a result, it is a difficult task to find both common outcomes and relationships between effects and observed variables. However, some common elements related to HRV were observed. Thus, it should be emphasized that both HF (<xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>) and LF/HF ratio (<xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref>) were shown as indicators for different stimuli. In addition, it was noted that GSR (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>) represents an element which presents variation against diverse sound stimuli. Here, a lack of clarity regarding influence of auditory stimuli on HR is noted. Hence, in studies relating to sound, it is evidenced that both HRV and GSR present variations influenced by sound stimuli, but HR is an element on which further research is worth being carried out.</p><p>From studies reviewed on the influence of noise, the results found do not establish a trend. Nevertheless, in this case, there are some repetitive elements between some studies. Thus, it can be seen that BP (SBP or DBP) increases or tends to increase (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>). This behavior is also evident in HR (<xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>). Other elements that have shown changes regarding noise exposure are HF, LF, and LF/HF ratio. Nonetheless, in HF and LF, there is no marked trend between studies. Thus, the LF/HF ratio has shown an increase (<xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>) compared to noise exposure. On the other hand, in HF, there was both an increase (<xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>) and a decrease (<xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>) with exposure to noise. This same behavior is seen in LF, where (<xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>) a decrease is shown (<xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>). Thus, these studies demonstrate that both BP and HR are affected by noise, but outcomes related with HRV elements are not clear. Despite these findings regarding noise and its effects, it is necessary to expand research about the psychophysiological response of the stress produced by noise.</p><p>Regarding research related to music, studies classifying emotions evoked by listening to music show further evidence of a relationship between emotions, music, and some physiological variables. For classification, the physiological variables which were considered with more frequency were ECG signal (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B49" ref-type="bibr">Naji et al., 2014b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>) and GSR (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>), as well as EMG and respiration (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>), in addition to others which were used with a lesser extent. Consequently, these variables are linked very much with emotions in general as well as listening to music.</p><p>In addition to ECG, GSR, EMG, and respiration, it should be noted that the studies observed do not allow us to establish accurately if music is an influence on HR or HRV. Therefore, it was noted that HR presented an increase (<xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>) and also a reduction (<xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>) in different research. In this case, it is difficult to draw a conclusion on this point since stimuli between the studies had different characteristics. This is therefore another element to be developed in future research.</p><p>Besides ECG (the most frequently acquired signal), there were other registers, such as respiration and BP. Therefore, it is important to consider ECG signals and other variables related directly with the cardiovascular system, as well as others which are not, such as GSR. All registers may support or to contribute to findings in the variable of interest. Thus, with more registers covering the entire cardiovascular system, there will be a greater possibility of finding a relationship between cause and effect in a particular variable, such as ECG in this particular case.</p></sec><sec><title>Psychological Variables</title><p>As well as physiological variables, it is important to know how psychological variables are affected by auditory stimuli. In this review, it was noted that valence and arousal were the psychological variables used the most to model emotional states evoked by sounds and music. However, they were not considered in studies with noise. In addition to these variables, other elements such as personality and anxiety were considered to a lesser extent. Thus, although psychological elements have an important role in auditory perception, they had been not included in research in a rigorous way.</p><p>Valence or arousal dimensions were used to classify emotions (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B48" ref-type="bibr">Naji et al., 2014a</xref>,<xref rid="B49" ref-type="bibr">b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>). Some studies showed which emotion differentiation was easier in arousal than valence dimension (<xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>). Another aspect to note was that pain perception can be affected by musical tempo through the arousal of the listener. Pain ratings were highest for fastest tempos (<xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>). Thus, emotions may be represented throughout valence and arousal. Moreover, music tempo might influence the perception of pain.</p><p>With respect to personality, emotions, and physiological response to auditory stimuli (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>), it was observed that the personality trait anxiety had an influence in response to affective stimuli, whereas in (<xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>) interaction of affective valence, sounds with cardiac response were observed. In the same way, in this case (<xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>), a correlation between emotional personality and ECG amplitude was found. In addition to ECG (<xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>), EEG signals were registered where both ECG and EEG changed emotional valence from negative to positive after listening to Quranic recitation. However, relaxing music changed arousal state and valence in EEG in a positive way, whereas relaxing music produced a negative change in the ECG signal. As a result, these studies show an influence of auditory stimuli on cardiac function, where in some cases, an ECG signal was registered throughout. Elements, such as emotions and personality, may also affect the ECG signal. In this sense, there could be evidence of a relationship between the brain and the heart.</p><p>Finally, it is important to note that (<xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>) the arousal change was related to GSR and EMG, whereas valence was linked to ECG and respiration. On the other hand, in <xref rid="B38" ref-type="bibr">Krabs et al. (2015)</xref>, it was found that the emotional valence of music affects ANS activity. In these cases, it is noted how valence and arousal may affect the physiological variables related to the cardiovascular system in different ways.</p><p>It is pertinent to highlight that both valence and arousal were the most registered psychological variables in the selected studies. However, it is necessary to extend research focused on other aspects, such as anxiety and personality. Research with personality as an observed variable is probably less common, due to the complexity of its evaluation and conclusions over obtained results (<xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>). Moreover, there is a lot of debate around this topic and it can add complexity to the studies that may arise. In this sense, anxiety could be also a useful element to consider in future research.</p></sec><sec><title>Scientific Disciplines for Documents Sourced in This Paper</title><p>In this review, studies from different scientific fields were included. The research chosen is associated with areas such as music therapy, work hygiene, music&#x02019;s influence on the heart&#x02019;s parameters, and affective sounds. The scientific disciplines from which these studies are selected are shown in <bold>Table <xref ref-type="table" rid="T1">1</xref></bold>. This paper has shown that the effects of sound on humans have been studied from diverse viewpoints, ranging from music therapy to work hygiene. However, the latter has been considered with more frequency. In the same way, <bold>Figure <xref ref-type="fig" rid="F9">9</xref></bold> summarizes how the effects of sound, noise, and music on the human body may be studied from different aspects. These factors may impact both the mind and emotions as much as the body. This may be observed both psychologically and as a medical response. Hence, sound may be used to produce different outcomes in areas from music therapy and arts to work hygiene.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p>Scientific disciplines for documents sourced in this paper.</p></caption><table frame="hsides" rules="groups" cellspacing="5" cellpadding="5"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1">Scientific domain</th><th valign="top" align="left" rowspan="1" colspan="1">Documents</th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Music therapy</td><td valign="top" align="left" rowspan="1" colspan="1"><xref rid="B72" ref-type="bibr">Watkins, 1997</xref>; <xref rid="B6" ref-type="bibr">Binns-Turner et al., 2011</xref>; <xref rid="B17" ref-type="bibr">Dousty et al., 2011</xref>; <xref rid="B57" ref-type="bibr">P&#x000e9;rez-Lloret et al., 2014</xref>; <xref rid="B59" ref-type="bibr">Rhomberg et al., 2014</xref>; <xref rid="B26" ref-type="bibr">Gruhlke et al., 2015</xref>; <xref rid="B27" ref-type="bibr">Gupta and Gupta, 2015</xref>; <xref rid="B38" ref-type="bibr">Krabs et al., 2015</xref>; <xref rid="B63" ref-type="bibr">Tan et al., 2015</xref>; <xref rid="B5" ref-type="bibr">Bidin et al., 2016</xref>; <xref rid="B47" ref-type="bibr">Mont&#x000e1;nchez Torres et al., 2016</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Work hygiene</td><td valign="top" align="left" rowspan="1" colspan="1"><xref rid="B65" ref-type="bibr">Tomei et al., 2000</xref>; <xref rid="B75" ref-type="bibr">Yuan et al., 2005</xref>; <xref rid="B68" ref-type="bibr">Ucl&#x000e9;s et al., 2006</xref>; <xref rid="B7" ref-type="bibr">Bj&#x000f6;r et al., 2007</xref>; <xref rid="B58" ref-type="bibr">Raggam et al., 2007</xref>; <xref rid="B25" ref-type="bibr">Graham et al., 2009</xref>; <xref rid="B24" ref-type="bibr">Goyal et al., 2010</xref>; <xref rid="B33" ref-type="bibr">Kasprzak, 2010</xref>; <xref rid="B61" ref-type="bibr">Sancini et al., 2012</xref>; <xref rid="B14" ref-type="bibr">Croy et al., 2013</xref>; <xref rid="B40" ref-type="bibr">Kraus et al., 2013</xref>; <xref rid="B9" ref-type="bibr">Chen et al., 2014a</xref>,<xref rid="B10" ref-type="bibr">b</xref>; <xref rid="B56" ref-type="bibr">Osiris et al., 2014</xref>; <xref rid="B54" ref-type="bibr">Oh et al., 2015</xref>; <xref rid="B20" ref-type="bibr">Gallasch et al., 2016</xref>; <xref rid="B50" ref-type="bibr">Nakajima et al., 2016</xref>; <xref rid="B70" ref-type="bibr">Walker et al., 2016</xref>; <xref rid="B18" ref-type="bibr">El Aarbaoui et al., 2017</xref>; <xref rid="B32" ref-type="bibr">Ishimitsu et al., 2017</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Music influence on heart parameters</td><td valign="top" align="left" rowspan="1" colspan="1"><xref rid="B31" ref-type="bibr">Hyde, 1924</xref>; <xref rid="B30" ref-type="bibr">Holand et al., 1999</xref>; <xref rid="B8" ref-type="bibr">Chang et al., 2004</xref>; <xref rid="B19" ref-type="bibr">Etzel et al., 2006</xref>; <xref rid="B39" ref-type="bibr">Krantz et al., 2010</xref>; <xref rid="B41" ref-type="bibr">Lee et al., 2010</xref>; <xref rid="B11" ref-type="bibr">Cho et al., 2011</xref>; <xref rid="B16" ref-type="bibr">Das et al., 2015</xref>; <xref rid="B36" ref-type="bibr">Koelsch and Jancke, 2015</xref>; <xref rid="B53" ref-type="bibr">Nozaki et al., 2015</xref>; <xref rid="B62" ref-type="bibr">Sim et al., 2015</xref>; <xref rid="B71" ref-type="bibr">Watanabe et al., 2015</xref>; <xref rid="B1" ref-type="bibr">Abedi et al., 2017</xref></td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Affective sounds</td><td valign="top" align="left" rowspan="1" colspan="1"><xref rid="B64" ref-type="bibr">Thayer and Faith, 2001</xref>; <xref rid="B69" ref-type="bibr">Wagner et al., 2005</xref>; <xref rid="B42" ref-type="bibr">Martin-Soelch et al., 2006</xref>; <xref rid="B34" ref-type="bibr">Kenntner-Mabiala et al., 2007</xref>; <xref rid="B37" ref-type="bibr">Koelsch et al., 2007</xref>; <xref rid="B35" ref-type="bibr">Kim and Andr&#x000e9;, 2008</xref>; <xref rid="B55" ref-type="bibr">Orini et al., 2010</xref>; <xref rid="B73" ref-type="bibr">Wong et al., 2010</xref>; <xref rid="B48" ref-type="bibr">Naji et al., 2014a</xref>,<xref rid="B49" ref-type="bibr">b</xref>; <xref rid="B52" ref-type="bibr">Niu et al., 2014</xref>; <xref rid="B15" ref-type="bibr">da Silva and Backs, 2015</xref>; <xref rid="B28" ref-type="bibr">Hajizadeh et al., 2015</xref>; <xref rid="B51" ref-type="bibr">Nardelli et al., 2015</xref>; <xref rid="B2" ref-type="bibr">Al-Galal et al., 2016</xref>; <xref rid="B21" ref-type="bibr">Goshvarpour et al., 2016a</xref>,<xref rid="B22" ref-type="bibr">b</xref>, <xref rid="B23" ref-type="bibr">2017</xref></td></tr></tbody></table></table-wrap><fig id="F9" position="float"><label>FIGURE 9</label><caption><p>Influence of sound, noise, and music on the human body.</p></caption><graphic xlink:href="fphys-09-00525-g009"/></fig></sec><sec><title>Limitations</title><p>One limitation in this review is related to the number of revisers. We think that in order to carry out the best review on this topic, it is necessary to have a multidisciplinary team with several researchers in each of the areas, such as medicine, cardiology, psychology, music or music therapy, engineering, and statistics. Moreover, it is also considered that this may also introduce the possibility of bias in the selection of papers included in this review.</p></sec></sec><sec><title>Conclusion</title><p>In this review, some relevant characteristics between selected studies were seen. Despite the differences between the outcomes of selected studies, some common elements were found among them. Thus, in noise studies where both BP and HR increased or tended to increase, it was noted that HRV (HF and LF/HF) changes with both sound and noise stimuli, whereas GSR changes with sound and musical stimuli. Furthermore, LF also showed changes with exposure to noise. In many cases, samples represented a limitation in experimental design, where in diverse studies, there was a lack of a control group. Regarding stimuli, there was a great variability in the presented stimuli providing a wide overview of the effects they could produce on humans. In the listening sessions, some elements which represent good practices in experimental designs were observed, such as the use of headphones, comfortable positions for study subjects, and control of environmental elements. Moreover, a minimum length of listening session of 20 min was found in most of the research. However, this variable needs critical review and standardization for future research. The use of classic statistics had a dominant role in most studies. New data analysis tools should also be included. Besides ECG, in some studies, registers for other variables of the cardiovascular system were acquired which may support findings about the interest variables. It is important to mention that selected studies do not provide enough evidence about the influence of sound over ECG signal. In this sense, new research needs to be carried out which allow us to make conclusions about this topic. In this way, this review aims to provide elements which can contribute to improving quality in future research about sound and its effects over ECG signals.</p><p>An important point to consider is the extensive variability in the research characteristics. Thus, there is little homogeneity among the elements, such as stimulus, sample, and experimental design in studies with sound, noise, and music. The variations in these characteristics hinder the possibility to draw a complete conclusion with respect to the relationships between causes and effects. However, despite these variations, it was possible to observe some of the elements which were often present.</p><p>In sound and noise studies, it was noted that HF and HF/LF ratio HRV were elements with variations according to the provided stimuli. In the same way, GSR was an element which presented variations with sound stimulus and served as an element in classifying emotions in research with music.</p><p>This review shows that there is a genuine need to continue with research related to the influence of sound, noise, and music on psychophysiological variables. It is known that noise can affect several aspects in humans, both psychological and physiological. However, studies of this review do not show a common trend. Therefore, it is important to consider future research to observe and understand the response to different types of noises, such as traffic noise.</p><p>In addition, it is important to highlight that future research needs to have a strict experimental design as well as to provide a complete report or publication about its outcomes. Thus, it is essential to bear in mind the suggestion to include stimuli with different characteristics in control groups. It is advisable to avoid control groups in silence or without some stimulus. In this way, it is necessary to understand the human response to stimulus with of a different nature, such as several types of sounds, noise, and music (<xref rid="B36" ref-type="bibr">Koelsch and Jancke, 2015</xref>).</p><p>To complement this review, we suggest reading the review &#x0201c;Music and the heart&#x0201d; by <xref rid="B36" ref-type="bibr">Koelsch and Jancke (2015)</xref>. The authors provide methodological recommendations for future research related to music (although many of them are suitable for research with sound and noise).</p><p>It is important to take into account the Consolidated Standards of Reporting Trials (CONSORT; <xref rid="B12" ref-type="bibr">CONSORT, 2017</xref>) for randomized controlled trial designs, the Transparent Reporting of Evaluations with Non-randomized Designs (TREND; <xref rid="B67" ref-type="bibr">Trend Statement CDC, 2017</xref>) for non-randomized designs, Reporting Guidelines for Music-based Interventions (<xref rid="B60" ref-type="bibr">Robb et al., 2011</xref>) for music-based intervention studies, and Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA; <xref rid="B46" ref-type="bibr">Moher et al., 2009</xref>) for reviews.</p></sec><sec><title>Key Concepts</title><sec><title>Sound</title><p>In general, sound may be defined as a mechanical vibration which travels through an elastic medium, like a variation in the pressure exerted on the particles which comprise it, and can be perceived by the ear or any device with this aim.</p></sec><sec><title>Music</title><p>In the case of music, there is a certain order. The frequencies which compose it are discrete (separable) and rational (their relations form simple fractions) with a discernible dominant frequency. It can also be described mathematically by an infinite sum of sines and cosines multiplied by appropriate coefficients.</p></sec><sec><title>Noise</title><p>On the other hand, noise has no set order, the frequencies which comprise it are continuous (each frequency may be present in some range) and random (described by a probability distribution) with no discernible dominant frequency.</p></sec><sec><title>Electrocardiogram</title><p>Electrocardiogram (ECG or EKG) is one of the main physiological measures for medical diagnosis and can be used to detect a large amount of cardiac abnormalities and pathologies; in addition to diagnosis, ECG is very important for the analysis and monitoring of cardiac function.</p></sec><sec><title>Signals</title><p>A signal is a varying phenomenon that differs with time (though it can vary with another parameter, such as space) and can be measured.</p></sec></sec><sec><title>Author&#x02019;s Note</title><p>This work is part of the Ph.D. dissertation ongoing by the EI-&#x000c1; at Universidad del Valle, Colombia.</p></sec><sec><title>Author Contributions</title><p>RV-C, EI-&#x000c1;, FM-B, LvN, and HL-C supervised the entire process and revised the manuscript. EI-&#x000c1; designed the systematic review, reviewed all the studies, and extracted the information from the eligible documents. FM-B analyzed the data and prepared the figures and tables. EI-&#x000c1;, RV-C, and FM-B wrote the paper. All authors reviewed and approved the manuscript.</p></sec><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><fn-group><fn fn-type="financial-disclosure"><p><bold>Funding.</bold> This work was supported by Colciencias, Universidad del Valle, and Universidad del Cauca, Colombia. Universidad del Cauca paid for the publication of this paper. The funders had no role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></fn></fn-group><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Abedi</surname><given-names>B.</given-names></name><name><surname>Abbasi</surname><given-names>A.</given-names></name><name><surname>Goshvarpour</surname><given-names>A.</given-names></name><name><surname>Khosroshai</surname><given-names>H. T.</given-names></name><name><surname>Javanshir</surname><given-names>E.</given-names></name></person-group> (<year>2017</year>). <article-title>The effect of traditional Persian music on the cardiac functioning of young Iranian women.</article-title>
<volume>69</volume>
<fpage>491</fpage>&#x02013;<lpage>498</lpage>. <pub-id pub-id-type="doi">10.1016/j.ihj.2016.12.016</pub-id>
<?supplied-pmid 28822517?><pub-id pub-id-type="pmid">28822517</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Al-Galal</surname><given-names>S. A. Y.</given-names></name><name><surname>Alshaikhli</surname><given-names>I. F.</given-names></name><name><surname>Rahman</surname><given-names>A. W.</given-names></name></person-group> (<year>2016</year>). <article-title>&#x0201c;Automatic emotion recognition based on EEG and ECG signals while listening to quranic recitation compared with listening to music,&#x0201d; in</article-title> (<publisher-loc>Kuala Lumpur</publisher-loc>: <publisher-name>Institute of Electrical and Electronics Engineers Inc.</publisher-name>) <fpage>269</fpage>&#x02013;<lpage>274</lpage>. <pub-id pub-id-type="doi">10.1109/ICT4M.2016.062</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Babisch</surname><given-names>W.</given-names></name><name><surname>Elwood</surname><given-names>P. C.</given-names></name><name><surname>Ising</surname><given-names>H.</given-names></name><name><surname>Kruppa</surname><given-names>B.</given-names></name></person-group> (<year>1993</year>). <article-title>Traffic noise as a risk factor for myocardial infarction.</article-title>
<volume>88</volume>
<fpage>135</fpage>&#x02013;<lpage>166</lpage>.</mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Basner</surname><given-names>M.</given-names></name><name><surname>Babisch</surname><given-names>W.</given-names></name><name><surname>Davis</surname><given-names>A.</given-names></name><name><surname>Brink</surname><given-names>M.</given-names></name><name><surname>Clark</surname><given-names>C.</given-names></name><name><surname>Janssen</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Auditory and non-auditory effects of noise on health.</article-title>
<volume>383</volume>
<fpage>1325</fpage>&#x02013;<lpage>1332</lpage>. <pub-id pub-id-type="doi">10.1016/S0140-6736(13)61613-X</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bidin</surname><given-names>L.</given-names></name><name><surname>Pigaiani</surname><given-names>L.</given-names></name><name><surname>Casini</surname><given-names>M.</given-names></name><name><surname>Seghini</surname><given-names>P.</given-names></name><name><surname>Cavanna</surname><given-names>L.</given-names></name></person-group> (<year>2016</year>). <article-title>Feasibility of a trial with Tibetan singing bowls, and suggested benefits in metastatic cancer patients. A pilot study in an Italian oncology unit.</article-title>
<volume>8</volume>
<fpage>747</fpage>&#x02013;<lpage>755</lpage>. <pub-id pub-id-type="doi">10.1016/j.eujim.2016.06.003</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Binns-Turner</surname><given-names>P. G.</given-names></name><name><surname>Wilson</surname><given-names>L. L.</given-names></name><name><surname>Pryor</surname><given-names>E. R.</given-names></name><name><surname>Boyd</surname><given-names>G. L.</given-names></name><name><surname>Prickett</surname><given-names>C. A.</given-names></name></person-group> (<year>2011</year>). <article-title>Perioperative music and its effects on anxiety, hemodynamics, and pain in women undergoing mastectomy.</article-title>
<volume>79</volume>
<fpage>S21</fpage>&#x02013;<lpage>S27</lpage>. <?supplied-pmid 22403963?><pub-id pub-id-type="pmid">22403963</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bj&#x000f6;r</surname><given-names>B.</given-names></name><name><surname>Burstr&#x000f6;m</surname><given-names>L.</given-names></name><name><surname>Karlsson</surname><given-names>M.</given-names></name><name><surname>Nilsson</surname><given-names>T.</given-names></name><name><surname>N&#x000e4;slund</surname><given-names>U.</given-names></name><name><surname>Wiklund</surname><given-names>U.</given-names></name></person-group> (<year>2007</year>). <article-title>Acute effects on heart rate variability when exposed to hand transmitted vibration and noise.</article-title>
<volume>81</volume>
<fpage>193</fpage>&#x02013;<lpage>199</lpage>. <pub-id pub-id-type="doi">10.1007/s00420-007-0205-0</pub-id>
<?supplied-pmid 17541625?><pub-id pub-id-type="pmid">17541625</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chang</surname><given-names>S. H.</given-names></name><name><surname>Luo</surname><given-names>C. H.</given-names></name><name><surname>Yeh</surname><given-names>T. L.</given-names></name></person-group> (<year>2004</year>). <article-title>An experimental design for quantification of cardiovascular responses to music stimuli in humans.</article-title>
<volume>28</volume>
<fpage>157</fpage>&#x02013;<lpage>166</lpage>. <pub-id pub-id-type="doi">10.1080/0309190031000111371</pub-id>
<?supplied-pmid 15371006?><pub-id pub-id-type="pmid">15371006</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S.-T.</given-names></name><name><surname>Chou</surname><given-names>C.-Y.</given-names></name><name><surname>Tseng</surname><given-names>L.-H.</given-names></name></person-group> (<year>2014a</year>). <article-title>Recurrence plot analysis of HRV for exposure to low-frequency noise.</article-title>
<fpage>1044</fpage>&#x02013;<lpage>1045</lpage>
<comment>1251&#x02013;1257</comment>
<pub-id pub-id-type="doi">10.4028/www.scientific.net/AMR.1044-1045.1251</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S.-T.</given-names></name><name><surname>Tseng</surname><given-names>L.-H.</given-names></name><name><surname>Lee</surname><given-names>Y.-P. L.</given-names></name><name><surname>Wu</surname><given-names>H.-Z.</given-names></name><name><surname>Chou</surname><given-names>C.-Y.</given-names></name></person-group> (<year>2014b</year>). <article-title>Detrended fluctuation analysis of heart rate variability in noise exposure.</article-title>
<fpage>1044</fpage>&#x02013;<lpage>1045</lpage>, <comment>1129&#x02013;1134</comment>. <pub-id pub-id-type="doi">10.1002/adma.201304658</pub-id>
<?supplied-pmid 24347466?><pub-id pub-id-type="pmid">24347466</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cho</surname><given-names>W.</given-names></name><name><surname>Hwang</surname><given-names>S.-H.</given-names></name><name><surname>Choi</surname><given-names>H. H.</given-names></name></person-group> (<year>2011</year>). <article-title>The relationship between pure-tone noise and human bio-signal response.</article-title>
<volume>12</volume>
<fpage>727</fpage>&#x02013;<lpage>731</lpage>. <pub-id pub-id-type="doi">10.1007/s12541-011-0094-8</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><collab>CONSORT</collab> (<year>2017</year>). <comment>Available at: <ext-link ext-link-type="uri" xlink:href="http://www.consort-statement.org/">http://www.consort-statement.org/</ext-link> [accessed October 9 2017]</comment>.</mixed-citation></ref><ref id="B13"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>J. P.</given-names></name></person-group> (<year>2016</year>). <publisher-loc>Hoboken, NJ</publisher-loc>: <publisher-name>John Wiley &#x00026; Sons</publisher-name>
<pub-id pub-id-type="doi">10.1002/9781118895696</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Croy</surname><given-names>I.</given-names></name><name><surname>Smith</surname><given-names>M. G.</given-names></name><name><surname>Waye</surname><given-names>K. P.</given-names></name></person-group> (<year>2013</year>). <article-title>Effects of train noise and vibration on human heart rate during sleep: an experimental study.</article-title>
<volume>3</volume>:<issue>e002655</issue>. <pub-id pub-id-type="doi">10.1136/bmjopen-2013-002655</pub-id>
<?supplied-pmid 23793667?><pub-id pub-id-type="pmid">23793667</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>da Silva</surname><given-names>S. P.</given-names></name><name><surname>Backs</surname><given-names>R. W.</given-names></name></person-group> (<year>2015</year>). <article-title>Cardiac response during auditory selective attention to tones and affective sounds.</article-title>
<volume>52</volume>
<fpage>1099</fpage>&#x02013;<lpage>1105</lpage>. <pub-id pub-id-type="doi">10.1111/psyp.12432</pub-id>
<?supplied-pmid 25847213?><pub-id pub-id-type="pmid">25847213</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Das</surname><given-names>M.</given-names></name><name><surname>Jana</surname><given-names>T.</given-names></name><name><surname>Dutta</surname><given-names>P.</given-names></name><name><surname>Banerjee</surname><given-names>R.</given-names></name><name><surname>Dey</surname><given-names>A.</given-names></name><name><surname>Bhattacharya</surname><given-names>D. K.</given-names></name><etal/></person-group> (<year>2015</year>). <article-title>&#x0201c;Study the effect of music on HRV signal using 3D Poincare plot in spherical Co-ordinates-A signal processing approach,&#x0201d; in</article-title> (<publisher-loc>Kolkata</publisher-loc>: <publisher-name>Institute of Electrical and Electronics Engineers Inc.</publisher-name>) <fpage>1011</fpage>&#x02013;<lpage>1015</lpage>. <pub-id pub-id-type="doi">10.1109/ICCSP.2015.7322652</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dousty</surname><given-names>M.</given-names></name><name><surname>Daneshvar</surname><given-names>S.</given-names></name><name><surname>Haghjoo</surname><given-names>M.</given-names></name></person-group> (<year>2011</year>). <article-title>The effects of sedative music, arousal music, and silence on electrocardiography signals.</article-title>
<volume>44</volume>
<fpage>396.el</fpage>&#x02013;<lpage>396.e6</lpage>. <pub-id pub-id-type="doi">10.1016/j.jelectrocard.2011.01.005</pub-id>
<?supplied-pmid 21353239?><pub-id pub-id-type="pmid">21353239</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>El Aarbaoui</surname><given-names>T.</given-names></name><name><surname>M&#x000e9;line</surname><given-names>J.</given-names></name><name><surname>Brondeel</surname><given-names>R.</given-names></name><name><surname>Chaix</surname><given-names>B.</given-names></name></person-group> (<year>2017</year>). <article-title>Short-term association between personal exposure to noise and heart rate variability: the RECORD MultiSensor Study.</article-title>
<volume>231</volume>
<fpage>703</fpage>&#x02013;<lpage>711</lpage>. <pub-id pub-id-type="doi">10.1016/j.envpol.2017.08.031</pub-id>
<?supplied-pmid 28850938?><pub-id pub-id-type="pmid">28850938</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Etzel</surname><given-names>J. A.</given-names></name><name><surname>Johnsen</surname><given-names>E. L.</given-names></name><name><surname>Dickerson</surname><given-names>J.</given-names></name><name><surname>Tranel</surname><given-names>D.</given-names></name><name><surname>Adolphs</surname><given-names>R.</given-names></name></person-group> (<year>2006</year>). <article-title>Cardiovascular and respiratory responses during musical mood induction.</article-title>
<volume>61</volume>
<fpage>57</fpage>&#x02013;<lpage>69</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijpsycho.2005.10.025</pub-id>
<?supplied-pmid 16460823?><pub-id pub-id-type="pmid">16460823</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gallasch</surname><given-names>E.</given-names></name><name><surname>Raggam</surname><given-names>R.</given-names></name><name><surname>Cik</surname><given-names>M.</given-names></name><name><surname>Rabensteiner</surname><given-names>J.</given-names></name><name><surname>Lackner</surname><given-names>A.</given-names></name><name><surname>Piber</surname><given-names>B.</given-names></name><etal/></person-group> (<year>2016</year>). <article-title>Road and rail traffic noise induce comparable extra-aural effects as revealed during a short-term memory test.</article-title>
<volume>18</volume>
<fpage>206</fpage>&#x02013;<lpage>213</lpage>. <pub-id pub-id-type="doi">10.4103/1463-1741.189243</pub-id>
<?supplied-pmid 27569408?><pub-id pub-id-type="pmid">27569408</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goshvarpour</surname><given-names>A.</given-names></name><name><surname>Abbasi</surname><given-names>A.</given-names></name><name><surname>Goshvarpour</surname><given-names>A.</given-names></name></person-group> (<year>2016a</year>). <article-title>Evaluating autonomic parameters: the role of sleep duration in emotional responses to music.</article-title>
<volume>11</volume>
<fpage>59</fpage>&#x02013;<lpage>63</lpage>. <?supplied-pmid 27252770?><pub-id pub-id-type="pmid">27252770</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goshvarpour</surname><given-names>A.</given-names></name><name><surname>Abbasi</surname><given-names>A.</given-names></name><name><surname>Goshvarpour</surname><given-names>A.</given-names></name><name><surname>Daneshvar</surname><given-names>S.</given-names></name></person-group> (<year>2016b</year>). <article-title>A novel signal-based fusion approach for accurate music emotion recognition.</article-title>
<volume>28</volume>:<issue>1650040</issue>
<pub-id pub-id-type="doi">10.4015/S101623721650040X</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goshvarpour</surname><given-names>A.</given-names></name><name><surname>Abbasi</surname><given-names>A.</given-names></name><name><surname>Goshvarpour</surname><given-names>A.</given-names></name></person-group> (<year>2017</year>). <article-title>Fusion of heart rate variability and pulse rate variability for emotion recognition using lagged poincare plots.</article-title>
<volume>40</volume>
<fpage>617</fpage>&#x02013;<lpage>629</lpage>. <pub-id pub-id-type="doi">10.1007/s13246-017-0571-1</pub-id>
<?supplied-pmid 28717902?><pub-id pub-id-type="pmid">28717902</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goyal</surname><given-names>S.</given-names></name><name><surname>Gupta</surname><given-names>V.</given-names></name><name><surname>Walia</surname><given-names>L.</given-names></name></person-group> (<year>2010</year>). <article-title>Effect of noise stress on autonomic function tests.</article-title>
<volume>12</volume>
<fpage>182</fpage>&#x02013;<lpage>186</lpage>. <pub-id pub-id-type="doi">10.4103/1463-1741.64976</pub-id>
<?supplied-pmid 20603574?><pub-id pub-id-type="pmid">20603574</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Graham</surname><given-names>J. M.</given-names></name><name><surname>Janssen</surname><given-names>S. A.</given-names></name><name><surname>Vos</surname><given-names>H.</given-names></name><name><surname>Miedema</surname><given-names>H. M.</given-names></name></person-group> (<year>2009</year>). <article-title>Habitual traffic noise at home reduces cardiac parasympathetic tone during sleep.</article-title>
<volume>72</volume>
<fpage>179</fpage>&#x02013;<lpage>186</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijpsycho.2008.12.004</pub-id>
<?supplied-pmid 19105970?><pub-id pub-id-type="pmid">19105970</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gruhlke</surname><given-names>L. C.</given-names></name><name><surname>Patr&#x000ed;cio</surname><given-names>M. C.</given-names></name><name><surname>Moreira</surname><given-names>D. M.</given-names></name></person-group> (<year>2015</year>). <article-title>Mozart, but not the Beatles, reduces systolic blood pressure in patients with myocardial infarction.</article-title>
<volume>70</volume>
<fpage>703</fpage>&#x02013;<lpage>706</lpage>. <pub-id pub-id-type="doi">10.2143/AC.70.6.3120183</pub-id>
<?supplied-pmid 26717219?><pub-id pub-id-type="pmid">26717219</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>U.</given-names></name><name><surname>Gupta</surname><given-names>B. S.</given-names></name></person-group> (<year>2015</year>). <article-title>Psychophysiological reactions to music in male coronary patients and healthy controls.</article-title>
<volume>43</volume>
<fpage>736</fpage>&#x02013;<lpage>755</lpage>. <pub-id pub-id-type="doi">10.1177/0305735614536754</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hajizadeh</surname><given-names>S.</given-names></name><name><surname>Abbasi</surname><given-names>A.</given-names></name><name><surname>Goshvarpour</surname><given-names>A.</given-names></name></person-group> (<year>2015</year>). <article-title>&#x0201c;Intelligent classification of ECG signals to distinguish between pre and on-music states,&#x0201d; in</article-title> (<publisher-loc>Tabriz</publisher-loc>: <publisher-name>Institute of Electrical and Electronics Engineers Inc.</publisher-name>). <pub-id pub-id-type="doi">10.1109/IKT.2015.7288790</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hewitt</surname><given-names>P. G.</given-names></name></person-group> (<year>2015</year>). <edition>12th Edn.</edition>
<publisher-loc>London</publisher-loc>: <publisher-name>Pearson Education Limited</publisher-name>.</mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holand</surname><given-names>S.</given-names></name><name><surname>Girard</surname><given-names>A.</given-names></name><name><surname>Laude</surname><given-names>D.</given-names></name><name><surname>Meyer-Bisch</surname><given-names>C.</given-names></name><name><surname>Elghozi</surname><given-names>J.-L.</given-names></name></person-group> (<year>1999</year>). <article-title>Effects of an auditory startle stimulus on blood pressure and heart rate in humans.</article-title>
<volume>17</volume>
<fpage>1893</fpage>&#x02013;<lpage>1897</lpage>. <pub-id pub-id-type="doi">10.1097/00004872-199917121-00018</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyde</surname><given-names>I. H.</given-names></name></person-group> (<year>1924</year>). <article-title>Effects of music upon electrocardiograms and blood pressure.</article-title>
<volume>7</volume>
<fpage>213</fpage>&#x02013;<lpage>224</lpage>. <pub-id pub-id-type="doi">10.1037/h0073580</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ishimitsu</surname><given-names>S.</given-names></name><name><surname>Oue</surname><given-names>K.</given-names></name><name><surname>Yamamoto</surname><given-names>A.</given-names></name><name><surname>Date</surname><given-names>Y.</given-names></name></person-group> (<year>2017</year>). <article-title>&#x0201c;Sound quality evaluation using heart rate variability analysis,&#x0201d; in</article-title> (<publisher-loc>Hiroshima</publisher-loc>: <publisher-name>International Institute of Acoustics and Vibrations</publisher-name>).</mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kasprzak</surname><given-names>C.</given-names></name></person-group> (<year>2010</year>). <article-title>The influence of infrasounds on the electrocardiograph patterns in humans.</article-title>
<volume>118</volume>
<fpage>87</fpage>&#x02013;<lpage>90</lpage>. <pub-id pub-id-type="doi">10.12693/APhysPolA.118.87</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kenntner-Mabiala</surname><given-names>R.</given-names></name><name><surname>Gorges</surname><given-names>S.</given-names></name><name><surname>Alpers</surname><given-names>G. W.</given-names></name><name><surname>Lehmann</surname><given-names>A. C.</given-names></name><name><surname>Pauli</surname><given-names>P.</given-names></name></person-group> (<year>2007</year>). <article-title>Musically induced arousal affects pain perception in females but not in males: a psychophysiological examination.</article-title>
<volume>75</volume>
<fpage>19</fpage>&#x02013;<lpage>23</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsycho.2006.10.005</pub-id>
<?supplied-pmid 17118518?><pub-id pub-id-type="pmid">17118518</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>J.</given-names></name><name><surname>Andr&#x000e9;</surname><given-names>E.</given-names></name></person-group> (<year>2008</year>). <article-title>Emotion recognition based on physiological changes in music listening.</article-title>
<volume>30</volume>
<fpage>2067</fpage>&#x02013;<lpage>2083</lpage>. <pub-id pub-id-type="doi">10.1109/TPAMI.2008.26</pub-id>
<?supplied-pmid 18988943?><pub-id pub-id-type="pmid">18988943</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koelsch</surname><given-names>S.</given-names></name><name><surname>Jancke</surname><given-names>L.</given-names></name></person-group> (<year>2015</year>). <article-title>Music and the heart.</article-title>
<volume>36</volume>
<fpage>3043</fpage>&#x02013;<lpage>3049</lpage>. <pub-id pub-id-type="doi">10.1093/eurheartj/ehv430</pub-id>
<?supplied-pmid 26354957?><pub-id pub-id-type="pmid">26354957</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Koelsch</surname><given-names>S.</given-names></name><name><surname>Remppis</surname><given-names>A.</given-names></name><name><surname>Sammler</surname><given-names>D.</given-names></name><name><surname>Jentschke</surname><given-names>S.</given-names></name><name><surname>Mietchen</surname><given-names>D.</given-names></name><name><surname>Fritz</surname><given-names>T.</given-names></name><etal/></person-group> (<year>2007</year>). <article-title>A cardiac signature of emotionality.</article-title>
<volume>26</volume>
<fpage>3328</fpage>&#x02013;<lpage>3338</lpage>. <pub-id pub-id-type="doi">10.1111/j.1460-9568.2007.05889.x</pub-id>
<?supplied-pmid 18028117?><pub-id pub-id-type="pmid">18028117</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krabs</surname><given-names>R. U.</given-names></name><name><surname>Enk</surname><given-names>R.</given-names></name><name><surname>Teich</surname><given-names>N.</given-names></name><name><surname>Koelsch</surname><given-names>S.</given-names></name></person-group> (<year>2015</year>). <article-title>Autonomic effects of music in health and Crohn&#x02019;s disease: the impact of isochronicity, emotional valence, and tempo.</article-title>
<volume>10</volume>:<issue>e0126224</issue>. <pub-id pub-id-type="doi">10.1371/journal.pone.0126224</pub-id>
<?supplied-pmid 25955253?><pub-id pub-id-type="pmid">25955253</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krantz</surname><given-names>G.</given-names></name><name><surname>Kreutz</surname><given-names>G.</given-names></name><name><surname>Ericson</surname><given-names>M.</given-names></name><name><surname>Theorell</surname><given-names>T.</given-names></name></person-group> (<year>2010</year>). <article-title>Bodily movements influence heart rate variability (HRV) responses to isolated melodic intervals.</article-title>
<volume>3</volume>
<fpage>108</fpage>&#x02013;<lpage>113</lpage>. <pub-id pub-id-type="doi">10.1177/1943862110387612</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kraus</surname><given-names>U.</given-names></name><name><surname>Schneider</surname><given-names>A.</given-names></name><name><surname>Breitner</surname><given-names>S.</given-names></name><name><surname>Hampel</surname><given-names>R.</given-names></name><name><surname>R&#x000fc;ckerl</surname><given-names>R.</given-names></name><name><surname>Pitz</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Individual daytime noise exposure during routine activities and heart rate variability in adults: a repeated measures study.</article-title>
<volume>121</volume>
<fpage>607</fpage>&#x02013;<lpage>612</lpage>. <pub-id pub-id-type="doi">10.1289/ehp.1205606</pub-id>
<?supplied-pmid 23512292?><pub-id pub-id-type="pmid">23512292</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>G.-S.</given-names></name><name><surname>Chen</surname><given-names>M.-L.</given-names></name><name><surname>Wang</surname><given-names>G.-Y.</given-names></name></person-group> (<year>2010</year>). <article-title>Evoked response of heart rate variability using short-duration white noise.</article-title>
<volume>155</volume>
<fpage>94</fpage>&#x02013;<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1016/j.autneu.2009.12.008</pub-id>
<?supplied-pmid 20071247?><pub-id pub-id-type="pmid">20071247</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Martin-Soelch</surname><given-names>C.</given-names></name><name><surname>St&#x000f6;cklin</surname><given-names>M.</given-names></name><name><surname>Dammann</surname><given-names>G.</given-names></name><name><surname>Opwis</surname><given-names>K.</given-names></name><name><surname>Seifritz</surname><given-names>E.</given-names></name></person-group> (<year>2006</year>). <article-title>Anxiety trait modulates psychophysiological reactions, but not habituation processes related to affective auditory stimuli.</article-title>
<volume>61</volume>
<fpage>87</fpage>&#x02013;<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijpsycho.2005.07.009</pub-id>
<?supplied-pmid 16135389?><pub-id pub-id-type="pmid">16135389</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>McDermott</surname><given-names>J. H.</given-names></name></person-group> (<year>2012</year>). <article-title>&#x0201c;Chapter 10 - Auditory preferences and aesthetics: music, voices, and everyday sounds,&#x0201d; in</article-title>
<role>eds</role>
<person-group person-group-type="editor"><name><surname>Dolan</surname><given-names>R.</given-names></name><name><surname>Sharot</surname><given-names>C.</given-names></name></person-group> (<publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic Press</publisher-name>) <fpage>227</fpage>&#x02013;<lpage>256</lpage>. <pub-id pub-id-type="doi">10.1016/B978-0-12-381431-9.00020-6</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDermott</surname><given-names>J. H.</given-names></name><name><surname>Schultz</surname><given-names>A. F.</given-names></name><name><surname>Undurraga</surname><given-names>E. A.</given-names></name><name><surname>Godoy</surname><given-names>R. A.</given-names></name></person-group> (<year>2016</year>). <article-title>Indifference to dissonance in native Amazonians reveals cultural variation in music perception.</article-title>
<volume>535</volume>
<fpage>547</fpage>&#x02013;<lpage>550</lpage>. <pub-id pub-id-type="doi">10.1038/nature18635</pub-id>
<?supplied-pmid 27409816?><pub-id pub-id-type="pmid">27409816</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mofredj</surname><given-names>A.</given-names></name><name><surname>Alaya</surname><given-names>S.</given-names></name><name><surname>Tassaioust</surname><given-names>K.</given-names></name><name><surname>Bahloul</surname><given-names>H.</given-names></name><name><surname>Mrabet</surname><given-names>A.</given-names></name></person-group> (<year>2016</year>). <article-title>Music therapy, a review of the potential therapeutic benefits for the critically ill.</article-title>
<volume>35</volume>
<fpage>195</fpage>&#x02013;<lpage>199</lpage>. <pub-id pub-id-type="doi">10.1016/j.jcrc.2016.05.021</pub-id>
<?supplied-pmid 27481759?><pub-id pub-id-type="pmid">27481759</pub-id></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moher</surname><given-names>D.</given-names></name><name><surname>Liberati</surname><given-names>A.</given-names></name><name><surname>Tetzlaff</surname><given-names>J.</given-names></name><name><surname>Altman</surname><given-names>D. G.</given-names></name></person-group> (<year>2009</year>). <article-title>Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement.</article-title>
<volume>6</volume>:<issue>e1000097</issue>. <pub-id pub-id-type="doi">10.1371/journal.pmed.1000097</pub-id>
<?supplied-pmid 19621072?><pub-id pub-id-type="pmid">19621072</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mont&#x000e1;nchez Torres</surname><given-names>M. L.</given-names></name><name><surname>Ju&#x000e1;rez Ramos</surname><given-names>V.</given-names></name><name><surname>Mart&#x000ed;nez Su&#x000e1;rez</surname><given-names>P. C.</given-names></name><name><surname>Alonso Garc&#x000ed;a</surname><given-names>S.</given-names></name><name><surname>Torres Mendoza</surname><given-names>M.</given-names></name></person-group> (<year>2016</year>). <article-title>Benefits of using music therapy in mental disorders.</article-title>
<volume>4</volume>:<issue>116</issue>
<pub-id pub-id-type="doi">10.4172/2090-2719.1000116</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Naji</surname><given-names>M.</given-names></name><name><surname>Firoozabadi</surname><given-names>M.</given-names></name><name><surname>Azadfallah</surname><given-names>P.</given-names></name></person-group> (<year>2014a</year>). <article-title>&#x0201c;A new information fusion approach for recognition of music-induced emotions,&#x0201d; in</article-title> (<publisher-loc>Dezful</publisher-loc>: <publisher-name>IEEE Computer Society</publisher-name>) <fpage>205</fpage>&#x02013;<lpage>208</lpage>. <pub-id pub-id-type="doi">10.1109/BHI.2014.6864340</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Naji</surname><given-names>M.</given-names></name><name><surname>Firoozabadi</surname><given-names>M.</given-names></name><name><surname>Azadfallah</surname><given-names>P.</given-names></name></person-group> (<year>2014b</year>). <article-title>Classification of music-induced emotions based on information fusion of forehead biosignals and electrocardiogram.</article-title>
<volume>6</volume>
<fpage>241</fpage>&#x02013;<lpage>252</lpage>. <pub-id pub-id-type="doi">10.1007/s12559-013-9239-7</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nakajima</surname><given-names>Y.</given-names></name><name><surname>Tanaka</surname><given-names>N.</given-names></name><name><surname>Mima</surname><given-names>T.</given-names></name><name><surname>Izumi</surname><given-names>S.-I.</given-names></name></person-group> (<year>2016</year>). <article-title>Stress recovery effects of high- and low-frequency amplified music on heart rate variability.</article-title>
<volume>2016</volume>:<issue>5965894</issue>. <pub-id pub-id-type="doi">10.1155/2016/5965894</pub-id>
<?supplied-pmid 27660396?><pub-id pub-id-type="pmid">27660396</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nardelli</surname><given-names>M.</given-names></name><name><surname>Valenza</surname><given-names>G.</given-names></name><name><surname>Greco</surname><given-names>A.</given-names></name><name><surname>Lanata</surname><given-names>A.</given-names></name><name><surname>Scilingo</surname><given-names>E. P.</given-names></name></person-group> (<year>2015</year>). <article-title>Recognizing emotions induced by affective sounds through heart rate variability.</article-title>
<volume>6</volume>
<fpage>385</fpage>&#x02013;<lpage>394</lpage>. <pub-id pub-id-type="doi">10.1109/TAFFC.2015.2432810</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Niu</surname><given-names>X.</given-names></name><name><surname>Chen</surname><given-names>L.</given-names></name><name><surname>Xie</surname><given-names>H.</given-names></name><name><surname>Chen</surname><given-names>Q.</given-names></name><name><surname>Li</surname><given-names>H.</given-names></name></person-group> (<year>2014</year>). <article-title>Emotion pattern recognition using physiological signals.</article-title>
<volume>172</volume>
<fpage>147</fpage>&#x02013;<lpage>156</lpage>.</mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nozaki</surname><given-names>H.</given-names></name><name><surname>Uetake</surname><given-names>T.</given-names></name><name><surname>Shimoda</surname><given-names>M.</given-names></name></person-group> (<year>2015</year>). <article-title>Sex differences in the effects of diverse sounds on heart rate variability.</article-title>
<volume>44</volume>
<fpage>83</fpage>&#x02013;<lpage>86</lpage>. <?supplied-pmid 27501540?><pub-id pub-id-type="pmid">27501540</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Oh</surname><given-names>B.-S.</given-names></name><name><surname>Yeo</surname><given-names>Y. K.</given-names></name><name><surname>Wan</surname><given-names>F. Y.</given-names></name><name><surname>Wen</surname><given-names>Y.</given-names></name><name><surname>Yang</surname><given-names>Y.</given-names></name><name><surname>Lin</surname><given-names>Z.</given-names></name></person-group> (<year>2015</year>). <article-title>&#x0201c;Effects of noisy sounds on human stress using ECG signals: an empirical study,&#x0201d; in</article-title> (<publisher-loc>Singapore</publisher-loc>: <publisher-name>Institute of Electrical and Electronics Engineers Inc.</publisher-name>). <pub-id pub-id-type="doi">10.1109/ICICS.2015.7459852</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Orini</surname><given-names>M.</given-names></name><name><surname>Bail&#x000f3;n</surname><given-names>R.</given-names></name><name><surname>Enk</surname><given-names>R.</given-names></name><name><surname>Koelsch</surname><given-names>S.</given-names></name><name><surname>Mainardi</surname><given-names>L.</given-names></name><name><surname>Laguna</surname><given-names>P.</given-names></name></person-group> (<year>2010</year>). <article-title>A method for continuously assessing the autonomic response to music-induced emotions through HRV analysis.</article-title>
<volume>48</volume>
<fpage>423</fpage>&#x02013;<lpage>433</lpage>. <pub-id pub-id-type="doi">10.1007/s11517-010-0592-3</pub-id>
<?supplied-pmid 20300873?><pub-id pub-id-type="pmid">20300873</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Osiris</surname><given-names>W.</given-names></name><name><surname>Mohamed</surname><given-names>A.-E.</given-names></name><name><surname>Hany</surname><given-names>S.</given-names></name></person-group> (<year>2014</year>). <article-title>&#x0201c;The association between noise exposure and blood pressure and ECG of workers in Egyptian factories,&#x0201d; in</article-title> (<publisher-loc>Giza</publisher-loc>: <publisher-name>International Institute of Acoustics and Vibrations</publisher-name>) <fpage>64</fpage>&#x02013;<lpage>75</lpage>.</mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>P&#x000e9;rez-Lloret</surname><given-names>S.</given-names></name><name><surname>Diez</surname><given-names>J.</given-names></name><name><surname>Dom&#x000e9;</surname><given-names>M. N.</given-names></name><name><surname>Alvarez</surname><given-names>A.</given-names></name><name><surname>Braidot</surname><given-names>N.</given-names></name><name><surname>Cardinali</surname><given-names>D. P.</given-names></name><etal/></person-group> (<year>2014</year>). <article-title>Effects of different &#x0201c;relaxing&#x0201d; music styles on the autonomic nervous system.</article-title>
<volume>16</volume>
<fpage>279</fpage>&#x02013;<lpage>284</lpage>. <pub-id pub-id-type="doi">10.4103/1463-1741.140507</pub-id>
<?supplied-pmid 25209037?><pub-id pub-id-type="pmid">25209037</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Raggam</surname><given-names>R. B.</given-names></name><name><surname>Cik</surname><given-names>M.</given-names></name><name><surname>H&#x000f6;ldrich</surname><given-names>R. R.</given-names></name><name><surname>Fallast</surname><given-names>K.</given-names></name><name><surname>Gallasch</surname><given-names>E.</given-names></name><name><surname>Fend</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2007</year>). <article-title>Personal noise ranking of road traffic: subjective estimation versus physiological parameters under laboratory conditions.</article-title>
<volume>210</volume>
<fpage>97</fpage>&#x02013;<lpage>105</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijheh.2006.08.007</pub-id>
<?supplied-pmid 17084667?><pub-id pub-id-type="pmid">17084667</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rhomberg</surname><given-names>F.</given-names></name><name><surname>Moeslinger</surname><given-names>T.</given-names></name><name><surname>Gottsauner-Wolf</surname><given-names>M.</given-names></name></person-group> (<year>2014</year>). <article-title>Music-induced prolongation of heart rate corrected QT intervals from electrocardiogram recordings of healthy preterm pregnant women.</article-title>
<volume>44</volume>
<fpage>631</fpage>&#x02013;<lpage>635</lpage>. <pub-id pub-id-type="doi">10.1515/jpm-2014-0200</pub-id>
<?supplied-pmid 25470602?><pub-id pub-id-type="pmid">25470602</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Robb</surname><given-names>S. L.</given-names></name><name><surname>Burns</surname><given-names>D. S.</given-names></name><name><surname>Carpenter</surname><given-names>J. S.</given-names></name></person-group> (<year>2011</year>). <article-title>Reporting guidelines for music-based interventions.</article-title>
<volume>3</volume>
<fpage>271</fpage>&#x02013;<lpage>279</lpage>. <pub-id pub-id-type="doi">10.1177/1943862111420539</pub-id>
<?supplied-pmid 23646227?><pub-id pub-id-type="pmid">23646227</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sancini</surname><given-names>A.</given-names></name><name><surname>Tomei</surname><given-names>G.</given-names></name><name><surname>Vitarelli</surname><given-names>A.</given-names></name><name><surname>Caciari</surname><given-names>T.</given-names></name><name><surname>Samperi</surname><given-names>I.</given-names></name><name><surname>Pacchiarotti</surname><given-names>A.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Cardiovascular risk in rotogravure industry.</article-title>
<volume>54</volume>
<fpage>551</fpage>&#x02013;<lpage>557</lpage>. <pub-id pub-id-type="doi">10.1097/JOM.0b013e318247a42d</pub-id>
<?supplied-pmid 22569474?><pub-id pub-id-type="pmid">22569474</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sim</surname><given-names>C. S.</given-names></name><name><surname>Sung</surname><given-names>J. H.</given-names></name><name><surname>Cheon</surname><given-names>S. H.</given-names></name><name><surname>Lee</surname><given-names>J. M.</given-names></name><name><surname>Lee</surname><given-names>J. W.</given-names></name><name><surname>Lee</surname><given-names>J.</given-names></name></person-group> (<year>2015</year>). <article-title>The effects of different noise types on heart rate variability in men.</article-title>
<volume>56</volume>
<fpage>235</fpage>&#x02013;<lpage>243</lpage>. <pub-id pub-id-type="doi">10.3349/ymj.2015.56.1.235</pub-id>
<?supplied-pmid 25510770?><pub-id pub-id-type="pmid">25510770</pub-id></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tan</surname><given-names>Y. Z.</given-names></name><name><surname>Ozdemir</surname><given-names>S.</given-names></name><name><surname>Temiz</surname><given-names>A.</given-names></name><name><surname>Celik</surname><given-names>F.</given-names></name></person-group> (<year>2015</year>). <article-title>The effect of relaxing music on heart rate and heart rate variability during ECG GATED-myocardial perfusion scintigraphy.</article-title>
<volume>21</volume>
<fpage>137</fpage>&#x02013;<lpage>140</lpage>. <pub-id pub-id-type="doi">10.1016/j.ctcp.2014.12.003</pub-id>
<?supplied-pmid 25747187?><pub-id pub-id-type="pmid">25747187</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thayer</surname><given-names>J. F.</given-names></name><name><surname>Faith</surname><given-names>M. L.</given-names></name></person-group> (<year>2001</year>). <article-title>A dynamic systems model of musically induced emotions: physiological and self-report evidence.</article-title>
<volume>930</volume>
<fpage>452</fpage>&#x02013;<lpage>456</lpage>. <pub-id pub-id-type="doi">10.1111/j.1749-6632.2001.tb05768.x</pub-id>
<?supplied-pmid 11458866?><pub-id pub-id-type="pmid">11458866</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tomei</surname><given-names>F.</given-names></name><name><surname>Fantini</surname><given-names>S.</given-names></name><name><surname>Tomao</surname><given-names>E.</given-names></name><name><surname>Baccolo</surname><given-names>T. P.</given-names></name><name><surname>Rosati</surname><given-names>M. V.</given-names></name></person-group> (<year>2000</year>). <article-title>Hypertension and chronic exposure to noise.</article-title>
<volume>55</volume>
<fpage>319</fpage>&#x02013;<lpage>325</lpage>. <pub-id pub-id-type="doi">10.1080/00039890009604023</pub-id>
<?supplied-pmid 11063406?><pub-id pub-id-type="pmid">11063406</pub-id></mixed-citation></ref><ref id="B66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Trappe</surname><given-names>H. J.</given-names></name></person-group> (<year>2012</year>). <article-title>Music and medicine: the effects of music on the human being.</article-title>
<volume>16</volume>
<fpage>133</fpage>&#x02013;<lpage>142</lpage>.</mixed-citation></ref><ref id="B67"><mixed-citation publication-type="journal"><collab>Trend Statement CDC</collab> (<year>2017</year>). <comment>Available at: <ext-link ext-link-type="uri" xlink:href="https://www.cdc.gov/trendstatement/">https://www.cdc.gov/trendstatement/</ext-link> [accessed October 9 2017]</comment>.</mixed-citation></ref><ref id="B68"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ucl&#x000e9;s</surname><given-names>I. R.</given-names></name><name><surname>de la Fuente Solana</surname><given-names>E. I.</given-names></name><name><surname>Tamayo</surname><given-names>I. M.</given-names></name><name><surname>Castellar</surname><given-names>J. V.</given-names></name></person-group> (<year>2006</year>). <article-title>Effect of manipulating the risetime of an acoustic stimulus on two protective reflexes: cardiac defense and motor startle.</article-title>
<volume>18</volume>
<fpage>717</fpage>&#x02013;<lpage>723</lpage>. <?supplied-pmid 17296108?><pub-id pub-id-type="pmid">17296108</pub-id></mixed-citation></ref><ref id="B69"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wagner</surname><given-names>J.</given-names></name><name><surname>Kim</surname><given-names>J.</given-names></name><name><surname>Andr&#x000e9;</surname><given-names>E.</given-names></name></person-group> (<year>2005</year>). <article-title>&#x0201c;From physiological signals to emotions: implementing and comparing selected methods for feature extraction and classification,&#x0201d; in</article-title> (<publisher-loc>Augsburg</publisher-loc>: <publisher-name>Institute of Computer Science, University of Augsburg</publisher-name>) <fpage>940</fpage>&#x02013;<lpage>943</lpage>. <pub-id pub-id-type="doi">10.1109/ICME.2005.1521579</pub-id></mixed-citation></ref><ref id="B70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>E. D.</given-names></name><name><surname>Brammer</surname><given-names>A.</given-names></name><name><surname>Cherniack</surname><given-names>M. G.</given-names></name><name><surname>Laden</surname><given-names>F.</given-names></name><name><surname>Cavallari</surname><given-names>J. M.</given-names></name></person-group> (<year>2016</year>). <article-title>Cardiovascular and stress responses to short-term noise exposures&#x02014;A panel study in healthy males.</article-title>
<volume>150</volume>
<fpage>391</fpage>&#x02013;<lpage>397</lpage>. <pub-id pub-id-type="doi">10.1016/j.envres.2016.06.016</pub-id>
<?supplied-pmid 27371930?><pub-id pub-id-type="pmid">27371930</pub-id></mixed-citation></ref><ref id="B71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watanabe</surname><given-names>K.</given-names></name><name><surname>Ooishi</surname><given-names>Y.</given-names></name><name><surname>Kashino</surname><given-names>M.</given-names></name></person-group> (<year>2015</year>). <article-title>Sympathetic tone induced by high acoustic tempo requires fast respiration.</article-title>
<volume>10</volume>:<issue>e0135589</issue>. <pub-id pub-id-type="doi">10.1371/journal.pone.0135589</pub-id>
<?supplied-pmid 26284521?><pub-id pub-id-type="pmid">26284521</pub-id></mixed-citation></ref><ref id="B72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watkins</surname><given-names>G. R.</given-names></name></person-group> (<year>1997</year>). <article-title>Music therapy: proposed physiological mechanisms and clinical implications.</article-title>
<volume>11</volume>
<fpage>43</fpage>&#x02013;<lpage>50</lpage>. <pub-id pub-id-type="doi">10.1097/00002800-199703000-00003</pub-id>
<?supplied-pmid 9233140?><pub-id pub-id-type="pmid">9233140</pub-id></mixed-citation></ref><ref id="B73"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wong</surname><given-names>W. M.</given-names></name><name><surname>Tan</surname><given-names>A. W. C.</given-names></name><name><surname>Loo</surname><given-names>C. K.</given-names></name><name><surname>Liew</surname><given-names>W. S.</given-names></name></person-group> (<year>2010</year>). <article-title>&#x0201c;PSO optimization of synergetic neural classifier for multichannel emotion recognition,&#x0201d; in</article-title> (<publisher-loc>Melaka</publisher-loc>: <publisher-name>Faculty of Engineering and Technology, Multimedia University</publisher-name>) <fpage>316</fpage>&#x02013;<lpage>321</lpage>. <pub-id pub-id-type="doi">10.1109/NABIC.2010.5716292</pub-id></mixed-citation></ref><ref id="B74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yang</surname><given-names>W.</given-names></name><name><surname>Kang</surname><given-names>J.</given-names></name></person-group> (<year>2005</year>). <article-title>Soundscape and sound preferences in urban squares: a case study in Sheffield.</article-title>
<volume>10</volume>
<fpage>61</fpage>&#x02013;<lpage>80</lpage>. <pub-id pub-id-type="doi">10.1080/13574800500062395</pub-id></mixed-citation></ref><ref id="B75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yuan</surname><given-names>J.</given-names></name><name><surname>Yang</surname><given-names>M.</given-names></name><name><surname>Yao</surname><given-names>H.</given-names></name><name><surname>Zheng</surname><given-names>J.</given-names></name><name><surname>Yang</surname><given-names>Q.</given-names></name><name><surname>Chen</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2005</year>). <article-title>Plasma antibodies to heat shock protein 60 and heat shock protein 70 are associated with increased risk of electrocardiograph abnormalities in automobile workers exposed to noise.</article-title>
<volume>10</volume>
<fpage>126</fpage>&#x02013;<lpage>135</lpage>. <pub-id pub-id-type="doi">10.1379/CSC-95R.1</pub-id>
<?supplied-pmid 16038409?><pub-id pub-id-type="pmid">16038409</pub-id></mixed-citation></ref></ref-list><glossary><title>Abbreviations</title><def-list id="DL1"><def-item><term>ANS</term><def><p>autonomic nervous system</p></def></def-item><def-item><term>BP</term><def><p>blood pressure</p></def></def-item><def-item><term>BPM</term><def><p>beats per minute</p></def></def-item><def-item><term>DBP</term><def><p>diastolic blood pressure</p></def></def-item><def-item><term>ECG</term><def><p>electrocardiography &#x02013; electrocardiogram</p></def></def-item><def-item><term>EEG</term><def><p>electroencephalography &#x02013; electroencephalogram</p></def></def-item><def-item><term>EMG</term><def><p>electromyography &#x02013; electromyogram</p></def></def-item><def-item><term>GSR</term><def><p>galvanic skin response</p></def></def-item><def-item><term>HF</term><def><p>high-frequency power &#x02013; HRV</p></def></def-item><def-item><term>HR</term><def><p>heart rate</p></def></def-item><def-item><term>HRV</term><def><p>heart rate variability</p></def></def-item><def-item><term>LF</term><def><p>low-frequency power &#x02013; HRV</p></def></def-item><def-item><term>NN50</term><def><p>number of adjacent NN intervals which differ by at least 50 ms &#x02013; HRV</p></def></def-item><def-item><term>RMSSD</term><def><p>root mean square of successive differences &#x02013; HRV</p></def></def-item><def-item><term>SBP</term><def><p>systolic blood pressure</p></def></def-item><def-item><term>SDNN</term><def><p>SD of RR intervals</p></def></def-item><def-item><term>VLF</term><def><p>very low frequency power</p></def></def-item></def-list></glossary></back></article>