<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//Springer-Verlag//DTD A++ V2.4//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName A++V2.4.dtd?><?SourceDTD.Version 2.4?><?ConverterInfo.XSLTName springer2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">BMC Neurosci</journal-id><journal-title-group><journal-title>BMC Neuroscience</journal-title></journal-title-group><issn pub-type="epub">1471-2202</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4574220</article-id><article-id pub-id-type="pmid">26377548</article-id><article-id pub-id-type="publisher-id">200</article-id><article-id pub-id-type="doi">10.1186/s12868-015-0200-4</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group></article-categories><title-group><article-title>Musical ability is associated with enhanced auditory and visual cognitive processing</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Fa&#x000df;hauer</surname><given-names>Caroline</given-names></name><address><email>caroline.fasshauer@arcor.de</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Frese</surname><given-names>Achim</given-names></name><address><email>fresea@uni-muenster.de</email></address><xref ref-type="aff" rid="Aff1"/><xref ref-type="aff" rid="Aff2"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Evers</surname><given-names>Stefan</given-names></name><address><phone>+49-5156-782-290</phone><email>everss@uni-muenster.de</email></address><xref ref-type="aff" rid="Aff1"/><xref ref-type="aff" rid="Aff3"/></contrib><aff id="Aff1"><label/>Department of Neurology, University of M&#x000fc;nster, M&#x000fc;nster, Germany </aff><aff id="Aff2"><label/>Academy of Manual Medicine, M&#x000fc;nster, Germany </aff><aff id="Aff3"><label/>Department of Neurology, Krankenhaus Lindenbrunn, Lindenbrunn 1, 31863 Coppenbr&#x000fc;gge, Germany </aff></contrib-group><pub-date pub-type="epub"><day>16</day><month>9</month><year>2015</year></pub-date><pub-date pub-type="pmc-release"><day>16</day><month>9</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>16</volume><elocation-id>59</elocation-id><history><date date-type="received"><day>21</day><month>6</month><year>2015</year></date><date date-type="accepted"><day>8</day><month>9</month><year>2015</year></date></history><permissions><copyright-statement>&#x000a9; Fa&#x000df;hauer et al. 2015</copyright-statement><license license-type="OpenAccess"><license-p><bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p>Musical ability has always been linked to enhanced cognitive and intellectual skills. We were interested in the relation between musical ability and short-time cognitive processing as measured by event-related potentials, in particular in visual processing, since previous studies have already suggested such a link for acoustic cognitive processing. We measured auditory and visual event-related potentials as elicited by an oddball paradigm in 20 healthy subjects (10 musicians and 10 non-musicians; 10 female; mean age 24&#x000a0;&#x000b1;&#x000a0;2&#x000a0;years). In addition, the Seashore test and a test developed by the authors to detect relevant amusia, the latter one with a high ceiling effect, were also applied.</p></sec><sec><title>Results</title><p>The most important finding was that there is a significant linear correlation between musical ability as measured by these tests and the P3 latencies of both the auditory and visual event-related potentials. Furthermore, musicians showed shorter latencies of the event-related potentials than non-musicians.</p></sec><sec><title>Conclusions</title><p>We conclude that musical ability as measured by neuropsychological tests is associated with improved short-time cognitive processing both in the auditory and, surprisingly, also in the visual domain.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Music</kwd><kwd>Musical ability</kwd><kwd>Event-related potentials</kwd><kwd>Visual cognition</kwd><kwd>Auditory cognition</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2015</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p>Musical ability as a term is used to describe the sensitivity for music, the ability to understand music, and/or the ability to produce music. There is no standard definition, and it is hard to measure musical ability. One can only measure how well a person can perceive musical stimuli such as small changes in pitch, loudness, rhythm, and other sub-domains of music processing. It is generally accepted that some people show higher musical ability than others. But what are the correlates for the term &#x02018;musical ability&#x02019; in the human brain? What are the differences between people with and without musical ability?</p><p>These questions and many others about music and music processing in the human brain have been a subject of interest in neuroscience research. The methods used in this field range widely from EEG, event-related potentials (ERP), magnetic resonance imaging (MRI) to the different methods of functional imaging. The processing of auditory stimuli and the differences in such processing between musicians and non-musicians have been investigated especially by means of auditory ERP which can objectively quantify latencies of stimulus processing. This evaluation is regarded as a measure for the quality of some aspects of cognitive processing such as stimulus evaluation, cognitive processing speed and internal short-term memory functions.</p><p>In general, rare target stimuli and frequent non-target stimuli are presented to subjects in ERP studies. The latencies and amplitudes of the potentials evoked by the target stimuli are analyzed such as the Mismatch Negativity (MMN or N2a) in auditory ERP studies and the P3 in both visual and auditory ERP studies. In previous music research studies, the subjects were either professional and non-professional musicians, people with absolute pitch, or non-musicians.</p><p>Looking at the results of different studies [<xref ref-type="bibr" rid="CR1">1</xref>&#x02013;<xref ref-type="bibr" rid="CR5">5</xref>], one can sum up that musicians with absolute pitch ability and musicians with relative pitch seem to have a shorter P3 latency in the auditory evoked ERP and also a smaller P3 amplitude than non-musicians. The P3 could even not be found at all in some musicians with absolute pitch [<xref ref-type="bibr" rid="CR3">3</xref>] when the method that led to a P3 signal in all musicians with relative pitch was the discrimination between major thirds as non-target and minor thirds as target stimuli. In a timbre discrimination study [<xref ref-type="bibr" rid="CR6">6</xref>], subjects with absolute pitch showed a shorter P3 latency and a smaller P3 amplitude than other musicians and non-musicians. The subjects had to differentiate between the sound of a tone with the same pitch played on a viola or a cello, on two different kinds of flutes and on two different kinds of tubas. In the last (tuba) part, the musicians showed a significantly shorter P3 latency than the non-musicians.</p><p>In a different approach, a piano phrase by Bach was used for eliciting ERP [<xref ref-type="bibr" rid="CR7">7</xref>]. They presented the original phrase (non-target) or the same phrase with an inharmonic note (target) or the same phrase with an unexpected mordent (target) to a group of musicians and a group of non-musicians. A shorter P3 latency for musicians could not be shown, but instead of that and among other results, a shorter N2 latency was detected. In a study in 1996 [<xref ref-type="bibr" rid="CR8">8</xref>], the reaction time of musicians was shorter in comparison to non-musicians when the subjects had to discriminate between small differences in frequency. Further, it was incidentally found a significantly decreased P3a latency in musicians (i.e., vocalists and instrumentalists) compared to non-musicians, evoking the P3 by means of pitch deviants [<xref ref-type="bibr" rid="CR9">9</xref>]. The P3a signal was suggested to be a sensitive index of musical expertise.</p><p>All in all, the studies mentioned above suggest a faster discrimination of auditory stimuli in musicians (with or without absolute pitch). None of the studies had analyzed the latencies of visually evoked ERP, and only two [<xref ref-type="bibr" rid="CR1">1</xref>, <xref ref-type="bibr" rid="CR10">10</xref>] have measured the amplitudes of the visually evoked P3 latency in subjects with absolute pitch, which was not found to be changed.</p><p>We raised the question whether people with absolute pitch have a different cognitive stimulus processing as measured by ERP, and not just a different processing of auditory stimuli, as most of the studies mentioned above suggest. In an experiment with three participating groups (musicians with absolute pitch, musicians without absolute pitch, and non-musicians), our group was able to show that both people with absolute pitch compared to non-musicians and musicians compared to non-musicians show a significantly decreased P3 latency in the auditory and visually evoked ERP [<xref ref-type="bibr" rid="CR11">11</xref>]. The P3 amplitudes were not significantly different. In a similar study, our group was able to show a significantly decreased auditory and visually evoked P3 latency in musicians as well as a larger amplitude of the P3 in the auditory domain [<xref ref-type="bibr" rid="CR12">12</xref>].</p><p>In the present study, we were interested in aspects of the specific visual cognitive processing in musicians versus non-musicians. In particular, we aimed to correlate the ERP results of visual and auditory stimulus processing with musical ability as evaluated by a psychometric measure. We chose an oddball paradigm since this is a very easy task not detracting the probands too much. Furthermore, oddball paradigms are often used in research on musical cognitive processing in the past. Since a specific cognitive processing of ERP has been shown for auditory stimuli, a similar result for visual stimuli would suggest that musical ability is associated with a specific cognitive processing in all modalities.</p></sec><sec id="Sec2"><title>Results</title><p>As shown in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>, there were no significant differences between the two groups with respect to age and the scores of the Zerssen scale. All subjects showed a normal mental well-being. This is important since feeling unwell could impair the results of the musical testing.<table-wrap id="Tab1"><label>Table&#x000a0;1</label><caption><p>Data at baseline of the two subject groups</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Musicians (n&#x000a0;=&#x000a0;10)</th><th align="left">Non-musicians (n&#x000a0;=&#x000a0;10)</th><th align="left">Significance</th></tr></thead><tbody><tr><td align="left">Age</td><td align="left">23&#x000a0;&#x000b1;&#x000a0;2</td><td align="left">24&#x000a0;&#x000b1;&#x000a0;2</td><td align="left">ns (p&#x000a0;=&#x000a0;0.436)</td></tr><tr><td align="left">Sex</td><td align="left">5 male/5 female</td><td align="left">5 male/5 female</td><td align="left">&#x02013;</td></tr><tr><td align="left" colspan="4">Amusia test</td></tr><tr><td align="left">&#x000a0;1a. Rhythm</td><td align="left">15.5&#x000a0;&#x000b1;&#x000a0;0.7</td><td align="left">9.8&#x000a0;&#x000b1;&#x000a0;1.8</td><td align="left">p&#x000a0;&#x0003c;&#x000a0;0.001</td></tr><tr><td align="left">&#x000a0;1b. Metrum</td><td align="left">16.0&#x000a0;&#x000b1;&#x000a0;0.0</td><td align="left">11.4&#x000a0;&#x000b1;&#x000a0;2.9</td><td align="left">p&#x000a0;&#x0003c;&#x000a0;0.001</td></tr><tr><td align="left">&#x000a0;2. Comparison of melodies</td><td align="left">15.5&#x000a0;&#x000b1;&#x000a0;0.7</td><td align="left">12.6&#x000a0;&#x000b1;&#x000a0;1.8</td><td align="left">p&#x000a0;&#x0003c;&#x000a0;0.001</td></tr><tr><td align="left">&#x000a0;3. Emotion</td><td align="left">11.2&#x000a0;&#x000b1;&#x000a0;0.9</td><td align="left">11.0&#x000a0;&#x000b1;&#x000a0;0.9</td><td align="left">ns (p&#x000a0;=&#x000a0;0.684)</td></tr><tr><td align="left">&#x000a0;4. Pitch</td><td align="left">12.0&#x000a0;&#x000b1;&#x000a0;0.0</td><td align="left">10.5&#x000a0;&#x000b1;&#x000a0;1.3</td><td align="left">p&#x000a0;=&#x000a0;0.007</td></tr><tr><td align="left">&#x000a0;5. Identification of melodies</td><td align="left">13.3&#x000a0;&#x000b1;&#x000a0;0.7</td><td align="left">11.9&#x000a0;&#x000b1;&#x000a0;1.6</td><td align="left">ns (p&#x000a0;=&#x000a0;0.052)</td></tr><tr><td align="left">&#x000a0;Total score</td><td align="left">83.5&#x000a0;&#x000b1;&#x000a0;1.2</td><td align="left">67.2&#x000a0;&#x000b1;&#x000a0;5.7</td><td align="left">p&#x000a0;&#x0003c;&#x000a0;0.001</td></tr><tr><td align="left" colspan="4">Seashore test</td></tr><tr><td align="left">&#x000a0;1. Pitch</td><td align="left">46.1&#x000a0;&#x000b1;&#x000a0;2.9</td><td align="left">34.6&#x000a0;&#x000b1;&#x000a0;8.6</td><td align="left">p&#x000a0;=&#x000a0;0.001</td></tr><tr><td align="left">&#x000a0;2. Loudness</td><td align="left">45.4&#x000a0;&#x000b1;&#x000a0;1.8</td><td align="left">42.4&#x000a0;&#x000b1;&#x000a0;3.0</td><td align="left">p&#x000a0;=&#x000a0;0.011</td></tr><tr><td align="left">&#x000a0;3. Rhythm</td><td align="left">28.6&#x000a0;&#x000b1;&#x000a0;1.0</td><td align="left">25.7&#x000a0;&#x000b1;&#x000a0;3.0</td><td align="left">p&#x000a0;=&#x000a0;0.005</td></tr><tr><td align="left">&#x000a0;4. Duration of a tone</td><td align="left">45.0&#x000a0;&#x000b1;&#x000a0;2.8</td><td align="left">42.2&#x000a0;&#x000b1;&#x000a0;2.3</td><td align="left">p&#x000a0;=&#x000a0;0.029</td></tr><tr><td align="left">&#x000a0;5. Timbre</td><td align="left">42.3&#x000a0;&#x000b1;&#x000a0;3.1</td><td align="left">37.1&#x000a0;&#x000b1;&#x000a0;6.0</td><td align="left">p&#x000a0;=&#x000a0;0.043</td></tr><tr><td align="left">&#x000a0;6. Tonal memory</td><td align="left">26.0&#x000a0;&#x000b1;&#x000a0;2.3</td><td align="left">15.9&#x000a0;&#x000b1;&#x000a0;6.7</td><td align="left">p&#x000a0;=&#x000a0;0.001</td></tr><tr><td align="left">&#x000a0;Total score</td><td align="left">233.4&#x000a0;&#x000b1;&#x000a0;6.6</td><td align="left">197.9&#x000a0;&#x000b1;&#x000a0;22.7</td><td align="left">p&#x000a0;&#x0003c;&#x000a0;0.001</td></tr><tr><td align="left">Zerssen 1</td><td align="left">29.9&#x000a0;&#x000b1;&#x000a0;5.6</td><td align="left">32.8&#x000a0;&#x000b1;&#x000a0;6.8</td><td align="left">ns (p&#x000a0;=&#x000a0;0.315)</td></tr><tr><td align="left">Zerssen 2</td><td align="left">31.3&#x000a0;&#x000b1;&#x000a0;9.9</td><td align="left">32.2&#x000a0;&#x000b1;&#x000a0;6.0</td><td align="left">ns (p&#x000a0;=&#x000a0;0.393)</td></tr></tbody></table><table-wrap-foot><p>Comparison between groups by Mann&#x02013;Whitney U test</p></table-wrap-foot></table-wrap></p><sec id="Sec3"><title>Musical ability</title><p>The scores in the self-developed amusia tests and in the Seashore test are shown in Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref>. In average, the group of musicians scored 83.5&#x000a0;&#x000b1;&#x000a0;1.2 out of 86 points in the amusia test as opposed to the group of non-musicians with a score of 67.2&#x000a0;&#x000b1;&#x000a0;5.7 (p&#x000a0;&#x0003c;&#x000a0;0.001). In the Seashore test, the results were significantly different between both groups for each of the six categories. The musicians&#x02019; total score was 233.4&#x000a0;&#x000b1;&#x000a0;6.6, the non-musicians&#x02019; total score was 197.9&#x000a0;&#x000b1;&#x000a0;22.7 (p&#x000a0;&#x0003c;&#x000a0;0.001).</p></sec><sec id="Sec4"><title>Visually and auditory evoked ERP</title><p>Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref> shows the data of the visual ERP (elicited by an oddball paradigm with red light as target), Table&#x000a0;<xref rid="Tab3" ref-type="table">3</xref> shows the data of the auditory ERP (elicited by an oddball paradigm with a high tone as target), presented separately for both groups. The analysis of the visual ERP resulted in significant differences in the P3 latency and the P3 habituation (i.e., difference of P3 latency in two different trials) after the target stimuli: the P3 latency was 390&#x000a0;&#x000b1;&#x000a0;33&#x000a0;ms in the musician group and 411&#x000a0;&#x000b1;&#x000a0;22&#x000a0;ms in the non-musician group (p&#x000a0;=&#x000a0;0.043). The P3 latency habituation was 0.6&#x000a0;&#x000b1;&#x000a0;7.8&#x000a0;ms (musicians) and 7.3&#x000a0;&#x000b1;&#x000a0;11.0&#x000a0;ms (non-musicians) with a significance of p&#x000a0;=&#x000a0;0.018. The evaluation of the mean choice reaction time, the P3 amplitude, and the signals occurring after the frequent stimulus did not result in any significant differences.<table-wrap id="Tab2"><label>Table&#x000a0;2</label><caption><p>Data of visually evoked event-related potentials (oddball paradigm) recording presented separately for both subjects group</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Musicians (n&#x000a0;=&#x000a0;10)</th><th align="left">Non-musicians (n&#x000a0;=&#x000a0;10)</th><th align="left">Significance</th></tr></thead><tbody><tr><td align="left" colspan="4">Frequent stimulus</td></tr><tr><td align="left">&#x000a0;P1 latency (ms)</td><td char="&#x000b1;" align="char">122&#x000a0;&#x000b1;&#x000a0;11</td><td char="&#x000b1;" align="char">81&#x000a0;&#x000b1;&#x000a0;0</td><td align="left">ns (p&#x000a0;=&#x000a0;0.500)</td></tr><tr><td align="left">&#x000a0;N1 latency (ms)</td><td char="&#x000b1;" align="char">165&#x000a0;&#x000b1;&#x000a0;23</td><td char="&#x000b1;" align="char">169&#x000a0;&#x000b1;&#x000a0;24</td><td align="left">ns (p&#x000a0;=&#x000a0;0.604)</td></tr><tr><td align="left">&#x000a0;P2 latency (ms)</td><td char="&#x000b1;" align="char">252&#x000a0;&#x000b1;&#x000a0;14</td><td char="&#x000b1;" align="char">251&#x000a0;&#x000b1;&#x000a0;16</td><td align="left">ns (p&#x000a0;=&#x000a0;0.837)</td></tr><tr><td align="left">&#x000a0;N2 latency (ms)</td><td char="&#x000b1;" align="char">305&#x000a0;&#x000b1;&#x000a0;19</td><td char="&#x000b1;" align="char">301&#x000a0;&#x000b1;&#x000a0;18</td><td align="left">ns (p&#x000a0;=&#x000a0;0.755)</td></tr><tr><td align="left">&#x000a0;P3 latency (ms)</td><td char="&#x000b1;" align="char">394&#x000a0;&#x000b1;&#x000a0;23</td><td char="&#x000b1;" align="char">383&#x000a0;&#x000b1;&#x000a0;52</td><td align="left">ns (p&#x000a0;=&#x000a0;0.902)</td></tr><tr><td align="left" colspan="4">Infrequent stimulus</td></tr><tr><td align="left">&#x000a0;P1 latency (ms)</td><td char="&#x000b1;" align="char">94&#x000a0;&#x000b1;&#x000a0;27</td><td char="&#x000b1;" align="char">116&#x000a0;&#x000b1;&#x000a0;0</td><td align="left">ns (p&#x000a0;=&#x000a0;0.667)</td></tr><tr><td align="left">&#x000a0;N1 latency (ms)</td><td char="&#x000b1;" align="char">156&#x000a0;&#x000b1;&#x000a0;23</td><td char="&#x000b1;" align="char">168&#x000a0;&#x000b1;&#x000a0;20</td><td align="left">ns (p&#x000a0;=&#x000a0;0.243)</td></tr><tr><td align="left">&#x000a0;P2 latency (ms)</td><td char="&#x000b1;" align="char">228&#x000a0;&#x000b1;&#x000a0;9</td><td char="&#x000b1;" align="char">239&#x000a0;&#x000b1;&#x000a0;15</td><td align="left">ns (p&#x000a0;=&#x000a0;0.105)</td></tr><tr><td align="left">&#x000a0;N2 latency (ms)</td><td char="&#x000b1;" align="char">272&#x000a0;&#x000b1;&#x000a0;16</td><td char="&#x000b1;" align="char">277&#x000a0;&#x000b1;&#x000a0;15</td><td align="left">ns (p&#x000a0;=&#x000a0;0.631)</td></tr><tr><td align="left">&#x000a0;P3 latency (ms)</td><td char="&#x000b1;" align="char">390&#x000a0;&#x000b1;&#x000a0;33</td><td char="&#x000b1;" align="char">411&#x000a0;&#x000b1;&#x000a0;22</td><td align="left">p&#x000a0;=&#x000a0;0.043</td></tr><tr><td align="left">&#x000a0;P3 amplitude (&#x000b5;V)</td><td char="&#x000b1;" align="char">14&#x000a0;&#x000b1;&#x000a0;6</td><td char="&#x000b1;" align="char">12&#x000a0;&#x000b1;&#x000a0;4</td><td align="left">ns (p&#x000a0;=&#x000a0;0.253)</td></tr><tr><td align="left">&#x000a0;P3 habituation (ms)</td><td char="&#x000b1;" align="char">0.6&#x000a0;&#x000b1;&#x000a0;7.8</td><td char="&#x000b1;" align="char">7.3&#x000a0;&#x000b1;&#x000a0;11.0</td><td align="left">p&#x000a0;=&#x000a0;0.018</td></tr><tr><td align="left">Mean choice reaction time (ms)</td><td char="&#x000b1;" align="char">381&#x000a0;&#x000b1;&#x000a0;45</td><td char="&#x000b1;" align="char">405&#x000a0;&#x000b1;&#x000a0;58</td><td align="left">ns (p&#x000a0;=&#x000a0;0.436)</td></tr></tbody></table></table-wrap><table-wrap id="Tab3"><label>Table&#x000a0;3</label><caption><p>Data of auditory evoked event-related potentials (oddball paradigm) recording presented separately for both subjects group</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left"/><th align="left">Musicians (n&#x000a0;=&#x000a0;10)</th><th align="left">Non-musicians (n&#x000a0;=&#x000a0;10)</th><th align="left">Significance</th></tr></thead><tbody><tr><td align="left" colspan="4">Frequent stimulus</td></tr><tr><td align="left">&#x000a0;P1 latency (ms)</td><td char="&#x000b1;" align="char">60&#x000a0;&#x000b1;&#x000a0;2</td><td char="&#x000b1;" align="char">63&#x000a0;&#x000b1;&#x000a0;3</td><td align="left">ns (p&#x000a0;=&#x000a0;0.229)</td></tr><tr><td align="left">&#x000a0;N1 latency (ms)</td><td char="&#x000b1;" align="char">125&#x000a0;&#x000b1;&#x000a0;22</td><td char="&#x000b1;" align="char">112&#x000a0;&#x000b1;&#x000a0;6</td><td align="left">ns (p&#x000a0;=&#x000a0;0.247)</td></tr><tr><td align="left">&#x000a0;P2 latency (ms)</td><td char="&#x000b1;" align="char">229&#x000a0;&#x000b1;&#x000a0;27</td><td char="&#x000b1;" align="char">199&#x000a0;&#x000b1;&#x000a0;17</td><td align="left">p&#x000a0;=&#x000a0;0.021</td></tr><tr><td align="left">&#x000a0;N2 latency (ms)</td><td char="&#x000b1;" align="char">302&#x000a0;&#x000b1;&#x000a0;11</td><td char="&#x000b1;" align="char">259&#x000a0;&#x000b1;&#x000a0;43</td><td align="left">ns (p&#x000a0;=&#x000a0;0.190)</td></tr><tr><td align="left">&#x000a0;P3 latency (ms)</td><td char="&#x000b1;" align="char">360&#x000a0;&#x000b1;&#x000a0;29</td><td char="&#x000b1;" align="char">332&#x000a0;&#x000b1;&#x000a0;48</td><td align="left">ns (p&#x000a0;=&#x000a0;0.400)</td></tr><tr><td align="left" colspan="4">Infrequent stimulus</td></tr><tr><td align="left">&#x000a0;P1 latency (ms)</td><td char="&#x000b1;" align="char">54&#x000a0;&#x000b1;&#x000a0;5</td><td char="&#x000b1;" align="char">71&#x000a0;&#x000b1;&#x000a0;29</td><td align="left">ns (p&#x000a0;=&#x000a0;0.413)</td></tr><tr><td align="left">&#x000a0;N1 latency (ms)</td><td char="&#x000b1;" align="char">109&#x000a0;&#x000b1;&#x000a0;10</td><td char="&#x000b1;" align="char">109&#x000a0;&#x000b1;&#x000a0;9</td><td align="left">ns (p&#x000a0;=&#x000a0;0.631)</td></tr><tr><td align="left">&#x000a0;P2 latency (ms)</td><td char="&#x000b1;" align="char">171&#x000a0;&#x000b1;&#x000a0;20</td><td char="&#x000b1;" align="char">180&#x000a0;&#x000b1;&#x000a0;13</td><td align="left">ns (p&#x000a0;=&#x000a0;0.165)</td></tr><tr><td align="left">&#x000a0;N2 latency (ms)</td><td char="&#x000b1;" align="char">218&#x000a0;&#x000b1;&#x000a0;22</td><td char="&#x000b1;" align="char">230&#x000a0;&#x000b1;&#x000a0;15</td><td align="left">ns (p&#x000a0;=&#x000a0;0.123)</td></tr><tr><td align="left">&#x000a0;P3 latency (ms)</td><td char="&#x000b1;" align="char">328&#x000a0;&#x000b1;&#x000a0;34</td><td char="&#x000b1;" align="char">360&#x000a0;&#x000b1;&#x000a0;10</td><td align="left">p&#x000a0;=&#x000a0;0.019</td></tr><tr><td align="left">&#x000a0;P3 amplitude (&#x000b5;V)</td><td char="&#x000b1;" align="char">13&#x000a0;&#x000b1;&#x000a0;5</td><td char="&#x000b1;" align="char">12&#x000a0;&#x000b1;&#x000a0;4</td><td align="left">ns (p&#x000a0;=&#x000a0;0.971)</td></tr><tr><td align="left">&#x000a0;P3 habituation (ms)</td><td char="&#x000b1;" align="char">&#x02212;5.8&#x000a0;&#x000b1;&#x000a0;19.6</td><td char="&#x000b1;" align="char">17.4&#x000a0;&#x000b1;&#x000a0;11.2</td><td align="left">p&#x000a0;=&#x000a0;0.009</td></tr><tr><td align="left">Mean choice reaction time (ms)</td><td char="&#x000b1;" align="char">345&#x000a0;&#x000b1;&#x000a0;43</td><td char="&#x000b1;" align="char">349&#x000a0;&#x000b1;&#x000a0;56</td><td align="left">ns (p&#x000a0;=&#x000a0;1.000)</td></tr></tbody></table></table-wrap></p><p>The latencies in the auditory ERP showed similar differences between the two groups: the P3 latency in the musician group was 328&#x000a0;&#x000b1;&#x000a0;34&#x000a0;ms as opposed to 360&#x000a0;&#x000b1;&#x000a0;10&#x000a0;ms in the non-musician group (p&#x000a0;=&#x000a0;0.019). The P3 latency habituation differed by 23.2&#x000a0;ms between the two groups with a P3 habituation of &#x02212;5.8&#x000a0;&#x000b1;&#x000a0;19.6&#x000a0;ms in the group of musicians (p&#x000a0;=&#x000a0;0.009).</p></sec><sec id="Sec5"><title>Correlation of P3 latency and musical ability</title><p>We further calculated the correlation between the results in the Seashore test and the P3 latencies. As shown in Figs.&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> and <xref rid="Fig2" ref-type="fig">2</xref>, there was a negative correlation between the P3 latency of the visual ERP and the total score of the Seashore test (r&#x000a0;=&#x000a0;&#x02212;0.470 and p&#x000a0;=&#x000a0;0.036; Spearman-rank-coefficient), as well as between the P3 latency of the auditory ERP and the total score of the Seashore-test (r&#x000a0;=&#x000a0;&#x02212;0.434 and p&#x000a0;=&#x000a0;0.038). This means that a higher musical ability is correlated to a shorter visual and auditory P3 latency.<fig id="Fig1"><label>Fig.&#x000a0;1</label><caption><p>Correlation between P3 latency of the visual event-related potentials and the total score of the Seashore-test (r&#x000a0;=&#x000a0;&#x02212;0.470 and p&#x000a0;=&#x000a0;0.036; Spearman-rank-coefficient)</p></caption><graphic xlink:href="12868_2015_200_Fig1_HTML" id="MO1"/></fig><fig id="Fig2"><label>Fig.&#x000a0;2</label><caption><p>Correlation between P3 latency of auditory evoked event-related potentials and results in the Seashore-test (r&#x000a0;=&#x000a0;&#x02212;0.434; p&#x000a0;=&#x000a0;0.038; Spearman-rank-coefficient)</p></caption><graphic xlink:href="12868_2015_200_Fig2_HTML" id="MO2"/></fig></p></sec></sec><sec id="Sec6"><title>Discussion</title><sec id="Sec7"><title>Testing musical ability</title><p>In the amusia test, the musicians scored significantly higher than the non-musicians, except for the categories &#x02018;emotion&#x02019; and &#x02018;identification of melodies&#x02019;. The purpose of this amusia test was to rule out a clinically relevant amusia in the non-musician group. The average score of 67 is within the normal range of &#x0003e;60 [<xref ref-type="bibr" rid="CR13">13</xref>]. Therefore, the non-musician group did not have a relevant impairment of musical ability. One has to take into account that this test has a high ceiling effect and was not designed for measuring small interindividual differences in musical ability, although different categories of musical ability are tested. This explains why in two of the categories the results were not significantly different between musicians and non-musicians; and this is also the reason why we used the Seashore test results for further analysis of musical ability and the correlation analysis with the P3 latencies.</p><p>The musicians scored significantly higher in the Seashore-test. This confirms that the group of musicians has a higher musical ability than the group of non-musicians. But what are the reasons for this? Several studies have investigated the question whether a higher degree of musical ability in musicians could be a result of practice-induced cortical plasticity or an innately given talent [<xref ref-type="bibr" rid="CR14">14</xref>&#x02013;<xref ref-type="bibr" rid="CR18">18</xref>].</p><p>In two studies [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>], non-musicians who had learned to play a certain rhythmical sequence or different melodic sequences showed an increased MMN in response to rhythm or pitch incongruities. Another group of non-musicians, who had just listened to the other group practising, did not show an increased MMN response. The authors interpret this finding as a sign of practice-induced cortical plasticity. Therefore, we assume that the musicians&#x02019; higher score in the Seashore test is a result of the musical training of 14&#x000a0;&#x000b1;&#x000a0;2&#x000a0;years on average, although parts of the musical ability could also be a genetically driven talent.</p><p>It was shown that professional musicians compared to amateur and non-musicians have an increase in grey matter volume in several brain regions such as motor, visual-spatial, and especially auditory regions [<xref ref-type="bibr" rid="CR15">15</xref>]. Because of the associations found between structural differences, musician status, and practice intensity, the authors interpret their results as practice-induced adaptations of the brain. In 2009, changes induced by private keyboard lessons in young children who had no prior musical training were studied [<xref ref-type="bibr" rid="CR18">18</xref>]: the results showed that instrumental children (versus children in a control group) showed a greater size of certain motor and auditory areas after 15&#x000a0;months of training and that their outcomes in motor and melody/rhythm tests also improved significantly. Again, this supports the hypothesis of practice-induced musical skills going along with structural brain changes.</p></sec><sec id="Sec8"><title>P3 latency and musical ability</title><p>The P3 response to the target stimuli of both the visual and auditory ERP was significantly earlier in the group of musicians. This result confirms the results of previous studies [<xref ref-type="bibr" rid="CR11">11</xref>, <xref ref-type="bibr" rid="CR12">12</xref>]. An early P3 response indicates fast stimulus processing and discrimination. Thus, musicians seem to be able to discriminate faster between auditory stimuli. Considering their long and special exposition to auditory stimuli in form of practising and listening to music, this result does not seem surprising.</p><p>Even though the mechanisms that determine latency of the P3 response have not yet been fully understood, there are several studies which have shown differences in the (auditory) brain structures of musicians. Several studies suggest a practice-induced brain plasticity and thus a functional and structural difference in auditory brain areas of musicians versus non-musicians [<xref ref-type="bibr" rid="CR14">14</xref>&#x02013;<xref ref-type="bibr" rid="CR17">17</xref>, <xref ref-type="bibr" rid="CR19">19</xref>]. The fact that musicians show an earlier P3 latency than non-musicians and thus have a faster auditory stimulus processing may be associated with those results. Supporting this notion, a negative correlation between P3 latency and the years of musical training was found [<xref ref-type="bibr" rid="CR12">12</xref>].</p><p>In our study, not only the auditory P3 latency was earlier in musicians but also the visual P3 latency. Musical training and/or musical ability therefore seem to affect also the visual perceptive system. This also goes along with the results of other studies concerning the musicians&#x02019; visual abilities. It was shown that musicians outperformed non-musicians in the ability of perceptual speed, which requires quick visual information processing [<xref ref-type="bibr" rid="CR20">20</xref>]. Visual memory was also reported to be better in musicians than in non-musicians [<xref ref-type="bibr" rid="CR21">21</xref>&#x02013;<xref ref-type="bibr" rid="CR24">24</xref>]; even primary visual perception [<xref ref-type="bibr" rid="CR25">25</xref>] and somatosensory cognitive processing [<xref ref-type="bibr" rid="CR26">26</xref>] were reported to be enhanced in musicians. However, these studies used psychometric measures and did not evaluate cognitive processing in an objective way. A difference in grey matter volume in visual-spatial areas was found [<xref ref-type="bibr" rid="CR15">15</xref>], going along with other results [<xref ref-type="bibr" rid="CR27">27</xref>] indicating an improvement of visual-spatial tasks in musically trained children.</p></sec><sec id="Sec9"><title>Correlation of Seashore test results and P3 latency</title><p>In our study, we were also able to link the early P3 responses in the auditory and visual paradigms to the results of the Seashore-test and found a negative correlation between the data. In studies on musicians, a musician is usually defined as a subject who has learned to play an instrument for a certain amount of years and musicians can be classified as &#x02018;professional&#x02019; or &#x02018;amateur&#x02019;. These definitions usually are the criteria for the participation of musicians in studies, but having had music lessons for a certain amount of years does not necessarily yield in a high musical ability. With our results, we showed that not just the status &#x02018;musicianship&#x02019;, but the amount of musical ability as measured by a psychometric test is related to the improved cognitive processing of musicians versus non-musicians.</p><p>All in all, people with high musical ability seem to have a faster auditory and visual cognitive processing. The question is, however, whether this connection between musical ability and cognitive processing is inherited or whether the acquisition of musical ability (i.e. long-term practice of an instrument) leads to an enhancement of cognitive processing. At this time, one can only speculate about the answer: on the one hand, fast cognitive processing is probably helpful for learning an instrument, which requires fast interaction of auditory, motor, and visual stimuli. One could even conjecture that musical ability is a congenital ability of cognitive processing. Some studies have shown evidence that the conditions upon which musical ability develops are innately predetermined. Hassler for example showed that a certain androgynous level of testosterone is characteristic of musicians, and that differences between musicians and non-musicians are possibly formed prenatally under the influence of hormones [<xref ref-type="bibr" rid="CR28">28</xref>].</p><p>On the other hand it also seems plausible that by practicing an instrument the processing of all these stimuli becomes faster, which then might lead to the improvement of auditory and visual abilities, as shown in the studies mentioned above. In an MEG study, an enhanced auditory evoked magnetic field response concerning violin tones was shown in children who had been musically trained for 1&#x000a0;year [<xref ref-type="bibr" rid="CR29">29</xref>]. There has also been a study not connected to music, which showed alterations in adults&#x02019; ERP in response to an auditory discrimination task [<xref ref-type="bibr" rid="CR30">30</xref>]. Hence, it has been shown before that training can have an influence on stimulus processing and therefore it is plausible that musical training which leads to a higher amount of musical ability could have an effect on auditive and visual processing [<xref ref-type="bibr" rid="CR31">31</xref>, <xref ref-type="bibr" rid="CR32">32</xref>].</p><p>All in all we suppose that there might be certain inherited conditions such as fast cognitive processing upon which musical ability develops but that a stimulating environment as well as long-term musical practice also leads to an improvement of cognitive processing and/or aptitude. This is also important for disturbances of cognition e.g. after stroke, after brain injury, or in different types of amusia [<xref ref-type="bibr" rid="CR33">33</xref>, <xref ref-type="bibr" rid="CR34">34</xref>].</p></sec><sec id="Sec10"><title>P3 latency habituation</title><p>In our study, we calculated the P3 latency habituation and found that musicians showed a habituation for both the visual and the auditory latencies close to zero, whereas in non-musicians it was significantly higher. There is evidence that, in normal subjects, the visual and auditory P3 latency increases over trial blocks [<xref ref-type="bibr" rid="CR35">35</xref>&#x02013;<xref ref-type="bibr" rid="CR38">38</xref>]. A loss of habituation in the visual P3 latency of migraine patients during the migraine interval was shown [<xref ref-type="bibr" rid="CR37">37</xref>], similar to our findings of a loss of habituation in musicians. We believe that the loss of habituation and the generally decreased P3 latency in musicians indicate that musicians have a remarkable cognitive processing with the ability of keeping the processing of stimuli faster for a longer time than normal subjects. This could be an indicator of an improved working memory in musicians, as it has been reported by some authors [<xref ref-type="bibr" rid="CR12">12</xref>, <xref ref-type="bibr" rid="CR39">39</xref>, <xref ref-type="bibr" rid="CR40">40</xref>]. Keeping the results from migraine patients in mind, it would be interesting to study whether in musicians a similar effect like the normalization of the habituation during a migraine attack could be observed after an interval of increased alertness.</p><p>A loss of cognitive habituation (or higher cognitive excitability) also means that stimuli on different levels might be processed faster and more accurate for a certain amount of time. This can be regarded as an advantage for musicians, e.g. when playing in an orchestra or playing both complex rhythmic and complex melodic music.</p></sec><sec id="Sec11"><title>Limitations</title><p>Our study has some limitations which have to be considered when interpreting our results. First of all, the concept of musical ability is still under discussion. There is no clear definition and no commonly accepted measure to evaluate musical ability. The sub-domains of musical ability as measured in both the Seashore test and the amusia test only include some aspects of musical ability which are commonly accepted as basic skills of musical ability (e.g., rhythm, loudness, pitch, duration of a tone, tonal memory); other aspects such as creativity, emotional perception of music, the ability of interpreting music etc. are not included because these aspects are hard to measure in an objective way. Nonetheless, they determine the amount of one&#x02019;s musical ability. We accept that our study did not comprise all aspects of musical ability.</p><p>A second problem is the procedure of testing musical ability. The test results depend strongly on the cooperation and motivation of the subjects, which in turn is hard to evaluate. This leads to a reduced objectivity of the testing of musical ability.</p><p>Third, when looking at the P3 latency results one has to consider that they only apply to our testing range. Since we looked at P3 latencies that were within in the normal range and only included healthy subjects one cannot transfer the results of the correlation analysis to subjects with pathological P3 latencies, i.e. pathological P3 latencies certainly do not yield in a total lack of musical ability.</p><p>Fourth, it is not clear whether or to which extent a decreased P3 latency has an impact on everyday life. A decreased P3 latency implies a faster cognitive processing. Some authors suggest an improved working memory, but there is still an ongoing discussion about this (e.g., [<xref ref-type="bibr" rid="CR12">12</xref>]).</p></sec></sec><sec id="Sec12"><title>Conclusion</title><p>Our most important finding is that measures in tests of musical ability are associated with decreased latencies in auditory and visual ERP suggesting that musical ability is associated with a general enhancement of cognitive processing.</p><p>Regarding the auditory P3 latency, we were able to reproduce findings of previous studies [<xref ref-type="bibr" rid="CR1">1</xref>&#x02013;<xref ref-type="bibr" rid="CR5">5</xref>]. Additionally, we were able to show a significant correlation between the level of musical ability as measured by the Seashore test and both the visual and the auditory P3 latency. Also, a significant difference in habituation of the visual and auditory P3 latencies between non-musicians and musicians could be observed. These results cannot be attributed to a different mental state of the two groups, as this would have lead to significantly different results between the two groups in the Zerssen self-rating Scale.</p></sec><sec id="Sec13" sec-type="materials|methods"><title>Methods</title><sec id="Sec14"><title>Participants</title><p>We compared a group of musicians (N&#x000a0;=&#x000a0;10; 5 male) to a group of non-musicians (N&#x000a0;=&#x000a0;10; 5 male). The mean age of the two groups was 23&#x000a0;&#x000b1;&#x000a0;2 and 24&#x000a0;&#x000b1;&#x000a0;2&#x000a0;years, respectively. Musicians were defined by having received at least 10&#x000a0;years of private music lessons (mean 14&#x000a0;&#x000b1;&#x000a0;2&#x000a0;years) and being active musicians (i.e., members of orchestras, chamber music groups, or choirs) at the time of the study. The non-musician group had no or very few (less than 2&#x000a0;years) music lessons in their lives. Exclusion criteria for the participation in the study were psychiatric or neurological disorders including migraine and epilepsy and medication on a regular basis except for oral contraceptives. Consumption of alcohol, nicotine, or caffeine was not allowed on the day of the experiment.</p><p>The experiment was always performed in the afternoon in a room without daylight. The room temperature was always the same. For the last part of the experiment, the recording of the ERP, the lights were turned off. All participants gave written informed consent. The study was approved by the local ethics committee.</p></sec><sec id="Sec15"><title>Psychometric testing</title><p>In the beginning, the participants had to complete the Zerssen self-rating scale [<xref ref-type="bibr" rid="CR41">41</xref>]. The Zerssen scale measures the actual mental well-being with a score between 0 and 56. In the validation sample, a mean score of 12&#x000a0;&#x000b1;&#x000a0;10 was described for healthy subjects. Only subjects with a score within the normal mean plus/minus one standard deviation in both measures were included in the study. Feeling mentally not well would impair the results of neuropsychological testing in an unappropriate way.</p><p>Then, two tests of musical ability were conducted. The first one was a test on amusia developed by the authors [<xref ref-type="bibr" rid="CR13">13</xref>]. In this test, the participants had to perform different tasks in the following five different categories: (1) production of rhythm/metrum by repeating different rhythms (knocking with a pin; (2) comparison of melodies (listening to two short melodies and deciding whether they are different or not); (3)emotional impression of music (listening to short pieces of new music which had to be categorized as happy, angry, frightening etc.; the impression could be said to the examiner or shown by different pictures showing the emotion); (4) pitch (comparison of two tones and deciding whether they have the same pitch or a different pitch); (5) identification of 14 commonly known melodies such as &#x0201c;Fr&#x000e8;re Jaques&#x0201d; or &#x0201c;Yesterday&#x0201d;. The maximum score of this test is 86 points, the higher the score the better the musical ability. This test was originally designed to detect amusia in neurological patients. It has a high ceiling effect, which means that a score of less than 90&#x000a0;% of the maximum denotes a relevant impairment. Therefore, the test is or poor value to detect small differences between individuals.</p><p>In order to evaluate the subjects&#x02019; musical ability in a previously designed test, we used the &#x0201c;Seashore test for Musical Ability&#x0201d; [<xref ref-type="bibr" rid="CR42">42</xref>] as a second test. It contains six different categories: (1) pitch; (2) loudness; (3) rhythm; (4) duration of a tone; (5) timbre; (6) tonal memory. The maximum score is 260. The subjects have to differentiate between small changes in pitch, loudness, rhythm etc. In the category pitch, for example, 50 pairs of tones are presented, differing in frequency from/between 17 and 2&#x000a0;Hz. The subjects are asked whether the second tone is lower or higher in frequency than the first. This test shows a nearly parametric distribution of scores and has no defined scores for amusia.</p></sec><sec id="Sec16"><title>ERP recording</title><p>The second part of the experiment was the recording of visually and auditory evoked ERP. The subjects had to sit in a comfortable chair in a dark room. For the visually evoked ERP the subjects were looking at a 30&#x000a0;cm&#x000a0;&#x000d7;&#x000a0;30&#x000a0;cm video screen, standing approximately 150&#x000a0;cm in front of them. Two trains of 200 flashes of light each with a 3&#x000a0;min break in between the trains were presented in a random order. We used 15&#x000a0;% red (target) and 85&#x000a0;% white (non-target) flashes of light. The duration of a single flash was 100&#x000a0;ms and the interval between two flashes was 1800&#x000a0;ms. Subjects were asked to press a button with their dominant hand whenever they observed a red flash. For the auditory evoked ERP, two trains of 200 tones each (3&#x000a0;min break between the two trains) were presented to the subjects. The target tones (15&#x000a0;%) had a pitch of 600&#x000a0;Hz, the non-target tones had a pitch of 325&#x000a0;Hz, they were also randomly mixed. Again, the subjects had to press a button whenever a target stimulus occurred. The duration of a tone was 100&#x000a0;ms, and the interval between two stimuli was 1800&#x000a0;ms.</p><p>In both ERP measurements (auditory and visual), the EEG was recorded by an amplifier using Ag/AgCl surface electrodes, which were placed at centroparietal (Pz), centrocentral (Cz), and frontocentral (Fz) (=recording electrodes) according to the international 10&#x02013;20 system. They were linked to the mastoid (=reference electrode). EOG was also registered in order to exclude EEG periods with eye movement artifacts from the ensuing averaging process. A high-frequency filter was set at 70&#x000a0;Hz and a low-frequency filter at 0.1&#x000a0;Hz. The EEG was stored digitally. EEG periods of 300&#x000a0;ms before and 1100&#x000a0;ms after onset of the stimulus were averaged separately for the target and non-target stimuli.</p><p>The evaluation of the ERP latencies was performed by a physician who did not conduct the experiment and who did not know which subjects were musicians and which ones were not. The components of the ERP following the red/high and white/low stimuli were evaluated. We determined the latencies of the P1, N1, P2, N2, and P3 components and the amplitude of the P3 component, further we measured the mean choice reaction time (i.e., the time between onset of the target stimulus and pressing of the button) according to international recommendations [<xref ref-type="bibr" rid="CR19">19</xref>]. For both the visual and the auditory ERP, the curves of the first and of the second train (200 stimuli), separated in target and non-target stimuli, were averaged and then the latencies, the P3 amplitude and the mean choice reaction time were measured. By calculating the difference of P3 latency between the first and the second train, the P3 habituation could also be evaluated. The P3 component of the ERP was chosen as the main parameter since it is associated with endogenous (mainly stimulus independent) cognitive processing whereas the P2 and the N2 components are exogenous (i.e., mainly dependent from the physical properties of the stimulus).</p></sec><sec id="Sec17"><title>Statistical analysis</title><p>We used non-parametric tests to analyze the correlation between the different test scores and the ERP parameters and to analyze group differences between musicians and non-musicians. For correlation analysis, the Spearman rank coefficient was calculated. For group comparisons, we used the Mann&#x02013;Whitney U test. Multiple comparisons were corrected by Bonferroni correction. All calculations were performed by the program SPSS version 18.0. Significance level was set at p&#x000a0;=&#x000a0;0.05.</p></sec></sec></body><back><ack><title>Authors&#x02019; contributions</title><p>All authors contributed to the design of the study, to the drafting of the manuscript and to the statistical analysis and discussion. SE and CF conducted the experiments. All authors read and approved the final manuscript.</p><sec id="d30e1243"><title>Acknowledgements</title><p>There was no funding and no other sources of support for this manuscript.</p></sec><sec id="d30e1248"><title>Compliance with ethical guidelines</title><p><bold>Competing interests</bold> The authors declare that they have no competing interests.</p></sec></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klein</surname><given-names>M</given-names></name><name><surname>Coles</surname><given-names>MGH</given-names></name><name><surname>Donchin</surname><given-names>E</given-names></name></person-group><article-title>People with absolute pitch process tones without producing a P300</article-title><source>Science</source><year>1984</year><volume>223</volume><fpage>1306</fpage><lpage>1309</lpage><pub-id pub-id-type="doi">10.1126/science.223.4642.1306</pub-id><?supplied-pmid 17759367?><pub-id pub-id-type="pmid">17759367</pub-id></element-citation></ref><ref id="CR2"><label>2.</label><mixed-citation publication-type="other">Sch&#x000fc;tz K. P300 bei Musikern mit und ohne absolutes Geh&#x000f6;rt im Vergleich zu zwei Kontrollgruppen. Med Diss Freiburg 1988.</mixed-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hantz</surname><given-names>E</given-names></name><name><surname>Crummer</surname><given-names>G</given-names></name><name><surname>Wayman</surname><given-names>J</given-names></name><name><surname>Walton</surname><given-names>J</given-names></name><name><surname>Frisina</surname><given-names>R</given-names></name></person-group><article-title>Effects of musical training and absolute pitch on the neural processing of melodic intervals: a P3 event-related potential study</article-title><source>Music Percept</source><year>1992</year><volume>10</volume><fpage>25</fpage><lpage>42</lpage><pub-id pub-id-type="doi">10.2307/40285536</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hantz</surname><given-names>EC</given-names></name><name><surname>Kreilick</surname><given-names>KG</given-names></name><name><surname>Kananen</surname><given-names>W</given-names></name><name><surname>Swartz</surname><given-names>KP</given-names></name></person-group><article-title>Neural responses to melodic and harmonic closure: an event-related potential-study</article-title><source>Music Percept</source><year>1997</year><volume>15</volume><fpage>69</fpage><lpage>98</lpage><pub-id pub-id-type="doi">10.2307/40285739</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wayman</surname><given-names>JW</given-names></name><name><surname>Frisina</surname><given-names>RD</given-names></name><name><surname>Walton</surname><given-names>JP</given-names></name><name><surname>Hantz</surname><given-names>EC</given-names></name><name><surname>Crummer</surname><given-names>GC</given-names></name></person-group><article-title>Effects of musical training and absolute pitch ability on event-related activity in response to sine tones</article-title><source>J Acoust Soc Am</source><year>1992</year><volume>34</volume><fpage>131</fpage><lpage>156</lpage></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Crummer</surname><given-names>GC</given-names></name><name><surname>Walton</surname><given-names>JP</given-names></name><name><surname>Wayman</surname><given-names>JW</given-names></name><name><surname>Hantz</surname><given-names>EC</given-names></name><name><surname>Frisina</surname><given-names>RD</given-names></name></person-group><article-title>Neural processing of musical timbre by musicians, nonmusicians and musicians possessing absolute pitch</article-title><source>J Acoust Soc Am</source><year>1994</year><volume>95</volume><fpage>2720</fpage><lpage>2727</lpage><pub-id pub-id-type="doi">10.1121/1.409840</pub-id><?supplied-pmid 8207143?><pub-id pub-id-type="pmid">8207143</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levett</surname><given-names>C</given-names></name><name><surname>Martin</surname><given-names>F</given-names></name></person-group><article-title>The relationship between complex music stimuli and the late components of the event-related potential</article-title><source>Psychomusicology</source><year>1992</year><volume>11</volume><fpage>125</fpage><lpage>140</lpage><pub-id pub-id-type="doi">10.1037/h0094126</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baribeau</surname><given-names>J</given-names></name><name><surname>Roth</surname><given-names>RM</given-names></name><name><surname>Velikonja</surname><given-names>K</given-names></name></person-group><article-title>Auditory brain potentials in musicians: effects of attention, task difficulty, and ear of stimulation</article-title><source>Brain Cogn</source><year>1996</year><volume>32</volume><fpage>296</fpage><lpage>299</lpage></element-citation></ref><ref id="CR9"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nikjeh</surname><given-names>DA</given-names></name><name><surname>Lister</surname><given-names>JJ</given-names></name><name><surname>Frisch</surname><given-names>SA</given-names></name></person-group><article-title>Hearing of a note: an electrophysiologic and psychoacoustic comparison of pitch discrimination between vocal and instrumental musicians</article-title><source>Psychophysiology</source><year>2008</year><volume>45</volume><fpage>994</fpage><lpage>1007</lpage><pub-id pub-id-type="doi">10.1111/j.1469-8986.2008.00689.x</pub-id><?supplied-pmid 18778322?><pub-id pub-id-type="pmid">18778322</pub-id></element-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Barnea</surname><given-names>A</given-names></name><name><surname>Granot</surname><given-names>R</given-names></name><name><surname>Pratt</surname><given-names>H</given-names></name></person-group><article-title>Absolute pitch&#x02014;electrophysiological evidence</article-title><source>Int J Psychophysiol</source><year>1994</year><volume>16</volume><fpage>29</fpage><lpage>38</lpage><pub-id pub-id-type="doi">10.1016/0167-8760(94)90039-6</pub-id><?supplied-pmid 8206802?><pub-id pub-id-type="pmid">8206802</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Evers</surname><given-names>S</given-names></name></person-group><source>Musikperzeption und visuelle Reizverarbeitung</source><year>2003</year><publisher-loc>Aachen</publisher-loc><publisher-name>Shaker Verlag</publisher-name></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>George</surname><given-names>EM</given-names></name><name><surname>Coch</surname><given-names>D</given-names></name></person-group><article-title>Music training and working memory: an ERP study</article-title><source>Neuropsychologia</source><year>2011</year><volume>49</volume><fpage>1083</fpage><lpage>1094</lpage><pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2011.02.001</pub-id><?supplied-pmid 21315092?><pub-id pub-id-type="pmid">21315092</pub-id></element-citation></ref><ref id="CR13"><label>13.</label><mixed-citation publication-type="other">Lorenz C. Entwicklung eines klinischen Musikalit&#x000e4;tstests: Normwerte, klinischer Einsatz und Vergleich von Patienten mit Hirninfarkten. Med Diss M&#x000fc;nster. 2000.</mixed-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pantev</surname><given-names>C</given-names></name><name><surname>Oostenveld</surname><given-names>R</given-names></name><name><surname>Engelien</surname><given-names>A</given-names></name><name><surname>Ross</surname><given-names>B</given-names></name><name><surname>Roberts</surname><given-names>LE</given-names></name><name><surname>Hoke</surname><given-names>M</given-names></name></person-group><article-title>Increased auditory cortical representation in musicians</article-title><source>Nature</source><year>1998</year><volume>392</volume><fpage>811</fpage><lpage>814</lpage><pub-id pub-id-type="doi">10.1038/33918</pub-id><?supplied-pmid 9572139?><pub-id pub-id-type="pmid">9572139</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gaser</surname><given-names>C</given-names></name><name><surname>Schlaug</surname><given-names>G</given-names></name></person-group><article-title>Brain structures differ between musicians and non-musicians</article-title><source>J Neurosci</source><year>2003</year><volume>23</volume><fpage>9240</fpage><lpage>9245</lpage><?supplied-pmid 14534258?><pub-id pub-id-type="pmid">14534258</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lappe</surname><given-names>C</given-names></name><name><surname>Herholz</surname><given-names>S</given-names></name><name><surname>Trainor</surname><given-names>L</given-names></name><name><surname>Pantev</surname><given-names>C</given-names></name></person-group><article-title>Cortical plasticity induced by short-term unimodal and multimodal musical training</article-title><source>J Neurosci</source><year>2008</year><volume>28</volume><fpage>9632</fpage><lpage>9639</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.2254-08.2008</pub-id><?supplied-pmid 18815249?><pub-id pub-id-type="pmid">18815249</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lappe</surname><given-names>C</given-names></name><name><surname>Trainor</surname><given-names>L</given-names></name><name><surname>Herholz</surname><given-names>S</given-names></name><name><surname>Pantev</surname><given-names>C</given-names></name></person-group><article-title>Cortical plasticity induced by short-term multimodal musical rhythm training</article-title><source>PLoS One</source><year>2011</year><volume>6</volume><fpage>21493</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0021493</pub-id></element-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hyde</surname><given-names>KL</given-names></name><name><surname>Lerch</surname><given-names>J</given-names></name><name><surname>Norton</surname><given-names>A</given-names></name><name><surname>Forgeard</surname><given-names>M</given-names></name><name><surname>Winner</surname><given-names>E</given-names></name><name><surname>Evans</surname><given-names>AC</given-names></name><name><surname>Schlaug</surname><given-names>G</given-names></name></person-group><article-title>Musical training shapes structural brain development</article-title><source>J Neurosci</source><year>2009</year><volume>29</volume><fpage>3019</fpage><lpage>3025</lpage><pub-id pub-id-type="doi">10.1523/JNEUROSCI.5118-08.2009</pub-id><?supplied-pmid 19279238?><pub-id pub-id-type="pmid">19279238</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goodin</surname><given-names>D</given-names></name><name><surname>Desmedt</surname><given-names>J</given-names></name><name><surname>Maurer</surname><given-names>K</given-names></name><name><surname>Nuwer</surname><given-names>MR</given-names></name></person-group><article-title>IFCN recommended standards for long-latency auditory event-related potentials. Report of an IFCN committee. International Federation of Clinical Neurophysiology</article-title><source>Electroencephalogr Clin Neurophysiol</source><year>1994</year><volume>91</volume><fpage>18</fpage><lpage>20</lpage><pub-id pub-id-type="doi">10.1016/0013-4694(94)90014-0</pub-id><?supplied-pmid 7517840?><pub-id pub-id-type="pmid">7517840</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Helmbold</surname><given-names>N</given-names></name><name><surname>Rammsayer</surname><given-names>T</given-names></name><name><surname>Altenm&#x000fc;ller</surname><given-names>E</given-names></name></person-group><article-title>Differences in primary mental abilities between musicians and nonmusicians</article-title><source>J Individ Differ</source><year>2005</year><volume>26</volume><fpage>74</fpage><lpage>85</lpage><pub-id pub-id-type="doi">10.1027/1614-0001.26.2.74</pub-id></element-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zafranas</surname><given-names>N</given-names></name></person-group><article-title>Piano keyboard training and the spatial-temporal development of young children attending kindergarten classes in Greece</article-title><source>Early Child Dev Care</source><year>2004</year><volume>174</volume><fpage>199</fpage><lpage>211</lpage><pub-id pub-id-type="doi">10.1080/0300443032000153534</pub-id></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kalakoski</surname><given-names>V</given-names></name></person-group><article-title>Effect of skill level on recall of visually presented patterns of musical notes</article-title><source>Scand J Psychol</source><year>2007</year><volume>48</volume><fpage>87</fpage><lpage>96</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9450.2007.00535.x</pub-id><?supplied-pmid 17430362?><pub-id pub-id-type="pmid">17430362</pub-id></element-citation></ref><ref id="CR23"><label>23.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bugos</surname><given-names>J</given-names></name><name><surname>Perlstein</surname><given-names>W</given-names></name><name><surname>McCrae</surname><given-names>C</given-names></name><name><surname>Brophy</surname><given-names>T</given-names></name><name><surname>Bedenbaugh</surname><given-names>P</given-names></name></person-group><article-title>Individualized piano instruction enhances executive functioning and working memory in older adults</article-title><source>Aging Ment Health</source><year>2007</year><volume>11</volume><fpage>464</fpage><lpage>471</lpage><pub-id pub-id-type="doi">10.1080/13607860601086504</pub-id><?supplied-pmid 17612811?><pub-id pub-id-type="pmid">17612811</pub-id></element-citation></ref><ref id="CR24"><label>24.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jakobson</surname><given-names>L</given-names></name><name><surname>Cuddy</surname><given-names>L</given-names></name><name><surname>Kilgour</surname><given-names>A</given-names></name></person-group><article-title>Time tagging: a key to musicians&#x02019; superior memory</article-title><source>Music Percept</source><year>2003</year><volume>20</volume><fpage>307</fpage><lpage>313</lpage><pub-id pub-id-type="doi">10.1525/mp.2003.20.3.307</pub-id></element-citation></ref><ref id="CR25"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jomori</surname><given-names>I</given-names></name><name><surname>Hoshiyama</surname><given-names>M</given-names></name><name><surname>Uemura</surname><given-names>J</given-names></name><name><surname>Nakagawa</surname><given-names>Y</given-names></name><name><surname>Hoshino</surname><given-names>A</given-names></name><name><surname>Iwamoto</surname><given-names>Y</given-names></name></person-group><article-title>Effects of emotional music on visual processes in inferior temporal area</article-title><source>Cogn Neurosci</source><year>2013</year><volume>4</volume><fpage>21</fpage><lpage>30</lpage><pub-id pub-id-type="doi">10.1080/17588928.2012.751366</pub-id><?supplied-pmid 24073696?><pub-id pub-id-type="pmid">24073696</pub-id></element-citation></ref><ref id="CR26"><label>26.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pantev</surname><given-names>C</given-names></name><name><surname>Lappe</surname><given-names>C</given-names></name><name><surname>Herholz</surname><given-names>SC</given-names></name><name><surname>Trainor</surname><given-names>L</given-names></name></person-group><article-title>Auditory-somatosensory integration and cortical plasticity in musical training</article-title><source>Ann N Y Acad Sci</source><year>2009</year><volume>1169</volume><fpage>143</fpage><lpage>150</lpage><pub-id pub-id-type="doi">10.1111/j.1749-6632.2009.04588.x</pub-id><?supplied-pmid 19673770?><pub-id pub-id-type="pmid">19673770</pub-id></element-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hetland</surname><given-names>L</given-names></name></person-group><article-title>Learning to make music enhances spatial reasoning</article-title><source>J Aesthet Educ</source><year>2000</year><volume>34</volume><fpage>179</fpage><lpage>238</lpage><pub-id pub-id-type="doi">10.2307/3333643</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hassler</surname><given-names>M</given-names></name></person-group><article-title>Music medicine. A neurobiological approach</article-title><source>Neuro Endocrinol Lett</source><year>2000</year><volume>21</volume><fpage>101</fpage><lpage>106</lpage><?supplied-pmid 11455337?><pub-id pub-id-type="pmid">11455337</pub-id></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fujioka</surname><given-names>T</given-names></name><name><surname>Ross</surname><given-names>B</given-names></name><name><surname>Kakigi</surname><given-names>R</given-names></name><name><surname>Pantev</surname><given-names>C</given-names></name><name><surname>Trainor</surname><given-names>LJ</given-names></name></person-group><article-title>One year of musical training affects development of auditory cortical-evoked fields in young children</article-title><source>Brain</source><year>2006</year><volume>129</volume><fpage>2593</fpage><lpage>2608</lpage><pub-id pub-id-type="doi">10.1093/brain/awl247</pub-id><?supplied-pmid 16959812?><pub-id pub-id-type="pmid">16959812</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reinke</surname><given-names>KS</given-names></name><name><surname>He</surname><given-names>Y</given-names></name><name><surname>Wang</surname><given-names>C</given-names></name><name><surname>Alain</surname><given-names>C</given-names></name></person-group><article-title>Perceptual learning modulates sensory evoked response during vowel segregation</article-title><source>Brain Res Cogn Brain Res</source><year>2003</year><volume>17</volume><fpage>781</fpage><lpage>791</lpage><pub-id pub-id-type="doi">10.1016/S0926-6410(03)00202-7</pub-id><?supplied-pmid 14561463?><pub-id pub-id-type="pmid">14561463</pub-id></element-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno</surname><given-names>S</given-names></name><name><surname>Bialystok</surname><given-names>E</given-names></name><name><surname>Barac</surname><given-names>R</given-names></name><name><surname>Schellenberg</surname><given-names>EG</given-names></name><name><surname>Cepeda</surname><given-names>NJ</given-names></name><name><surname>Chau</surname><given-names>T</given-names></name></person-group><article-title>Short-term music training enhances verbal intelligence and executive function</article-title><source>Psychol Sci</source><year>2011</year><volume>22</volume><fpage>1425</fpage><lpage>1433</lpage><pub-id pub-id-type="doi">10.1177/0956797611416999</pub-id><?supplied-pmid 21969312?><pub-id pub-id-type="pmid">21969312</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moreno</surname><given-names>S</given-names></name><name><surname>Wodniecka</surname><given-names>Z</given-names></name><name><surname>Tays</surname><given-names>W</given-names></name><name><surname>Alain</surname><given-names>C</given-names></name><name><surname>Bialystok</surname><given-names>E</given-names></name></person-group><article-title>Inhibitory control in bilinguals and musicians: event related potential (ERP) evidence for experience-specific effects</article-title><source>PLoS One</source><year>2014</year><volume>9</volume><fpage>e94169</fpage><pub-id pub-id-type="doi">10.1371/journal.pone.0094169</pub-id><?supplied-pmid 24743321?><pub-id pub-id-type="pmid">24743321</pub-id></element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>MC</given-names></name><name><surname>Tsai</surname><given-names>PL</given-names></name><name><surname>Huang</surname><given-names>YT</given-names></name><name><surname>Lin</surname><given-names>KC</given-names></name></person-group><article-title>Pleasant music improves visual attention in patients with unilateral neglect after stroke</article-title><source>Brain Inj</source><year>2013</year><volume>27</volume><fpage>75</fpage><lpage>82</lpage><pub-id pub-id-type="doi">10.3109/02699052.2012.722255</pub-id><?supplied-pmid 23252438?><pub-id pub-id-type="pmid">23252438</pub-id></element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schlesiger</surname><given-names>C</given-names></name><name><surname>Evers</surname><given-names>S</given-names></name></person-group><article-title>Amusien</article-title><source>Nervenheilkunde</source><year>2013</year><volume>32</volume><fpage>675</fpage><lpage>680</lpage></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lammers</surname><given-names>W</given-names></name><name><surname>Badia</surname><given-names>C</given-names></name></person-group><article-title>Habituation of P300 to target stimuli</article-title><source>Psychol Behav</source><year>1989</year><volume>45</volume><fpage>595</fpage><lpage>601</lpage></element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geisler</surname><given-names>M</given-names></name><name><surname>Polich</surname><given-names>J</given-names></name></person-group><article-title>P300 habituation from visual stimuli?</article-title><source>Physiol Behav</source><year>1994</year><volume>56</volume><fpage>511</fpage><lpage>516</lpage><pub-id pub-id-type="doi">10.1016/0031-9384(94)90294-1</pub-id><?supplied-pmid 7972401?><pub-id pub-id-type="pmid">7972401</pub-id></element-citation></ref><ref id="CR37"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evers</surname><given-names>S</given-names></name><name><surname>Bauer</surname><given-names>B</given-names></name><name><surname>Suhr</surname><given-names>B</given-names></name><name><surname>Husstedt</surname><given-names>IW</given-names></name><name><surname>Grotemeyer</surname><given-names>KH</given-names></name></person-group><article-title>Cognitive processing in primary headache: a study on event-related potentials</article-title><source>Neurology</source><year>1997</year><volume>48</volume><fpage>108</fpage><lpage>113</lpage><pub-id pub-id-type="doi">10.1212/WNL.48.1.108</pub-id><?supplied-pmid 9008504?><pub-id pub-id-type="pmid">9008504</pub-id></element-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pan</surname><given-names>J</given-names></name><name><surname>Takeshita</surname><given-names>T</given-names></name><name><surname>Morimoto</surname><given-names>K</given-names></name></person-group><article-title>P300 habituation from auditory single-stimulus and oddball paradigms</article-title><source>Int J Psychophysiol</source><year>2000</year><volume>37</volume><fpage>149</fpage><lpage>153</lpage><pub-id pub-id-type="doi">10.1016/S0167-8760(00)00086-6</pub-id><?supplied-pmid 10832001?><pub-id pub-id-type="pmid">10832001</pub-id></element-citation></ref><ref id="CR39"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gunter</surname><given-names>T</given-names></name><name><surname>Schmidt</surname><given-names>BH</given-names></name><name><surname>Besson</surname><given-names>M</given-names></name></person-group><article-title>Let&#x02019;s face the music: a behavioral and electrophysiological exploration of score reading</article-title><source>Psychophysiology</source><year>2003</year><volume>40</volume><fpage>742</fpage><lpage>751</lpage><pub-id pub-id-type="doi">10.1111/1469-8986.00074</pub-id><?supplied-pmid 14696727?><pub-id pub-id-type="pmid">14696727</pub-id></element-citation></ref><ref id="CR40"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>Y</given-names></name><name><surname>Lu</surname><given-names>M</given-names></name><name><surname>Ko</surname><given-names>H</given-names></name></person-group><article-title>Effects of skill training on working memory capacity</article-title><source>Learn Instr</source><year>2007</year><volume>17</volume><fpage>336</fpage><lpage>344</lpage><pub-id pub-id-type="doi">10.1016/j.learninstruc.2007.02.010</pub-id></element-citation></ref><ref id="CR41"><label>41.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>von Zerssen</surname><given-names>D</given-names></name></person-group><source>Die Befindlichkeitsskala-Skala: Manual</source><year>1976</year><publisher-loc>Weinheim</publisher-loc><publisher-name>Beltz Test</publisher-name></element-citation></ref><ref id="CR42"><label>42.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Lewis</surname><given-names>D</given-names></name><name><surname>Saetveit</surname><given-names>J</given-names></name></person-group><source>Seashore Measures of Musical Talent&#x02019;s Manual (Revised)</source><year>1960</year><publisher-loc>New York</publisher-loc><publisher-name>Psychological Corporation</publisher-name></element-citation></ref></ref-list></back></article>