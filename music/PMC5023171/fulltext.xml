<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1 20151215//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD JATS (Z39.96) Journal Publishing DTD v1.1d3 20150301//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName JATS-journalpublishing1.dtd?><?SourceDTD.Version 39.96?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 1?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS Biol</journal-id><journal-id journal-id-type="iso-abbrev">PLoS Biol</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosbiol</journal-id><journal-title-group><journal-title>PLoS Biology</journal-title></journal-title-group><issn pub-type="ppub">1544-9173</issn><issn pub-type="epub">1545-7885</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">5023171</article-id><article-id pub-id-type="pmid">27627738</article-id><article-id pub-id-type="doi">10.1371/journal.pbio.2000106</article-id><article-id pub-id-type="publisher-id">pbio.2000106</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject><subj-group><subject>Fear</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject><subj-group><subject>Fear</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Brain Mapping</subject><subj-group><subject>Functional Magnetic Resonance Imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Diagnostic Medicine</subject><subj-group><subject>Diagnostic Radiology</subject><subj-group><subject>Magnetic Resonance Imaging</subject><subj-group><subject>Functional Magnetic Resonance Imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject><subj-group><subject>Diagnostic Radiology</subject><subj-group><subject>Magnetic Resonance Imaging</subject><subj-group><subject>Functional Magnetic Resonance Imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Radiology and Imaging</subject><subj-group><subject>Diagnostic Radiology</subject><subj-group><subject>Magnetic Resonance Imaging</subject><subj-group><subject>Functional Magnetic Resonance Imaging</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional Magnetic Resonance Imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject><subj-group><subject>Functional Magnetic Resonance Imaging</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Imaging Techniques</subject><subj-group><subject>Neuroimaging</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuroimaging</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject><subj-group><subject>Anxiety</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject><subj-group><subject>Anxiety</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Biochemistry</subject><subj-group><subject>Biomarkers</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Personality</subject><subj-group><subject>Personality Traits</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Personality</subject><subj-group><subject>Personality Traits</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Cognition</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Decoding Spontaneous Emotional States in the Human Brain</article-title><alt-title alt-title-type="running-head">Spontaneous Emotional Brain States</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kragel</surname><given-names>Philip A.</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Knodt</surname><given-names>Annchen R.</given-names></name><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Project administration</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>Hariri</surname><given-names>Ahmad R.</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Funding acquisition</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Resources</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/></contrib><contrib contrib-type="author"><name><surname>LaBar</surname><given-names>Kevin S.</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Funding acquisition</role><role content-type="http://credit.casrai.org/">Project administration</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"/><xref ref-type="corresp" rid="cor001">*</xref></contrib></contrib-group><aff id="aff001"><addr-line>Department of Psychology &#x00026; Neuroscience, Duke University, Durham, North Carolina, United States of America</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Rushworth</surname><given-names>Matthew</given-names></name><role>Academic Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1"><addr-line>Oxford University, United Kingdom</addr-line></aff><author-notes><fn fn-type="COI-statement" id="coi001"><p>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>klabar@duke.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>14</day><month>9</month><year>2016</year></pub-date><pub-date pub-type="collection"><month>9</month><year>2016</year></pub-date><pub-date pub-type="pmc-release"><day>14</day><month>9</month><year>2016</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the <pub-date pub-type="epub"/>. --><volume>14</volume><issue>9</issue><elocation-id>e2000106</elocation-id><history><date date-type="received"><day>19</day><month>5</month><year>2016</year></date><date date-type="accepted"><day>11</day><month>8</month><year>2016</year></date></history><permissions><copyright-statement>&#x000a9; 2016 Kragel et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Kragel et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pbio.2000106.pdf"/><abstract><p>Pattern classification of human brain activity provides unique insight into the neural underpinnings of diverse mental states. These multivariate tools have recently been used within the field of affective neuroscience to classify distributed patterns of brain activation evoked during emotion induction procedures. Here we assess whether neural models developed to discriminate among distinct emotion categories exhibit predictive validity in the absence of exteroceptive emotional stimulation. In two experiments, we show that spontaneous fluctuations in human resting-state brain activity can be decoded into categories of experience delineating unique emotional states that exhibit spatiotemporal coherence, covary with individual differences in mood and personality traits, and predict on-line, self-reported feelings. These findings validate objective, brain-based models of emotion and show how emotional states dynamically emerge from the activity of separable neural systems.</p></abstract><abstract abstract-type="summary"><title>Author Summary</title><p>Functional brain imaging techniques provide a window into neural activity underpinning diverse cognitive processes, including visual perception, decision-making, and memory, among many others. By treating functional imaging data as a pattern-recognition problem, similar to face- or character-recognition, researchers have successfully identified patterns of brain activity that predict specific mental states; for example, the kind of an object being viewed. Moreover, these methods are capable of predicting mental states in the absence of external stimulation. For example, pattern-classifiers trained on brain responses to visual stimuli can successfully predict the contents of imagery during sleep. This research shows that internally mediated brain activity can be used to infer subjective mental states; however, it is not known whether more complex emotional mental states can be decoded from neuroimaging data in the absence of experimental manipulations. Here we show that brain-based models of specific emotions can detect individual differences in mood and emotional traits and are consistent with self-reports of emotional experience during intermittent periods of wakeful rest. These findings show that the brain dynamically fluctuates among multiple distinct emotional states at rest. More practically, the results suggest that brain-based models of emotion may help assess emotional status in clinical settings, particularly in individuals incapable of providing self-report of their own emotional experience.</p></abstract><funding-group><funding-statement>NIH <ext-link ext-link-type="uri" xlink:href="http://www.nih.gov">www.nih.gov</ext-link> (grant number R01 DA033369). Received by ARH. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. NIH <ext-link ext-link-type="uri" xlink:href="http://www.nih.gov">www.nih.gov</ext-link> (grant number R01 AG049789). Received by ARH. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. NIH <ext-link ext-link-type="uri" xlink:href="http://www.nih.gov">www.nih.gov</ext-link> (grant number R21 MH098149). Received by KSL. The funder had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</funding-statement></funding-group><counts><fig-count count="5"/><table-count count="1"/><page-count count="19"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>Data are from the Duke Neurogenetics Study (DNS), whose investigators can be contacted at <email>haririlab@gmail.com</email>. Access to the full DNS dataset, including the raw fMRI resting state data, can be obtained from <ext-link ext-link-type="uri" xlink:href="https://www.haririlab.com/projects">https://www.haririlab.com/projects</ext-link>. In short, restricted access is provided for the following reasons: 1. We are using an archived database of research participants as the primary source of data for the study. Participants in this study did not provide consent to have their raw MRI images stored in a public repository. It would violate our own Duke IRB policy to share these raw images without consent from the research participants. 2. The database has its own Standard Operating Procedures for data sharing, which is available at <ext-link ext-link-type="uri" xlink:href="http://www.haririlab.com">www.haririlab.com</ext-link>. Every peer-reviewed manuscript published from this common database adheres to the same data sharing policy. 3. The raw MRI images contain public health information in the MRI headers, and the faces of the research participants can be reconstructed from the raw MRI images. The raw data underlying plots in <xref ref-type="fig" rid="pbio.2000106.g001">Fig 1</xref> (panel B), <xref ref-type="fig" rid="pbio.2000106.g002">Fig 2</xref> (panel B), Figs <xref ref-type="fig" rid="pbio.2000106.g003">3</xref> and <xref ref-type="fig" rid="pbio.2000106.g004">4</xref> (panels A and B), <xref ref-type="fig" rid="pbio.2000106.g005">Fig 5</xref> (panels B and C), <xref ref-type="supplementary-material" rid="pbio.2000106.s002">S2 Fig</xref> (panels A and B), <xref ref-type="supplementary-material" rid="pbio.2000106.s003">S3 Fig</xref> (panels A and B), and <xref ref-type="supplementary-material" rid="pbio.2000106.s004">S4 Fig</xref> (panels A and B) are provided in the Supporting Information file <xref ref-type="supplementary-material" rid="pbio.2000106.s006">S1 Data</xref>.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>Data are from the Duke Neurogenetics Study (DNS), whose investigators can be contacted at <email>haririlab@gmail.com</email>. Access to the full DNS dataset, including the raw fMRI resting state data, can be obtained from <ext-link ext-link-type="uri" xlink:href="https://www.haririlab.com/projects">https://www.haririlab.com/projects</ext-link>. In short, restricted access is provided for the following reasons: 1. We are using an archived database of research participants as the primary source of data for the study. Participants in this study did not provide consent to have their raw MRI images stored in a public repository. It would violate our own Duke IRB policy to share these raw images without consent from the research participants. 2. The database has its own Standard Operating Procedures for data sharing, which is available at <ext-link ext-link-type="uri" xlink:href="http://www.haririlab.com">www.haririlab.com</ext-link>. Every peer-reviewed manuscript published from this common database adheres to the same data sharing policy. 3. The raw MRI images contain public health information in the MRI headers, and the faces of the research participants can be reconstructed from the raw MRI images. The raw data underlying plots in <xref ref-type="fig" rid="pbio.2000106.g001">Fig 1</xref> (panel B), <xref ref-type="fig" rid="pbio.2000106.g002">Fig 2</xref> (panel B), Figs <xref ref-type="fig" rid="pbio.2000106.g003">3</xref> and <xref ref-type="fig" rid="pbio.2000106.g004">4</xref> (panels A and B), <xref ref-type="fig" rid="pbio.2000106.g005">Fig 5</xref> (panels B and C), <xref ref-type="supplementary-material" rid="pbio.2000106.s002">S2 Fig</xref> (panels A and B), <xref ref-type="supplementary-material" rid="pbio.2000106.s003">S3 Fig</xref> (panels A and B), and <xref ref-type="supplementary-material" rid="pbio.2000106.s004">S4 Fig</xref> (panels A and B) are provided in the Supporting Information file <xref ref-type="supplementary-material" rid="pbio.2000106.s006">S1 Data</xref>.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>Functional neuroimaging offers unique insight into how mental representations are encoded in brain activity [<xref rid="pbio.2000106.ref001" ref-type="bibr">1</xref>,<xref rid="pbio.2000106.ref002" ref-type="bibr">2</xref>]. Seminal cognitive neuroscience studies demonstrated that distributed patterns of cortical activity measured with functional magnetic resonance imaging (fMRI) contain information capable of differentiating among visual percepts, including object categories [<xref rid="pbio.2000106.ref003" ref-type="bibr">3</xref>] and basic visual features [<xref rid="pbio.2000106.ref004" ref-type="bibr">4</xref>]. Extending findings from these studies, subsequent work demonstrated that machine learning models trained on stimulus-evoked brain activity, termed &#x0201c;decoding&#x0201d; or &#x0201c;mind-reading&#x0201d; [<xref rid="pbio.2000106.ref005" ref-type="bibr">5</xref>], can be used to predict the contents of working memory [<xref rid="pbio.2000106.ref006" ref-type="bibr">6</xref>&#x02013;<xref rid="pbio.2000106.ref008" ref-type="bibr">8</xref>] and mental imagery [<xref rid="pbio.2000106.ref009" ref-type="bibr">9</xref>,<xref rid="pbio.2000106.ref010" ref-type="bibr">10</xref>], even during sleep [<xref rid="pbio.2000106.ref011" ref-type="bibr">11</xref>]. Thus, pattern recognition approaches can identify defining features of mental processes, even when driven solely on the basis of endogenous brain activity. The approach was further shown to accurately discriminate among multiple cognitive processes (e.g., decision-making, working memory, response inhibition, among others) in independent subjects [<xref rid="pbio.2000106.ref012" ref-type="bibr">12</xref>], establishing the efficacy of assessing diverse mental states with fMRI across individuals.</p><p>Paralleling cognitive studies decoding task-evoked brain activity, multivariate decoding approaches have recently been used to map patterns of neural activity evoked by emotion elicitors onto discrete feeling states [<xref rid="pbio.2000106.ref013" ref-type="bibr">13</xref>,<xref rid="pbio.2000106.ref014" ref-type="bibr">14</xref>]. However, a key piece of missing evidence is whether categorically distinct emotional brain states occur intrinsically [<xref rid="pbio.2000106.ref015" ref-type="bibr">15</xref>,<xref rid="pbio.2000106.ref016" ref-type="bibr">16</xref>] in the absence of external eliciting stimuli. If so, then it should be possible to classify the emotional status of a human being based on analysis of spontaneous fluctuations of brain activity during rest. Successful classification would validate multivariate decoding of unconstrained brain activity and provides insight into the nature of emotional brain activity during the resting state.</p><p>Adapting the logic of other cognitive imaging studies [<xref rid="pbio.2000106.ref016" ref-type="bibr">16</xref>,<xref rid="pbio.2000106.ref017" ref-type="bibr">17</xref>], we postulate that the presence of spontaneous emotional brain states should be detectable using multivariate models derived from prior investigations of emotion elicitation. We previously developed decoding algorithms to classify stimulus-evoked responses to emotionally evocative cinematic films and instrumental music [<xref rid="pbio.2000106.ref013" ref-type="bibr">13</xref>]. These neural models (<xref ref-type="fig" rid="pbio.2000106.g001">Fig 1</xref>) accurately classify patterns of neural activation associated with six different emotions (contentment, amusement, surprise, fear, anger, and sadness) and a neutral control state in independent subjects, generalizing across induction modality. Importantly, these neural biomarkers track the subjective experience of discrete emotions independent of differences in the more general dimensions of valence and arousal [<xref rid="pbio.2000106.ref018" ref-type="bibr">18</xref>]. By indexing the extent to which a pattern of neural activation to extrinsic stimuli reflects a specific emotion, these models can be used to test whether intrinsic spatiotemporal patterns of brain activity correspond to stimulus-evoked emotional states.</p><fig id="pbio.2000106.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.2000106.g001</object-id><label>Fig 1</label><caption><title>Distributed patterns of brain activity predict the experience of discrete emotions.</title><p>(A) Parametric maps indicate brain regions in which increased fMRI signal informs the classification of emotional states. See [<xref rid="pbio.2000106.ref013" ref-type="bibr">13</xref>] for details of the development and validation of these neural decoding models. (B) Sensitivity of the seven models. Error bars depict 95% confidence intervals. The data underlying this figure can be found in <xref ref-type="supplementary-material" rid="pbio.2000106.s006">S1 Data</xref>.</p></caption><graphic xlink:href="pbio.2000106.g001"/></fig><p>Here, we evaluate whether these neural models of discrete emotions generalize to spontaneous brain activation measured via fMRI in two experiments. The first experiment assesses if model predictions are convergent with individual differences in self-reported mood and emotional traits. Because individual differences are linked to mental health and subjective well-being [<xref rid="pbio.2000106.ref019" ref-type="bibr">19</xref>&#x02013;<xref rid="pbio.2000106.ref021" ref-type="bibr">21</xref>], this evaluation provides insight into the potential clinical utility of quantifying spontaneous emotional states, as they may be associated with risk factors for mental illness. The second experiment employs an experience sampling procedure to evaluate whether model predictions based on brain activity during periods of rest are congruent with on-line measures of emotional experience. Together, these studies probe how brain-based models of specific emotion categories quantify changes in extemporaneous affect both between and within individuals.</p></sec><sec sec-type="results" id="sec002"><title>Results</title><sec id="sec003"><title>Classification of Resting-State Brain Activity</title><p>We applied the multivariate models of emotional experience to brain activation acquired from young adults during resting-state fMRI (<italic>n</italic> = 499; <xref ref-type="fig" rid="pbio.2000106.g002">Fig 2A</xref>). Two consecutive runs of resting-state scans were acquired, spanning a total duration of 8.53 min. Following preprocessing of data, we computed the scalar product of the resting-state signal and emotion category-specific model weights at every time point of data acquisition. This procedure yielded scores that reflect the relative evidence for each of seven emotional states across the full scanning period. A confirmatory analysis revealed that voxels distributed across the whole brain informed this prediction, as opposed to activity in a small number of brain regions (<xref ref-type="supplementary-material" rid="pbio.2000106.s001">S1 Fig</xref>).</p><fig id="pbio.2000106.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.2000106.g002</object-id><label>Fig 2</label><caption><title>Emotional states emerge spontaneously during resting-state scans.</title><p>(A) Procedure for classification of resting-state data. Scores are computed by taking the scalar product of preprocessed data and regression weights from decoding models. (B) Frequency distributions for the classification of all seven emotional states (<italic>n</italic> = 499). The mean, 25th, and 75th percentiles are indicated by black lines. The solid gray line indicates the number of trials that would occur from random guessing. The data underlying this figure can be found in <xref ref-type="supplementary-material" rid="pbio.2000106.s006">S1 Data</xref>. The raw fMRI resting state data can be obtained from <ext-link ext-link-type="uri" xlink:href="https://www.haririlab.com/projects">https://www.haririlab.com/projects</ext-link>.</p></caption><graphic xlink:href="pbio.2000106.g002"/></fig><p>If emotional brain states occur spontaneously, the frequency of classifications from our decoding models should be more varied than the uniform distribution that would be expected by chance. To test this hypothesis, we sought to identify whether the total time (or absolute frequency) in each state differed across emotion categories. Such an analysis informs the degree to which discrete emotional brain states may spontaneously occur and, by extension, could contribute to the identification of individual differences that map onto the likelihood of experiencing specific spontaneous states. To perform this comparison, we identified the single model with the maximum score at each time point (one-versus-all classification) and summed the number of time points assigned to each category. The frequency of emotional states clearly differed across categories (<xref ref-type="fig" rid="pbio.2000106.g002">Fig 2B</xref>, &#x003c7;<sup>2</sup> = 1491.52, <italic>P</italic> &#x0003c; .0001, Friedman test), in contrast to the uniform distribution that would be expected if emotional brain-states did not occur in spontaneous activity (see <xref ref-type="supplementary-material" rid="pbio.2000106.s002">S2 Fig</xref>).</p><p>Follow-up comparisons revealed that neutral states occurred more frequently than chance rates (20.1 &#x000b1; 3.59% [s.d.], <italic>z</italic> = 20.50, <italic>P</italic><sub>unc</sub> = 2.03E-93), followed by states of surprise (18.37 &#x000b1; 3.87% [s.d.], <italic>z</italic> = 16.38, <italic>P</italic><sub>unc</sub> = 2.47E-60) and amusement (14.71 &#x000b1; 3.78% [s.d.], <italic>z</italic> = 1.25, <italic>P</italic><sub>unc</sub> = 0.21). States of sadness (13.49 &#x000b1; 3.76% [s.d.], <italic>z</italic> = -3.31, <italic>P</italic><sub>unc</sub> = 9.24E-4), fear (13.26 &#x000b1; 3.42% [s.d.], <italic>z</italic> = -5.28, <italic>P</italic><sub>unc</sub> = 1.28E-7), and anger (11.31 &#x000b1; 3.62% [s.d.], <italic>z</italic> = -13.07, <italic>P</italic><sub>unc</sub> = 4.78E-39) occurred with lower frequency, while states of contentment occurred the least often (8.74% &#x000b1; 3.42% [s.d.], <italic>z</italic> = -19.61, <italic>P</italic><sub>unc</sub> = 1.33E-85; see <xref rid="pbio.2000106.t001" ref-type="table">Table 1</xref>).</p><table-wrap id="pbio.2000106.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.2000106.t001</object-id><label>Table 1</label><caption><title>Pairwise comparisons of classification frequency ranks for the emotion models.</title></caption><alternatives><graphic id="pbio.2000106.t001g" xlink:href="pbio.2000106.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Model 1</th><th align="center" rowspan="1" colspan="1">Model 2</th><th align="center" rowspan="1" colspan="1">Lower Bound</th><th align="center" rowspan="1" colspan="1">Estimate</th><th align="center" rowspan="1" colspan="1">Upper Bound</th><th align="center" rowspan="1" colspan="1"><italic>P</italic><sub>unc</sub></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Content</td><td align="left" rowspan="1" colspan="1">Amusement</td><td align="char" char="." rowspan="1" colspan="1">-2.836</td><td align="char" char="." rowspan="1" colspan="1">-2.422</td><td align="char" char="." rowspan="1" colspan="1">-2.008</td><td align="right" rowspan="1" colspan="1">2.601E-69</td></tr><tr><td align="left" rowspan="1" colspan="1">Content</td><td align="left" rowspan="1" colspan="1">Surprise</td><td align="char" char="." rowspan="1" colspan="1">-4.199</td><td align="char" char="." rowspan="1" colspan="1">-3.785</td><td align="char" char="." rowspan="1" colspan="1">-3.370</td><td align="right" rowspan="1" colspan="1">2.310E-168</td></tr><tr><td align="left" rowspan="1" colspan="1">Content</td><td align="left" rowspan="1" colspan="1">Fear</td><td align="char" char="." rowspan="1" colspan="1">-2.199</td><td align="char" char="." rowspan="1" colspan="1">-1.785</td><td align="char" char="." rowspan="1" colspan="1">-1.370</td><td align="right" rowspan="1" colspan="1">7.583E-38</td></tr><tr><td align="left" rowspan="1" colspan="1">Content</td><td align="left" rowspan="1" colspan="1">Anger</td><td align="char" char="." rowspan="1" colspan="1">-1.445</td><td align="char" char="." rowspan="1" colspan="1">-1.031</td><td align="char" char="." rowspan="1" colspan="1">-0.617</td><td align="right" rowspan="1" colspan="1">8.165E-13</td></tr><tr><td align="left" rowspan="1" colspan="1">Content</td><td align="left" rowspan="1" colspan="1">Sad</td><td align="char" char="." rowspan="1" colspan="1">-2.291</td><td align="char" char="." rowspan="1" colspan="1">-1.877</td><td align="char" char="." rowspan="1" colspan="1">-1.463</td><td align="right" rowspan="1" colspan="1">8.186E-42</td></tr><tr><td align="left" rowspan="1" colspan="1">Content</td><td align="left" rowspan="1" colspan="1">Neutral</td><td align="char" char="." rowspan="1" colspan="1">-4.771</td><td align="char" char="." rowspan="1" colspan="1">-4.357</td><td align="char" char="." rowspan="1" colspan="1">-3.943</td><td align="right" rowspan="1" colspan="1">7.192E-223</td></tr><tr><td align="left" rowspan="1" colspan="1">Amusement</td><td align="left" rowspan="1" colspan="1">Surprise</td><td align="char" char="." rowspan="1" colspan="1">-1.777</td><td align="char" char="." rowspan="1" colspan="1">-1.363</td><td align="char" char="." rowspan="1" colspan="1">-0.949</td><td align="right" rowspan="1" colspan="1">3.265E-22</td></tr><tr><td align="left" rowspan="1" colspan="1">Amusement</td><td align="left" rowspan="1" colspan="1">Fear</td><td align="char" char="." rowspan="1" colspan="1">0.223</td><td align="char" char="." rowspan="1" colspan="1">0.637</td><td align="char" char="." rowspan="1" colspan="1">1.051</td><td align="right" rowspan="1" colspan="1">6.157E-05</td></tr><tr><td align="left" rowspan="1" colspan="1">Amusement</td><td align="left" rowspan="1" colspan="1">Anger</td><td align="char" char="." rowspan="1" colspan="1">0.977</td><td align="char" char="." rowspan="1" colspan="1">1.391</td><td align="char" char="." rowspan="1" colspan="1">1.805</td><td align="right" rowspan="1" colspan="1">4.001E-23</td></tr><tr><td align="left" rowspan="1" colspan="1">Amusement</td><td align="left" rowspan="1" colspan="1">Sad</td><td align="char" char="." rowspan="1" colspan="1">0.131</td><td align="char" char="." rowspan="1" colspan="1">0.545</td><td align="char" char="." rowspan="1" colspan="1">0.959</td><td align="right" rowspan="1" colspan="1">1.335E-03</td></tr><tr><td align="left" rowspan="1" colspan="1">Amusement</td><td align="left" rowspan="1" colspan="1">Neutral</td><td align="char" char="." rowspan="1" colspan="1">-2.349</td><td align="char" char="." rowspan="1" colspan="1">-1.935</td><td align="char" char="." rowspan="1" colspan="1">-1.521</td><td align="right" rowspan="1" colspan="1">2.045E-44</td></tr><tr><td align="left" rowspan="1" colspan="1">Surprise</td><td align="left" rowspan="1" colspan="1">Fear</td><td align="char" char="." rowspan="1" colspan="1">1.586</td><td align="char" char="." rowspan="1" colspan="1">2.000</td><td align="char" char="." rowspan="1" colspan="1">2.414</td><td align="right" rowspan="1" colspan="1">1.999E-47</td></tr><tr><td align="left" rowspan="1" colspan="1">Surprise</td><td align="left" rowspan="1" colspan="1">Anger</td><td align="char" char="." rowspan="1" colspan="1">2.339</td><td align="char" char="." rowspan="1" colspan="1">2.754</td><td align="char" char="." rowspan="1" colspan="1">3.168</td><td align="right" rowspan="1" colspan="1">1.979E-89</td></tr><tr><td align="left" rowspan="1" colspan="1">Surprise</td><td align="left" rowspan="1" colspan="1">Sad</td><td align="char" char="." rowspan="1" colspan="1">1.494</td><td align="char" char="." rowspan="1" colspan="1">1.908</td><td align="char" char="." rowspan="1" colspan="1">2.322</td><td align="right" rowspan="1" colspan="1">3.404E-43</td></tr><tr><td align="left" rowspan="1" colspan="1">Surprise</td><td align="left" rowspan="1" colspan="1">Neutral</td><td align="char" char="." rowspan="1" colspan="1">-0.986</td><td align="char" char="." rowspan="1" colspan="1">-0.572</td><td align="char" char="." rowspan="1" colspan="1">-0.158</td><td align="right" rowspan="1" colspan="1">5.662E-04</td></tr><tr><td align="left" rowspan="1" colspan="1">Fear</td><td align="left" rowspan="1" colspan="1">Anger</td><td align="char" char="." rowspan="1" colspan="1">0.339</td><td align="char" char="." rowspan="1" colspan="1">0.754</td><td align="char" char="." rowspan="1" colspan="1">1.168</td><td align="right" rowspan="1" colspan="1">6.790E-07</td></tr><tr><td align="left" rowspan="1" colspan="1">Fear</td><td align="left" rowspan="1" colspan="1">Sad</td><td align="char" char="." rowspan="1" colspan="1">-0.506</td><td align="char" char="." rowspan="1" colspan="1">-0.092</td><td align="char" char="." rowspan="1" colspan="1">0.322</td><td align="right" rowspan="1" colspan="1">1.000E+00<xref ref-type="table-fn" rid="t001fn002">*</xref></td></tr><tr><td align="left" rowspan="1" colspan="1">Fear</td><td align="left" rowspan="1" colspan="1">Neutral</td><td align="char" char="." rowspan="1" colspan="1">-2.986</td><td align="char" char="." rowspan="1" colspan="1">-2.572</td><td align="char" char="." rowspan="1" colspan="1">-2.158</td><td align="right" rowspan="1" colspan="1">4.128E-78</td></tr><tr><td align="left" rowspan="1" colspan="1">Anger</td><td align="left" rowspan="1" colspan="1">Sad</td><td align="char" char="." rowspan="1" colspan="1">-1.260</td><td align="char" char="." rowspan="1" colspan="1">-0.846</td><td align="char" char="." rowspan="1" colspan="1">-0.432</td><td align="right" rowspan="1" colspan="1">1.151E-08</td></tr><tr><td align="left" rowspan="1" colspan="1">Anger</td><td align="left" rowspan="1" colspan="1">Neutral</td><td align="char" char="." rowspan="1" colspan="1">-3.740</td><td align="char" char="." rowspan="1" colspan="1">-3.326</td><td align="char" char="." rowspan="1" colspan="1">-2.912</td><td align="right" rowspan="1" colspan="1">3.629E-130</td></tr><tr><td align="left" rowspan="1" colspan="1">Sad</td><td align="left" rowspan="1" colspan="1">Neutral</td><td align="char" char="." rowspan="1" colspan="1">-2.894</td><td align="char" char="." rowspan="1" colspan="1">-2.480</td><td align="char" char="." rowspan="1" colspan="1">-2.066</td><td align="right" rowspan="1" colspan="1">1.189E-72</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t001fn001"><p><italic>P</italic><sub>unc</sub> = uncorrected <italic>P</italic> value.</p></fn><fn id="t001fn002"><p>*does not survive FDR correction for multiple comparisons. Estimates reflect the difference in rank for Model 1 versus Model 2</p></fn></table-wrap-foot></table-wrap><p>Although patterns of neural activation were most often classified as neutral as a whole, it is possible that consistent fluctuations in the time course of emotional states occur against this background. Research on MRI scanner-related anxiety has shown that self-report [<xref rid="pbio.2000106.ref022" ref-type="bibr">22</xref>,<xref rid="pbio.2000106.ref023" ref-type="bibr">23</xref>] and peripheral physiological [<xref rid="pbio.2000106.ref024" ref-type="bibr">24</xref>] measures of anxiety peak at the beginning of scanning, when subjects first enter the scanner bore. This literature predicts that brain states indicative of fear should be most prevalent at the beginning of resting-state runs, and that neutral states should emerge over time, given their overall high prevalence (<xref ref-type="fig" rid="pbio.2000106.g002">Fig 2B</xref>).</p><p>To assess gradual changes in the emotional states over time, we performed Friedman tests separately for each emotion category, all of which revealed significant effects of time (see <xref ref-type="supplementary-material" rid="pbio.2000106.s005">S1 Table</xref>). Next, we quantified the direction of these effects using general linear models to predict classifier scores using scan time as an input. We found the scores for fear decreased over time (<inline-formula id="pbio.2000106.e001"><alternatives><graphic xlink:href="pbio.2000106.e001.jpg" id="pbio.2000106.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.001</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>498</sub> = -4.92, <italic>P</italic><sub>unc</sub> = 1.20E-006, <xref ref-type="fig" rid="pbio.2000106.g003">Fig 3</xref> gray lines), whereas neutral states exhibited an increasing trend throughout the scanning period (<inline-formula id="pbio.2000106.e002"><alternatives><graphic xlink:href="pbio.2000106.e002.jpg" id="pbio.2000106.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.0017</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>498</sub> = 7.36, <italic>P</italic><sub>unc</sub> = 7.66E-013), consistent with predictions (additional effects were observed for scores for contentment [<inline-formula id="pbio.2000106.e003"><alternatives><graphic xlink:href="pbio.2000106.e003.jpg" id="pbio.2000106.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.0017</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>498</sub> = 7.37, <italic>P</italic><sub>unc</sub> = 7.05E-13], surprise [<inline-formula id="pbio.2000106.e004"><alternatives><graphic xlink:href="pbio.2000106.e004.jpg" id="pbio.2000106.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.0010</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>498</sub> = 4.07, <italic>P</italic><sub>unc</sub> = 5.51E-05], anger [<inline-formula id="pbio.2000106.e005"><alternatives><graphic xlink:href="pbio.2000106.e005.jpg" id="pbio.2000106.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.0007</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>498</sub> = -3.36, <italic>P</italic><sub>unc</sub> = 0.00085], and sadness [<inline-formula id="pbio.2000106.e006"><alternatives><graphic xlink:href="pbio.2000106.e006.jpg" id="pbio.2000106.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.0034</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>498</sub> = -15.59, <italic>P</italic><sub>unc</sub> &#x0003c; 2.52E-038]).</p><fig id="pbio.2000106.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.2000106.g003</object-id><label>Fig 3</label><caption><title>Emotional states exhibit coherence during resting-state scans.</title><p>Gray circles reflect the sample mean classification scores for all seven emotions (<italic>n</italic> = 499). Thick colored lines display group-average predicted time course using smoothing splines (with bordering 95% confidence interval). Text overlay (r<sub>cv</sub>) indicates the average cross-validated correlation between splines fitted for each subject and tested on the average fit of other subjects. Dashed lines indicate linear fits over time. Solid black dots indicate time points at which a model has the highest proportion of classifications. Data are concatenated across two sessions of 256 s (solid vertical line). Note the early peak for fear scores and general increases in neutral scores over time. The data underlying this figure can be found in <xref ref-type="supplementary-material" rid="pbio.2000106.s006">S1 Data</xref>. The raw fMRI resting state data can be obtained from <ext-link ext-link-type="uri" xlink:href="https://www.haririlab.com/projects">https://www.haririlab.com/projects</ext-link>.</p></caption><graphic xlink:href="pbio.2000106.g003"/></fig><p>To determine whether emotional states exhibited consistent dynamics over the course of the scanning period, we fit smoothing spline models [<xref rid="pbio.2000106.ref025" ref-type="bibr">25</xref>] for each subject and assessed the correlation between each subject and the average time course of other subjects in a cross-validation procedure. This analysis showed that there is substantial moment-to-moment variability in the time course of emotional states across subjects (which cannot simply be explained by scaling differences in the emotion models or resting-state data; see <xref ref-type="supplementary-material" rid="pbio.2000106.s003">S3 Fig</xref>). Consistent with the linear models using time as a predictor, evidence for neutral brain states was most prevalent in the second scanning session, especially during a peak at the beginning of the run, whereas the time course for fear peaked at the beginning of the first run and decreased throughout the scanning session. The model for surprise exhibited a similar time course as neutral states but peaked at the end of the second run. Additionally, this analysis showed that evidence for sad classifications peaked in the middle of the first run and decreased over time. Overall, these time series revealed a gradual change in evidence from negative emotions (fear and sadness in run 1) to non-valenced or bi-valenced emotions (neutral and surprise in run 2).</p><p>To ensure that our emotion-specific brain states are not proxies for more general resting-state networks thought to subserve other functions, we examined the spatial overlap between our models and those commonly derived by connectivity-based analysis of resting-state fMRI data [<xref rid="pbio.2000106.ref026" ref-type="bibr">26</xref>]. On average, we observed little overlap (Jaccard index = 13.1 &#x000b1; 1.97% [s.d.]; range 10.8%&#x02013;16.7%) with the seven most prominent networks found in resting-state data, implicating a substantial degree of independence.</p><p>To further establish the construct validity of the spontaneous emotional brain states, we reasoned that their incidence should vary with individual differences in self-reported mood and personality traits associated with specific emotions. We assayed depressive mood with the Center for Epidemiologic Studies Depression Scale (CESD) [<xref rid="pbio.2000106.ref027" ref-type="bibr">27</xref>] and state anxiety using the State-Trait Anxiety Inventory State Version (STAI-S) [<xref rid="pbio.2000106.ref028" ref-type="bibr">28</xref>], instructing participants to indicate how they felt during the resting-state scan itself. Binomial regression models revealed that higher depression scores were associated with increases in the frequency of sadness (<inline-formula id="pbio.2000106.e007"><alternatives><graphic xlink:href="pbio.2000106.e007.jpg" id="pbio.2000106.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.0025</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>497</sub> = 2.673, <italic>P</italic><sub>unc</sub> = .0075, <xref ref-type="fig" rid="pbio.2000106.g004">Fig 4A</xref>, see <xref ref-type="supplementary-material" rid="pbio.2000106.s004">S4 Fig</xref> for scatter plots of predictions) and no other emotional state (all <italic>P</italic><sub>unc</sub> &#x0003e; .24). State anxiety was associated with increasing classifications of fear (<inline-formula id="pbio.2000106.e008"><alternatives><graphic xlink:href="pbio.2000106.e008.jpg" id="pbio.2000106.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.0033</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>497</sub> = 2.608, <italic>P</italic><sub>unc</sub> = .0091) and decreasing frequency of contentment (<inline-formula id="pbio.2000106.e009"><alternatives><graphic xlink:href="pbio.2000106.e009.jpg" id="pbio.2000106.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.0031</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>497</sub> = -2.015, <italic>P</italic><sub>unc</sub> = .0439). Viewing these beta estimates as odds ratios (computed as <inline-formula id="pbio.2000106.e010"><alternatives><graphic xlink:href="pbio.2000106.e010.jpg" id="pbio.2000106.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mrow><mml:msup><mml:mtext>e</mml:mtext><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>) reveals how a one-unit increase in self-reported mood is associated with differences in the occurrence of spontaneous emotional states. Applying this approach to CESD scores reveals that individuals with a score of 16 (the cutoff for identifying individuals at risk for depression) have 5.92% increased odds of being in a sad state compared to those with a score of 0. In more practical terms, this corresponds to approximately seven extra minutes a day of exhibiting a brain state that would be classified as sadness.</p><fig id="pbio.2000106.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.2000106.g004</object-id><label>Fig 4</label><caption><title>Individual differences in mood and personality modulate the occurrence of spontaneous emotional brain states.</title><p>(A) Differences in depressive and anxious mood are associated with increases in the frequency of sad and fear classifications during rest. (B) Emotional traits of Anxiety, Angry Hostility, and Depression track differences in the frequency of fear, anger, and sad classifications (<italic>n</italic> = 499, error bars reflect standard error, * indicates effects significant at <italic>P</italic><sub>unc</sub> &#x0003c; .05). The data underlying this figure can be found in <xref ref-type="supplementary-material" rid="pbio.2000106.s006">S1 Data</xref>. The raw fMRI resting state data can be obtained from <ext-link ext-link-type="uri" xlink:href="https://www.haririlab.com/projects">https://www.haririlab.com/projects</ext-link>.</p></caption><graphic xlink:href="pbio.2000106.g004"/></fig><p>Drawing from the Revised NEO Personality Inventory (NEO-PI-R) [<xref rid="pbio.2000106.ref029" ref-type="bibr">29</xref>], we focused personality trait assessment on the specific Neuroticism subfacets of Anxiety, Angry Hostility, and Depression, due to their discriminant validity [<xref rid="pbio.2000106.ref030" ref-type="bibr">30</xref>], heritability [<xref rid="pbio.2000106.ref031" ref-type="bibr">31</xref>], universality [<xref rid="pbio.2000106.ref032" ref-type="bibr">32</xref>], and close theoretical ties to the experience of fear, anger, and sadness. We found that increasing Anxiety scores were associated with more frequent classification of fear (<inline-formula id="pbio.2000106.e011"><alternatives><graphic xlink:href="pbio.2000106.e011.jpg" id="pbio.2000106.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.003</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>497</sub> = 1.978, <italic>P</italic><sub>unc</sub> = 0.0479, <xref ref-type="fig" rid="pbio.2000106.g004">Fig 4B</xref>) and fewer classifications of anger (<inline-formula id="pbio.2000106.e012"><alternatives><graphic xlink:href="pbio.2000106.e012.jpg" id="pbio.2000106.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.004</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>497</sub> = -2.407, <italic>P</italic><sub>unc</sub> = 0.0161). Angry Hostility scores were positively associated with the number of anger classifications (<inline-formula id="pbio.2000106.e013"><alternatives><graphic xlink:href="pbio.2000106.e013.jpg" id="pbio.2000106.e013g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M13"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.0042</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>497</sub> = 2.400, <italic>P</italic><sub>unc</sub> = 0.0164). Depression scores were positively associated with the frequency of fear (<inline-formula id="pbio.2000106.e014"><alternatives><graphic xlink:href="pbio.2000106.e014.jpg" id="pbio.2000106.e014g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M14"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.003</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>497</sub> = 2.058, <italic>P</italic><sub>unc</sub> = 0.0396) and sadness (<inline-formula id="pbio.2000106.e015"><alternatives><graphic xlink:href="pbio.2000106.e015.jpg" id="pbio.2000106.e015g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M15"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003b2;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mn>0.0037</mml:mn></mml:mrow></mml:math></alternatives></inline-formula>, t<sub>497</sub> = 2.546, <italic>P</italic><sub>unc</sub> = 0.0109). These results provide converging evidence across both state and trait markers that individual differences uniquely and differentially bias the spontaneous occurrence of brain states indicative of fear, anger, and sadness.</p></sec><sec id="sec004"><title>Concordance with Subjective Experience</title><p>Finally, we examined whether the predictions of our decoding models were consistent with self-report of emotional experience during periods of unconstrained rest. We conducted a separate fMRI experiment in which an independent sample of young adult participants (<italic>n</italic> = 21) performed an experience sampling task in the absence of external stimulation (<xref ref-type="fig" rid="pbio.2000106.g005">Fig 5A</xref>). Participants were instructed to rest and let their mind wander freely with their eyes open during scanning. Following intervals of rest of at least 30 s, a rating screen appeared during which participants moved a cursor to the location on the screen that best indicated how they currently felt.</p><fig id="pbio.2000106.g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pbio.2000106.g005</object-id><label>Fig 5</label><caption><title>Spontaneous emotional brain states exhibit correspondence with self-report.</title><p>(A) Participants (<italic>n</italic> = 21) participated in an experience sampling task in which they reported their current emotional state at random intervals exceeding 30 s during fMRI scanning. The five samples of data (lasting 10 s, TR = 2 s) preceding each rating were used to compute predictions of emotional state using multivariate decoding models. (B) Scores for classification models congruent with self-report are greater than incongruent models (<italic>z</italic> = 2.311, <italic>P</italic><sub>unc</sub> = 0.0208; Wilcoxon signed rank test). Classification scores are calculated based on the inner product of neural activity and classifier weights and indicate the relative evidence for the different emotion models. (C) The frequency of classifications from multivariate models significantly correlates with those made by participant self-report (r = .3876 &#x000b1; 0.102 [s.e.m.], t<sub>20</sub> = 2.537, <italic>P</italic><sub>unc</sub> = .0196; one sample <italic>t</italic> test). Gray line indicates best-fitting least-squares line for group mean. In all panels, error bars reflect standard error of the mean. The data underlying this figure can be found in <xref ref-type="supplementary-material" rid="pbio.2000106.s006">S1 Data</xref>.</p></caption><graphic xlink:href="pbio.2000106.g005"/></fig><p>If spontaneous emotional states are accessible to conscious awareness, then scores should be greater for emotion models congruent with self-report relative to scores for models incongruent with self-report. Contrasting emotion models in this manner is advantageous from a signal detection standpoint because it minimizes noise by averaging across emotions, as some were reported infrequently or not at all in some subjects (see [<xref rid="pbio.2000106.ref033" ref-type="bibr">33</xref>] for an analogous approach to predict the contents of memory retrieval during similarly unconstrained free-recall). To test our hypothesis, we extracted resting-state fMRI data from the 10-s interval preceding each self-report query and applied multivariate models to determine the extent to which evidence for the emotional brain states in this window predicted the participants&#x02019; conscious emotional experience.</p><p>Consistent with our hypothesis, we found that scores for models congruent with self-report were positive (0.016 &#x000b1; 0.0093 [s.e.m.], <italic>z</italic> = 2.068, <italic>P</italic><sub>unc</sub> = 0.0386; Wilcoxon signed rank test), whereas scores for incongruent models were negative (-0.0048 &#x000b1; 0.0017 [s.e.m.], <italic>z</italic> = -3.041, <italic>P</italic><sub>unc</sub> = 0.0024). Classification of individual trials into the seven emotion categories exhibited an overall accuracy of 27.9 &#x000b1; 2.1% (s.e.m.) of trials, where chance agreement is 21.47% (<italic>P</italic><sub>unc</sub> = 0.001; binomial test). Not only do these results demonstrate that classification models are sensitive to changes in emotional state reported by participants, but also that there is selectivity in their predictions, as negative scores indicate evidence against emotion labels that are incongruent with self-report. Establishing both sensitivity and selectivity is important for the potential use of these brain-based models as diagnostic biomarkers of emotional states.</p><p>As an additional validation of our decoding models, we examined the correspondence between the prevalence of individual emotional brain states as detected via pattern classification and participant self-report. Classifications based on self-report and multivariate decoding yielded similar frequency distributions (<xref ref-type="fig" rid="pbio.2000106.g005">Fig 5C</xref>), in which neutral and amusement were the most frequent. We found a positive correlation between the frequency of classifications based on participant ratings and multivariate decoding (r = .3876 &#x000b1; 0.102 [s.e.m.], t<sub>20</sub> = 2.537, <italic>P</italic><sub>unc</sub> = .0196; one sample <italic>t</italic> test), further demonstrating a link between patterning of brain states and subjective ratings of emotional experience in the absence of external stimuli or contextual cues.</p></sec></sec><sec sec-type="conclusions" id="sec005"><title>Discussion</title><p>Converging findings from our experiments provide evidence that brain states associated with distinct emotional experiences emerge during unconstrained rest. Whereas prior work has decoded stimulus-evoked responses to emotional events, our study demonstrates that spontaneous neural activity dynamically fluctuates among multiple emotional states in a reliable manner over time. Observing such coherent, emotion-specific patterns in spontaneous fMRI activation provides evidence to support theories that posit emotions are represented categorically in the coordinated activity of separable neural substrates [<xref rid="pbio.2000106.ref034" ref-type="bibr">34</xref>,<xref rid="pbio.2000106.ref035" ref-type="bibr">35</xref>].</p><p>Validating the neural biomarkers in the absence of external stimulation suggests that they track information of functional significance, and do not merely reflect properties of the stimuli used in their development. It is possible that these classifiers detect the endogenous activity of distributed neural circuits, consistent with recent views that emotions are not represented in modular functional units [<xref rid="pbio.2000106.ref036" ref-type="bibr">36</xref>,<xref rid="pbio.2000106.ref037" ref-type="bibr">37</xref>]. However, the extent to which such activity is the result of innate emotion-dedicated circuitry, a series of cognitive appraisals, or constructive processes shaped by social and environmental factors remains to be determined (for a review of these viewpoints, see [<xref rid="pbio.2000106.ref038" ref-type="bibr">38</xref>]). Regardless of the relative influence of such factors, the present findings suggest that the emotion-specific biomarkers track the expression of functionally distinct brain systems, as opposed to idiosyncrasies of the particular machine-learning problem.</p><p>Our findings complement recent studies demonstrating that a variety of emotion manipulations have lasting effects on resting brain activity [<xref rid="pbio.2000106.ref039" ref-type="bibr">39</xref>&#x02013;<xref rid="pbio.2000106.ref041" ref-type="bibr">41</xref>]. For instance, one study revealed elevated striatal activity following gratifying outcomes in a decision-making task&#x02014;an effect that was diminished in individuals with higher depressive tendencies [<xref rid="pbio.2000106.ref039" ref-type="bibr">39</xref>]. Because these effects immediately followed emotional stimulation, they could plausibly reflect regulatory processes or lingering effects of mood. The present results, on the other hand, show that resting brain activity transiently fluctuates among multiple emotional states and that these fluctuations vary depending on the emotional status of an individual. Thus, emotional processes unfolding at both long and short time scales likely contribute to spontaneous brain activity.</p><p>Findings from our resting state experiment stand in contrast to recent work investigating emotion-specific functional connectivity [<xref rid="pbio.2000106.ref042" ref-type="bibr">42</xref>]. In this study, whole-brain resting-state functional connectivity was assessed using seeds identified from a meta-analytic summary of emotion research [<xref rid="pbio.2000106.ref043" ref-type="bibr">43</xref>]. This latter approach failed to reveal unique patterns of resting-state connectivity for individual emotions but showed that seed regions were commonly correlated with domain-general resting-state networks, such as the salience network [<xref rid="pbio.2000106.ref044" ref-type="bibr">44</xref>]. In light of the present results, it is important to consider methodological differences between studies. Seed-based correlation highlights connectivity between brain regions whose time course of activation is maximally similar to the activity of a small number of voxels (which are averaged together to create a single time series), whereas pattern classification identifies combinations of voxels that maximally discriminate among mental states. Because individual voxels sample diverse neural populations [<xref rid="pbio.2000106.ref045" ref-type="bibr">45</xref>], it is plausible that seed-based correlation is biased towards identifying networks that have large amplitudes in seeded regions as opposed to exhibiting specificity (e.g., see [<xref rid="pbio.2000106.ref046" ref-type="bibr">46</xref>]). Thus, our approach may have greater sensitivity to detect discriminable categorical patterns.</p><p>Results of the experience sampling study provide external validation of our emotion-specific biomarkers [<xref rid="pbio.2000106.ref013" ref-type="bibr">13</xref>]. Consistent with the resting-state study, the overall distribution of emotional states was clearly non-uniform, and classifications of neutral states occurred with high frequency. Beyond these commonalities, the inclusion of behavioral self-report led to differences in emotion-related brain activity. States of contentment and amusement were more frequently predicted during experience sampling compared to resting-state (46.31% versus 23.45%), a finding that was corroborated by higher ratings for these emotions in the self-report data. It is possible that this difference in the frequency of positive brain states is the result of a self-presentation bias [<xref rid="pbio.2000106.ref047" ref-type="bibr">47</xref>], wherein participants may have employed emotion regulation in order to project a more positive image. Alternatively, it is possible that the self-reporting task requirement elicited more introspection between trials, which contributed to the pattern of altered emotional states [<xref rid="pbio.2000106.ref048" ref-type="bibr">48</xref>]. Future work will be necessary to fully characterize how such cognitive-emotional interactions shape the landscape of emotional brain states [<xref rid="pbio.2000106.ref036" ref-type="bibr">36</xref>,<xref rid="pbio.2000106.ref049" ref-type="bibr">49</xref>].</p><p>We found that individual differences in mood states and personality traits are associated with the relative incidence of brain states associated with fear, anger, and sadness. These findings further establish the construct validity of our brain-based models of emotion and link subfacets of Neuroticism to the expression of emotion-specific brain systems. Given their sensitivity to individual differences linked to the symptomology of anxiety and depression, spontaneous emotional brain states may serve as a novel diagnostic tool to determine susceptibility to affective illness or as an outcome measure for clinical interventions aimed at reducing the spontaneous elicitation of specific emotions. This tool may be particularly useful to objectively assess the emotional status of individuals who do not have good insight into their emotions, as in alexithymia, or for those who cannot report on their own feelings, including patients in a vegetative or minimally conscious state.</p></sec><sec sec-type="materials|methods" id="sec006"><title>Materials and Methods</title><sec id="sec007"><title>Ethics Statement</title><p>All participants provided written informed consent in accordance with the National Institutes of Health guidelines as approved by the Duke University IRB. The resting state experiment was approved as part of the Duke Neurogenetics Study (Pro00019095) with an associated database (Pro00014717). The experience sampling project was approved separately (Pro00027404).</p></sec><sec id="sec008"><title>Neural Biomarkers of Emotional States</title><p>Classification of emotional states was performed using neural biomarkers that were developed based on blood oxygen level dependent (BOLD) responses to cinematic films and instrumental music [<xref rid="pbio.2000106.ref013" ref-type="bibr">13</xref>]. This induction procedure was selected because it reliably elicits emotional responses over a 1 to 2 min period, as opposed to longer-lasting moods. These models were developed to identify neural patterning specific to states of contentment, amusement, surprise, fear, anger, and sadness (in addition to a neutral control state). These particular emotions were modeled to broadly sample both valence and arousal, as selecting common sets of basic emotions (e.g., fear, anger, sadness, disgust, and happiness) undersamples positive emotions. In selecting these particular emotions, we verified that the accuracy of these models tracked the experience of specific emotion categories (average <italic>R</italic><sup>2</sup> across emotions = .57) independent of subjective valence and arousal. Thus, the models offer unique insight into the emotional state of individuals and characterize the likelihood they would endorse each of the seven emotion labels, independent of general factors such as valence or arousal.</p></sec><sec id="sec009"><title>Resting-State Experiment</title><p>A total of 499 subjects (age = 19.65 &#x000b1; 1.22 years [mean &#x000b1; s.d.], 274 women) were included as part of the Duke Neurogenetics Study (DNS), which assesses a wide range of behavioral and biological traits among healthy, young adult university students. For access to this data, see information provided in <xref ref-type="supplementary-material" rid="pbio.2000106.s007">S1 Text</xref>. This sample was independent of that used to develop the classification models. This sample size is sufficient to reliably detect (&#x003b2; = .01) a moderate effect (r = .2) with a type-I error rate of .05, which is particularly important when studying individual differences in neural activity. All participants provided informed consent in accordance with Duke University guidelines and were in good general health. The participants were free of the following study exclusions: (1) medical diagnoses of cancer, stroke, head injury with loss of consciousness, untreated migraine headaches, diabetes requiring insulin treatment, chronic kidney or liver disease, or lifetime history of psychotic symptoms; (2) use of psychotropic, glucocorticoid, or hypolipidemic medication; and (3) conditions affecting cerebral blood flow and metabolism (e.g., hypertension). Diagnosis of any current DSM-IV Axis I disorder or select Axis II disorders (antisocial personality disorder and borderline personality disorder), assessed with the electronic Mini International Neuropsychiatric Interview [<xref rid="pbio.2000106.ref050" ref-type="bibr">50</xref>] and Structured Clinical Interview for the DSM-IV subtests [<xref rid="pbio.2000106.ref051" ref-type="bibr">51</xref>], were not an exclusion, as the DNS seeks to establish broad variability in multiple behavioral phenotypes related to psychopathology. No participants met criteria for a personality disorder, and 72 (14.4%) participants from our final sample met criteria for at least one Axis I disorder (10 Agoraphobia, 33 Alcohol Abuse, 3 Substance Abuse, 25 Past Major Depressive Episode, 5 Social Phobia). However, as noted above, none of the participants were using psychotropic medication during the course of the DNS.</p><p>Participants were scanned on one of two identical 3 Tesla General Electric MR 750 system with 50-mT/m gradients and an eight channel head coil for parallel imaging (General Electric, Waukesha, Wisconsin, USA). High-resolution 3-dimensional structural images were acquired coplanar with the functional scans (repetition time [TR] = 7.7 s; echo time [TE] = 3.0 ms; flip angle [&#x003b1;] = 12&#x000b0;; voxel size = 0.9 &#x000d7; 0.9 &#x000d7; 4 mm; field of view [FOV] = 240 mm; 34 contiguous slices). For the two 4 min, 16 s resting-state scans, a series of interleaved axial functional slices aligned with the anterior commissure&#x02014;posterior commissure plane were acquired for whole-brain coverage using an inverse-spiral pulse sequence to reduce susceptibility artifact (TR = 2000 ms; TE = 30 ms; &#x003b1; = 60&#x000b0;; FOV = 240 mm; voxel size = 3.75 &#x000d7; 3.75 &#x000d7; 4 mm; 34 contiguous slices). Four initial radiofrequency excitations were performed (and discarded) to achieve steady-state equilibrium. Participants were shown a blank gray screen and instructed to lie still with their eyes open, think about nothing in particular, and remain awake.</p><p>Preprocessing of all resting-state fMRI data was conducted using SPM8 (Wellcome Department of Imaging Neuroscience). Images for each subject were slice-time-corrected, realigned to the first volume in the time series to correct for head motion, spatially normalized into a standard stereotactic space (Montreal Neurological Institute template) using a 12-parameter affine model (final resolution of functional images = 2 mm isotropic voxels), and smoothed with a 6 mm FWHM Gaussian filter. Low-frequency noise was attenuated by high-pass filtering with a 0.0078 Hz cutoff.</p></sec><sec id="sec010"><title>Experience Sampling Experiment</title><p>A total of 22 subjects (age = 26.04 &#x000b1; 5.16 years [mean &#x000b1; s.d.], 11 women) provided informed consent and participated in the study. Data from one participant was excluded from analyses because of excessive head movement (in excess of 1 cm) during scanning. While no statistical test was performed to determine sample size a priori, this sample size is similar to those demonstrating a correspondence between self-report of affect and neural activity [<xref rid="pbio.2000106.ref013" ref-type="bibr">13</xref>,<xref rid="pbio.2000106.ref052" ref-type="bibr">52</xref>,<xref rid="pbio.2000106.ref053" ref-type="bibr">53</xref>].</p><p>Participants engaged in an experience sampling task in which they rated their current feelings during unconstrained rest. Participants were instructed to keep their eyes open and let their mind wander freely and that a rating screen [<xref rid="pbio.2000106.ref054" ref-type="bibr">54</xref>] would occasionally appear, which they should use to indicate the intensity of the emotion that best describes how they currently feel. This validated assay of emotional self-report consists of 16 emotion words organized radially about the center of the screen. Four circles emanate from the center of the screen to each word (similar to a spoke of a wheel), which were used to indicate the intensity of each emotion by moving the cursor about the screen. During four runs of scanning, participants completed 40 trials (10 per run) with an inter-stimulus interval (ISI) of 30 s plus pseudo-random jitter (Poisson distribution, &#x003bb; = 4 s).</p><p>Self-report data were transformed from two-dimensional cursor locations to categorical labels. Polygonal masks were created by hand corresponding to each emotion term on the response screen. A circular mask in the center of the screen was created for neutral responses. Because terms in the standard response screen did not perfectly match those in the neural models, the item &#x0201c;relief&#x0201d; was scored as &#x0201c;content,&#x0201d; whereas &#x0201c;joy&#x0201d; and &#x0201c;satisfaction&#x0201d; were scored as &#x0201c;amusement.&#x0201d; The items &#x0201c;surprise,&#x0201d; &#x0201c;fear,&#x0201d; &#x0201c;anger,&#x0201d; &#x0201c;sadness,&#x0201d; and &#x0201c;neutral&#x0201d; were scored as normal.</p><p>Scanning was performed on a 3 Tesla General Electric MR 750 system with 50-mT/m gradients and an eight channel head coil for parallel imaging (General Electric, Waukesha, Wisconsin, USA). High-resolution images were acquired using a 3D fast SPGR BRAVO pulse sequence (TR = 7.58 ms; TE = 2.936 ms; image matrix = 256<sup>2</sup>; &#x003b1; = 12&#x000b0;; voxel size = 1 &#x000d7; 1 &#x000d7; 1 mm; 206 contiguous slices) for coregistration with the functional data. These structural images were aligned in the near-axial plane defined by the anterior and posterior commissures. Whole-brain functional images were acquired using a spiral-in pulse sequence with sensitivity encoding along the axial plane (TR = 2000 ms; TE = 30 ms; image matrix = 64 &#x000d7; 64; &#x003b1; = 70&#x000b0;; voxel size = 3.8 &#x000d7; 3.8 &#x000d7; 3.8 mm; 34 contiguous slices). Four initial radiofrequency excitations were performed (and discarded) to achieve steady-state equilibrium.</p><p>Processing of MR data was performed using SPM8 (Wellcome Department of Imaging Neuroscience). Functional images were slice-time-corrected, spatially realigned to correct for motion artifacts, coregistered to high resolution anatomical scans, and normalized to Montreal Neurologic Institute (MNI) space using high-dimensional warping implemented in the VBM8 toolbox (<ext-link ext-link-type="uri" xlink:href="http://dbm.neuro.uni-jena.de/vbm.html">http://dbm.neuro.uni-jena.de/vbm.html</ext-link>). Low-frequency noise was attenuated by high-pass filtering with a 0.0078 Hz cutoff.</p></sec><sec id="sec011"><title>Statistical Analysis</title><p>To rescale data for classification, preprocessed time series were standardized by subtracting their mean and dividing by their standard deviation. Maps of partial least squares (PLS) regression coefficients from stimulus-evoked decoding models [<xref rid="pbio.2000106.ref013" ref-type="bibr">13</xref>] were resliced to match the voxel size of functional data. These coefficients are conceptually similar to those in multiple linear regression, only they are computed by identifying a small number of factors (reducing the dimensionality of the problem) that maximize the covariance between patterns of neural activation and emotion labels (for specifics on their computation, see [<xref rid="pbio.2000106.ref055" ref-type="bibr">55</xref>]). Classifier scores were computed by taking the scalar product of functional data at each time point and PLS regression coefficients from content, amusement, surprise, fear, anger, sad, and neutral models. Individual time points were assigned categorical labels by identifying the model with the maximal score.</p><p>In order to determine if relatively focal or diffuse patterns of resting-state activity informed classification, we computed importance maps for each subject (<xref ref-type="supplementary-material" rid="pbio.2000106.s001">S1 Fig</xref>). This was accomplished by calculating the voxel-wise product between PLS regression coefficients for each emotion model and the average activity of acquisition time points labeled as the corresponding emotion. We made inference on these maps by conducting a mass-univariate one-sample <italic>t</italic> test for each of the seven models, thresholding at FDR <italic>q</italic> = .05.</p><p>To address the potential overlap of the emotion classification models and canonical resting-state networks of the brain, we computed the maximal Jaccard index for each emotion model and the seven most prominent resting-state networks identified in Yeo et al [<xref rid="pbio.2000106.ref026" ref-type="bibr">26</xref>]. This index is computed as the intersection of voxels in the two maps (voxels above threshold in both maps) relative to their union (the number of voxels above threshold in either map). Thresholds for classification models were adaptively matched to equate the proportion of voxels assigned to each resting state network.</p><p>When conducting inferential tests on classification frequency (count data), non-parametric tests were conducted. To test whether classifications were uniformly distributed across the emotion categories, a Friedman test was performed (<italic>n</italic> = 499 subjects, k = 7 emotions). Wilcoxon signed-rank tests were performed to test for differences in frequency relative to chance rates (14.3%) in addition to pairwise comparisons between emotion models, and corrected for multiple comparisons based on the false-discovery rate.</p><p>Because the models have different levels of accuracy when used for seven-way classification [<xref rid="pbio.2000106.ref013" ref-type="bibr">13</xref>], we additionally conducted wavelet resampling of classifier scores in the time domain [<xref rid="pbio.2000106.ref033" ref-type="bibr">33</xref>,<xref rid="pbio.2000106.ref056" ref-type="bibr">56</xref>] over 100 iterations to ensure that differences in the sensitivity of models did not bias results. This procedure involved scrambling the wavelet coefficients (identified using the discrete wavelet transform) of classifier scores (time series in <xref ref-type="fig" rid="pbio.2000106.g003">Fig 3</xref>) to generate random time series with similar autocorrelation as the original data. Classifications were then made on these surrogate time series, and Friedman tests were performed to test for differences in frequencies across categories. This procedure yielded a null distribution for the chi-square statistic against which the observed statistic on unscrambled data was compared.</p><p>To test whether classifier scores changed over time, Friedman tests were conducted on the outputs of the emotion models separately (concatenating the time series across runs), as classifier scores were found to violate assumptions of normality. Follow-up tests on the direction of these changes (either as increases or decreases) were conducted using general linear models with one constant regressor and another for linearly increasing time for each subject. Inference on the parameter estimate for changes over time was made using a one-sample <italic>t</italic> test (498 degrees of freedom).</p><p>In addition to testing gradual changes over time, smoothing spline models [<xref rid="pbio.2000106.ref025" ref-type="bibr">25</xref>] were used to characterize more complex dynamics of emotional states. Because spline models are flexible and may include a different number of parameters for each subject, cross-validation was conducted to assess the coherence of spline fits across subjects. In this procedure, a smoothing spline model was fit for each subject, and its Pearson correlation with the mean fit for all other subjects was computed. The average of resulting correlations accordingly reflects the coherence of nonlinear changes in emotional states across all subjects.</p><p>The influence of individual differences in mood and personality was assessed using generalized linear models with a binomial distribution and a logit link function. Multiple models were constructed, each using a single measure from either the CESD, STAI, or facets from the NEO-PI-R to predict the frequency of classifications for the seven emotion categories (seven models per self-report measure). Inference on parameter estimates (characterizing relationships between individual difference measures and classification frequency) was made using a <italic>t</italic> distribution with 497 degrees of freedom.</p><p>To control for multiple comparisons, FDR correction (<italic>q</italic> = .05) [<xref rid="pbio.2000106.ref057" ref-type="bibr">57</xref>,<xref rid="pbio.2000106.ref058" ref-type="bibr">58</xref>] was applied for targeted predictions. For individual differences in mood, this procedure included correction for positive associations between the frequency of sad classifications and CESD scores and between fear classification and STAI values (<italic>P</italic><sub>thresh</sub> = .0091). For differences in emotional traits, correction was applied to models predicting the frequency of fear classification on the basis of Anxiety scores, anger classification using Angry Hostility scores, and sad classifications on the basis of Depression scores (<italic>P</italic><sub>thresh</sub> = .0479). Scatterplots and predicted outcomes for these regression analyses are displayed in <xref ref-type="supplementary-material" rid="pbio.2000106.s004">S4 Fig</xref>.</p><p>To assess concordance in the experience sampling study, classifier scores were averaged for trials congruent and incongruent with self-report for each subject. For instance, all trials in which a participant self-reported &#x0201c;fear,&#x0201d; the classifier outputs from the neural model predicting fear were considered congruent, whereas the remaining six models were averaged as incongruent. Because the frequency of self-report varied across emotions (e.g., endorsement of fear and sadness were very infrequent), scores were averaged across all trials to reduce noise.</p><p>In a supplemental analysis, scores were extracted separately for all trials and classified by identifying the model with the highest score. Accuracy was assessed on data from all subjects, using self-reports of emotion as ground truth. Because the frequency of self-reported emotions was non-uniform, chance agreement between self-report and neural models was calculated based on the product of marginal frequencies, under the assumption of independent observer classifications [<xref rid="pbio.2000106.ref059" ref-type="bibr">59</xref>]. Inference on the observed classification accuracy was tested against this value using the binomial distribution <italic>B</italic>(480, 0.2147). Due to infrequent self-reports of surprise, fear, and anger, accuracy on individual models was not computed.</p><p>Scores were initially assessed by averaging the 10 s preceding each rating. Subsequent analyses increasing the window length up to 20 s did not alter results. Because the scores for congruent (<italic>p</italic> = 0.0186, Lilliefors test against normal distribution) and incongruent (<italic>p</italic> = 0.0453) trials exhibited non-normal distributions, Wilcoxon signed rank tests were used to test each sample against zero mean rank. The correspondence between the frequencies of classification labels from self-report and neural decoding was assessed by computing the Pearson correlation for each subject. The correlation coefficients were Fisher transformed and tested against zero using a one-sample <italic>t</italic> test.</p><p>To ensure that population differences (i.e., inclusion of individuals with psychopathology) did not contribute to differences in the prevalence of emotions in the resting-state and experience sampling studies, we re-calculated the frequency of classifications using repeated random subsampling of healthy participants in the resting-state sample (1,000 iterations, sampling 21 participants without replacement). The average correlation between the healthy subsamples and the full sample was very high (r<sub>avg</sub> = .981, s.d. = .013), making it unlikely that clinical status accounts for differences in the frequency of classifications across studies.</p></sec></sec><sec sec-type="supplementary-material" id="sec012"><title>Supporting Information</title><supplementary-material content-type="local-data" id="pbio.2000106.s001"><label>S1 Fig</label><caption><title>Importance maps for resting-state experiment.</title><p>Parametric maps of t-statistics (one-sample t-test against 0) showing voxels whose activation (either positive or negative) contributed towards classification of (A) content, (B) amusement, (C) surprise, (D) fear, (E) anger, (F) sad, and (G) neutral states. Importance maps were created for each subject by taking voxel-wise product of classification weights and the mean activity of time-points assigned the corresponding label. Voxels are thresholded at an FDR corrected <italic>q</italic> = .05. The raw fMRI resting state data can be obtained from <ext-link ext-link-type="uri" xlink:href="https://www.haririlab.com/projects">https://www.haririlab.com/projects</ext-link>.</p><p>(TIF)</p></caption><media xlink:href="pbio.2000106.s001.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pbio.2000106.s002"><label>S2 Fig</label><caption><title>Null frequency distributions for the classification of all seven emotional states (n = 499).</title><p>(A) Colored distributions reflect the average frequency over 100 iterations of wavelet resampling. The mean, 25th and 75th percentiles are indicated by black lines. The solid gray line indicates the number of trials which would occur from random guessing. The range of the axes are matched to those in <xref ref-type="fig" rid="pbio.2000106.g002">Fig 2B</xref> for ease of comparison. (B) Distribution of &#x003c7;<sup>2</sup> statistics across 100 iterations (Friedman test against uniform distribution), compared to that of the unpermuted data (solid red line). The data underlying this figure can be found in <xref ref-type="supplementary-material" rid="pbio.2000106.s006">S1 Data</xref>. The raw fMRI resting state data can be obtained from <ext-link ext-link-type="uri" xlink:href="https://www.haririlab.com/projects">https://www.haririlab.com/projects</ext-link>.</p><p>(TIF)</p></caption><media xlink:href="pbio.2000106.s002.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pbio.2000106.s003"><label>S3 Fig</label><caption><title>&#x02113;2-norms of models and data.</title><p>(A) &#x02113;2-norms computed for each of the neural biomarkers of emotion. The &#x02113;2-norm is calculated by taking the square root of the sum of squared deviations across all voxels (i.e., Euclidean distance). These norms do not vary strongly across emotion models, indicating that the outputs of classifiers are typically on the same scale. (B) Mean (s.d.) of &#x02113;2-norms computed on the resting state data (n = 499 subjects). Each time-point reflects a single data acquisition lasting two seconds. Solid vertical line demarcates scans from the first and second run. The data underlying this figure can be found in <xref ref-type="supplementary-material" rid="pbio.2000106.s006">S1 Data</xref>. The raw fMRI resting state data can be obtained from <ext-link ext-link-type="uri" xlink:href="https://www.haririlab.com/projects">https://www.haririlab.com/projects</ext-link>.</p><p>(TIF)</p></caption><media xlink:href="pbio.2000106.s003.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pbio.2000106.s004"><label>S4 Fig</label><caption><title>Logistic regression models predicting the frequency of emotional states from individual difference measures.</title><p>(A) Associations between self-reported anxiety and fear classifications (left) and between depressive symptoms and sad classifications (right). (B) Associations between the NEO scores for the Anxiety subfacet and fear classifications (left), between Angry Hostility and anger classifications (middle), and between Depression and sad classifications (right). Solid curves reflect the best fitting binomial model, semi-transparent curves reflect variation about the mean estimated by bootstrap resampling. Correlations between the estimated and observed classification frequencies are displayed on the upper right of each panel. The data underlying this figure can be found in <xref ref-type="supplementary-material" rid="pbio.2000106.s006">S1 Data</xref>. The raw fMRI resting state data can be obtained from <ext-link ext-link-type="uri" xlink:href="https://www.haririlab.com/projects">https://www.haririlab.com/projects</ext-link>.</p><p>(TIF)</p></caption><media xlink:href="pbio.2000106.s004.tif"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pbio.2000106.s005"><label>S1 Table</label><caption><title>Friedman&#x02019;s ANOVAs for changes in classification scores over time.</title><p>(XLSX)</p></caption><media xlink:href="pbio.2000106.s005.xlsx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pbio.2000106.s006"><label>S1 Data</label><caption><title>Raw data underlying plots in <xref ref-type="fig" rid="pbio.2000106.g001">Fig 1</xref> (panel B), <xref ref-type="fig" rid="pbio.2000106.g002">Fig 2</xref> (panel B), Figs <xref ref-type="fig" rid="pbio.2000106.g003">3</xref> and <xref ref-type="fig" rid="pbio.2000106.g004">4</xref> (panels A and B), <xref ref-type="fig" rid="pbio.2000106.g005">Fig 5</xref> (panels B and C), <xref ref-type="supplementary-material" rid="pbio.2000106.s002">S2 Fig</xref> (panels A and B), <xref ref-type="supplementary-material" rid="pbio.2000106.s003">S3 Fig</xref> (panels A and B), and <xref ref-type="supplementary-material" rid="pbio.2000106.s004">S4 Fig</xref> (panels A and B).</title><p>(XLSX)</p></caption><media xlink:href="pbio.2000106.s006.xlsx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pbio.2000106.s007"><label>S1 Text</label><caption><title>Data sharing restrictions explanation.</title><p>(DOCX)</p></caption><media xlink:href="pbio.2000106.s007.docx"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>We thank the laboratory of NeuroGenetics for collection of resting-state data.</p></ack><glossary><title>Abbreviations</title><def-list><def-item><term>CESD</term><def><p>Center for Epidemiologic Studies Depression Scale</p></def></def-item><def-item><term>NEO-PI-R</term><def><p>Revised NEO Personality Inventory</p></def></def-item><def-item><term>STAI-S</term><def><p>State-Trait Anxiety Inventory State Version</p></def></def-item></def-list></glossary><ref-list><title>References</title><ref id="pbio.2000106.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Norman</surname><given-names>KA</given-names></name>, <name><surname>Polyn</surname><given-names>SM</given-names></name>, <name><surname>Detre</surname><given-names>GJ</given-names></name>, <name><surname>Haxby</surname><given-names>JV</given-names></name>. <article-title>Beyond mind-reading: multi-voxel pattern analysis of fMRI data</article-title>. <source>Trends Cogn Sci</source>. <year>2006</year>;<volume>10</volume>(<issue>9</issue>):<fpage>424</fpage>&#x02013;<lpage>30</lpage>. <pub-id pub-id-type="doi">10.1016/j.tics.2006.07.005</pub-id> .<?supplied-pmid 16899397?><pub-id pub-id-type="pmid">16899397</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>O'Toole</surname><given-names>AJ</given-names></name>, <name><surname>Jiang</surname><given-names>F</given-names></name>, <name><surname>Abdi</surname><given-names>H</given-names></name>, <name><surname>Penard</surname><given-names>N</given-names></name>, <name><surname>Dunlop</surname><given-names>JP</given-names></name>, <name><surname>Parent</surname><given-names>MA</given-names></name>. <article-title>Theoretical, statistical, and practical perspectives on pattern-based classification approaches to the analysis of functional neuroimaging data</article-title>. <source>J Cogn Neurosci</source>. <year>2007</year>;<volume>19</volume>(<issue>11</issue>):<fpage>1735</fpage>&#x02013;<lpage>52</lpage>. <pub-id pub-id-type="doi">10.1162/jocn.2007.19.11.1735</pub-id> .<?supplied-pmid 17958478?><pub-id pub-id-type="pmid">17958478</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Haxby</surname><given-names>JV</given-names></name>, <name><surname>Gobbini</surname><given-names>MI</given-names></name>, <name><surname>Furey</surname><given-names>ML</given-names></name>, <name><surname>Ishai</surname><given-names>A</given-names></name>, <name><surname>Schouten</surname><given-names>JL</given-names></name>, <name><surname>Pietrini</surname><given-names>P</given-names></name>. <article-title>Distributed and overlapping representations of faces and objects in ventral temporal cortex</article-title>. <source>Science</source>. <year>2001</year>;<volume>293</volume>(<issue>5539</issue>):<fpage>2425</fpage>&#x02013;<lpage>30</lpage>. <pub-id pub-id-type="doi">10.1126/science.1063736</pub-id> .<?supplied-pmid 11577229?><pub-id pub-id-type="pmid">11577229</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Kamitani</surname><given-names>Y</given-names></name>, <name><surname>Tong</surname><given-names>F</given-names></name>. <article-title>Decoding the visual and subjective contents of the human brain</article-title>. <source>Nat Neurosci</source>. <year>2005</year>;<volume>8</volume>(<issue>5</issue>):<fpage>679</fpage>&#x02013;<lpage>85</lpage>. <pub-id pub-id-type="doi">10.1038/nn1444</pub-id>
<?supplied-pmid 15852014?><pub-id pub-id-type="pmid">15852014</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Tong</surname><given-names>F</given-names></name>, <name><surname>Pratte</surname><given-names>MS</given-names></name>. <article-title>Decoding patterns of human brain activity</article-title>. <source>Annu Rev Psychol</source>. <year>2012</year>;<volume>63</volume>:<fpage>483</fpage>&#x02013;<lpage>509</lpage>. <pub-id pub-id-type="doi">10.1146/annurev-psych-120710-100412</pub-id> .<?supplied-pmid 21943172?><pub-id pub-id-type="pmid">21943172</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Harrison</surname><given-names>SA</given-names></name>, <name><surname>Tong</surname><given-names>F</given-names></name>. <article-title>Decoding reveals the contents of visual working memory in early visual areas</article-title>. <source>Nature</source>. <year>2009</year>;<volume>458</volume>(<issue>7238</issue>):<fpage>632</fpage>&#x02013;<lpage>5</lpage>. <pub-id pub-id-type="doi">10.1038/nature07832</pub-id>
<?supplied-pmid 19225460?><pub-id pub-id-type="pmid">19225460</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref007"><label>7</label><mixed-citation publication-type="journal"><name><surname>Serences</surname><given-names>JT</given-names></name>, <name><surname>Ester</surname><given-names>EF</given-names></name>, <name><surname>Vogel</surname><given-names>EK</given-names></name>, <name><surname>Awh</surname><given-names>E</given-names></name>. <article-title>Stimulus-specific delay activity in human primary visual cortex</article-title>. <source>Psychol Sci</source>. <year>2009</year>;<volume>20</volume>(<issue>2</issue>):<fpage>207</fpage>&#x02013;<lpage>14</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02276.x</pub-id>
<?supplied-pmid 19170936?><pub-id pub-id-type="pmid">19170936</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref008"><label>8</label><mixed-citation publication-type="journal"><name><surname>Lewis-Peacock</surname><given-names>JA</given-names></name>, <name><surname>Postle</surname><given-names>BR</given-names></name>. <article-title>Temporary activation of long-term memory supports working memory</article-title>. <source>J Neurosci</source>. <year>2008</year>;<volume>28</volume>(<issue>35</issue>):<fpage>8765</fpage>&#x02013;<lpage>71</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.1953-08.2008</pub-id>
<?supplied-pmid 18753378?><pub-id pub-id-type="pmid">18753378</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Stokes</surname><given-names>M</given-names></name>, <name><surname>Thompson</surname><given-names>R</given-names></name>, <name><surname>Cusack</surname><given-names>R</given-names></name>, <name><surname>Duncan</surname><given-names>J</given-names></name>. <article-title>Top-down activation of shape-specific population codes in visual cortex during mental imagery</article-title>. <source>J Neurosci</source>. <year>2009</year>;<volume>29</volume>(<issue>5</issue>):<fpage>1565</fpage>&#x02013;<lpage>72</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.4657-08.2009</pub-id> .<?supplied-pmid 19193903?><pub-id pub-id-type="pmid">19193903</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Reddy</surname><given-names>L</given-names></name>, <name><surname>Tsuchiya</surname><given-names>N</given-names></name>, <name><surname>Serre</surname><given-names>T</given-names></name>. <article-title>Reading the mind's eye: decoding category information during mental imagery</article-title>. <source>Neuroimage</source>. <year>2010</year>;<volume>50</volume>(<issue>2</issue>):<fpage>818</fpage>&#x02013;<lpage>25</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.11.084</pub-id>
<?supplied-pmid 20004247?><pub-id pub-id-type="pmid">20004247</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Horikawa</surname><given-names>T</given-names></name>, <name><surname>Tamaki</surname><given-names>M</given-names></name>, <name><surname>Miyawaki</surname><given-names>Y</given-names></name>, <name><surname>Kamitani</surname><given-names>Y</given-names></name>. <article-title>Neural decoding of visual imagery during sleep</article-title>. <source>Science</source>. <year>2013</year>;<volume>340</volume>(<issue>6132</issue>):<fpage>639</fpage>&#x02013;<lpage>42</lpage>. <pub-id pub-id-type="doi">10.1126/science.1234330</pub-id> .<?supplied-pmid 23558170?><pub-id pub-id-type="pmid">23558170</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref012"><label>12</label><mixed-citation publication-type="journal"><name><surname>Poldrack</surname><given-names>RA</given-names></name>, <name><surname>Halchenko</surname><given-names>YO</given-names></name>, <name><surname>Hanson</surname><given-names>SJ</given-names></name>. <article-title>Decoding the large-scale structure of brain function by classifying mental States across individuals</article-title>. <source>Psychol Sci</source>. <year>2009</year>;<volume>20</volume>(<issue>11</issue>):<fpage>1364</fpage>&#x02013;<lpage>72</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.2009.02460.x</pub-id>
<?supplied-pmid 19883493?><pub-id pub-id-type="pmid">19883493</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref013"><label>13</label><mixed-citation publication-type="journal"><name><surname>Kragel</surname><given-names>PA</given-names></name>, <name><surname>LaBar</surname><given-names>KS</given-names></name>. <article-title>Multivariate neural biomarkers of emotional states are categorically distinct</article-title>. <source>Soc Cogn Affect Neurosci</source>. <year>2015</year>;<volume>10</volume>(<issue>11</issue>):<fpage>1437</fpage>&#x02013;<lpage>48</lpage>. <pub-id pub-id-type="doi">10.1093/scan/nsv032</pub-id>
<?supplied-pmid 25813790?><pub-id pub-id-type="pmid">25813790</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Saarimaki</surname><given-names>H</given-names></name>, <name><surname>Gotsopoulos</surname><given-names>A</given-names></name>, <name><surname>Jaaskelainen</surname><given-names>IP</given-names></name>, <name><surname>Lampinen</surname><given-names>J</given-names></name>, <name><surname>Vuilleumier</surname><given-names>P</given-names></name>, <name><surname>Hari</surname><given-names>R</given-names></name>, <etal>et al</etal>
<article-title>Discrete Neural Signatures of Basic Emotions</article-title>. <source>Cereb Cortex</source>. <year>2016</year>
<month>6</month>;<volume>26</volume>(<issue>6</issue>):<fpage>2563</fpage>&#x02013;<lpage>73</lpage>. bhv086 [pii] <pub-id pub-id-type="doi">10.1093/cercor/bhv086</pub-id> .<?supplied-pmid 25924952?><pub-id pub-id-type="pmid">25924952</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Fox</surname><given-names>MD</given-names></name>, <name><surname>Raichle</surname><given-names>ME</given-names></name>. <article-title>Spontaneous fluctuations in brain activity observed with functional magnetic resonance imaging</article-title>. <source>Nat Rev Neurosci</source>. <year>2007</year>;<volume>8</volume>(<issue>9</issue>):<fpage>700</fpage>&#x02013;<lpage>11</lpage>. Epub 2007/08/21. <pub-id pub-id-type="doi">10.1038/nrn2201</pub-id> .<?supplied-pmid 17704812?><pub-id pub-id-type="pmid">17704812</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref016"><label>16</label><mixed-citation publication-type="journal"><name><surname>Vincent</surname><given-names>JL</given-names></name>, <name><surname>Patel</surname><given-names>GH</given-names></name>, <name><surname>Fox</surname><given-names>MD</given-names></name>, <name><surname>Snyder</surname><given-names>AZ</given-names></name>, <name><surname>Baker</surname><given-names>JT</given-names></name>, <name><surname>Van Essen</surname><given-names>DC</given-names></name>, <etal>et al</etal>
<article-title>Intrinsic functional architecture in the anaesthetized monkey brain</article-title>. <source>Nature</source>. <year>2007</year>;<volume>447</volume>(<issue>7140</issue>):<fpage>83</fpage>&#x02013;<lpage>U4</lpage>. <pub-id pub-id-type="doi">10.1038/Nature05758</pub-id><comment>.</comment> ISI:000246149300048. <?supplied-pmid 17476267?><pub-id pub-id-type="pmid">17476267</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Kenet</surname><given-names>T</given-names></name>, <name><surname>Bibitchkov</surname><given-names>D</given-names></name>, <name><surname>Tsodyks</surname><given-names>M</given-names></name>, <name><surname>Grinvald</surname><given-names>A</given-names></name>, <name><surname>Arieli</surname><given-names>A</given-names></name>. <article-title>Spontaneously emerging cortical representations of visual attributes</article-title>. <source>Nature</source>. <year>2003</year>;<volume>425</volume>(<issue>6961</issue>):<fpage>954</fpage>&#x02013;<lpage>6</lpage>. Epub 2003/10/31. <pub-id pub-id-type="doi">10.1038/nature02078</pub-id> .<?supplied-pmid 14586468?><pub-id pub-id-type="pmid">14586468</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref018"><label>18</label><mixed-citation publication-type="journal"><name><surname>Russell</surname><given-names>JA</given-names></name>. <article-title>A Circumplex Model of Affect</article-title>. <source>J Pers Soc Psychol</source>. <year>1980</year>;<volume>39</volume>(<issue>6</issue>):<fpage>1161</fpage>&#x02013;<lpage>78</lpage>. <pub-id pub-id-type="doi">10.1037/H0077714</pub-id><comment>.</comment> WOS:A1980KX30300015.</mixed-citation></ref><ref id="pbio.2000106.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>DeNeve</surname><given-names>KM</given-names></name>, <name><surname>Cooper</surname><given-names>H</given-names></name>. <article-title>The happy personality: a meta-analysis of 137 personality traits and subjective well-being</article-title>. <source>Psychol Bull</source>. <year>1998</year>;<volume>124</volume>(<issue>2</issue>):<fpage>197</fpage>&#x02013;<lpage>229</lpage>. .<?supplied-pmid 9747186?><pub-id pub-id-type="pmid">9747186</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Costa</surname><given-names>PT</given-names><suffix>Jr.</suffix></name>, <name><surname>McCrae</surname><given-names>RR</given-names></name>. <article-title>Influence of extraversion and neuroticism on subjective well-being: happy and unhappy people</article-title>. <source>J Pers Soc Psychol</source>. <year>1980</year>;<volume>38</volume>(<issue>4</issue>):<fpage>668</fpage>&#x02013;<lpage>78</lpage>. .<?supplied-pmid 7381680?><pub-id pub-id-type="pmid">7381680</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Lahey</surname><given-names>BB</given-names></name>. <article-title>Public health significance of neuroticism</article-title>. <source>Am Psychol</source>. <year>2009</year>;<volume>64</volume>(<issue>4</issue>):<fpage>241</fpage>&#x02013;<lpage>56</lpage>. <pub-id pub-id-type="doi">10.1037/a0015309</pub-id>
<?supplied-pmid 19449983?><pub-id pub-id-type="pmid">19449983</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref022"><label>22</label><mixed-citation publication-type="journal"><name><surname>Chapman</surname><given-names>HA</given-names></name>, <name><surname>Bernier</surname><given-names>D</given-names></name>, <name><surname>Rusak</surname><given-names>B</given-names></name>. <article-title>MRI-related anxiety levels change within and between repeated scanning sessions</article-title>. <source>Psychiat Res-Neuroim</source>. <year>2010</year>;<volume>182</volume>(<issue>2</issue>):<fpage>160</fpage>&#x02013;<lpage>4</lpage>. <pub-id pub-id-type="doi">10.1016/j.pscychresns.2010.01.005</pub-id><comment>.</comment> ISI:000278701500012.</mixed-citation></ref><ref id="pbio.2000106.ref023"><label>23</label><mixed-citation publication-type="journal"><name><surname>van Minde</surname><given-names>D</given-names></name>, <name><surname>Klaming</surname><given-names>L</given-names></name>, <name><surname>Weda</surname><given-names>H</given-names></name>. <article-title>Pinpointing Moments of High Anxiety During an MRI Examination</article-title>. <source>Int J Behav Med</source>. <year>2014</year>;<volume>21</volume>(<issue>3</issue>):<fpage>487</fpage>&#x02013;<lpage>95</lpage>. <pub-id pub-id-type="doi">10.1007/s12529-013-9339-5</pub-id><comment>.</comment> ISI:000335770800010. <?supplied-pmid 24043600?><pub-id pub-id-type="pmid">24043600</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref024"><label>24</label><mixed-citation publication-type="journal"><name><surname>Muehlhan</surname><given-names>M</given-names></name>, <name><surname>Lueken</surname><given-names>U</given-names></name>, <name><surname>Wittchen</surname><given-names>HU</given-names></name>, <name><surname>Kirschbaum</surname><given-names>C</given-names></name>. <article-title>The scanner as a stressor: Evidence from subjective and neuroendocrine stress parameters in the time course of a functional magnetic resonance imaging session</article-title>. <source>Int J Psychophysiol</source>. <year>2011</year>;<volume>79</volume>(<issue>2</issue>):<fpage>118</fpage>&#x02013;<lpage>26</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijpsycho.2010.09.009</pub-id><comment>.</comment> ISI:000288294700005. <?supplied-pmid 20875462?><pub-id pub-id-type="pmid">20875462</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Reinsch</surname><given-names>CH</given-names></name>. <article-title>Smoothing by spline functions</article-title>. <source>Numerische mathematik</source>. <year>1967</year>;<volume>10</volume>(<issue>3</issue>):<fpage>177</fpage>&#x02013;<lpage>83</lpage>.</mixed-citation></ref><ref id="pbio.2000106.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Yeo</surname><given-names>BT</given-names></name>, <name><surname>Krienen</surname><given-names>FM</given-names></name>, <name><surname>Sepulcre</surname><given-names>J</given-names></name>, <name><surname>Sabuncu</surname><given-names>MR</given-names></name>, <name><surname>Lashkari</surname><given-names>D</given-names></name>, <name><surname>Hollinshead</surname><given-names>M</given-names></name>, <etal>et al</etal>
<article-title>The organization of the human cerebral cortex estimated by intrinsic functional connectivity</article-title>. <source>J Neurophysiol</source>. <year>2011</year>;<volume>106</volume>(<issue>3</issue>):<fpage>1125</fpage>&#x02013;<lpage>65</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00338.2011</pub-id>
<?supplied-pmid 21653723?><pub-id pub-id-type="pmid">21653723</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref027"><label>27</label><mixed-citation publication-type="journal"><name><surname>Radloff</surname><given-names>LS</given-names></name>. <article-title>The CES-D Scale: A Self-Report Depression Scale for Research in the General Population</article-title>. <source>Applied Psychological Measurement</source>. <year>1977</year>;<volume>1</volume>(<issue>3</issue>):<fpage>385</fpage>&#x02013;<lpage>401</lpage>. <pub-id pub-id-type="doi">10.1177/014662167700100306</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref028"><label>28</label><mixed-citation publication-type="other">Spielberger CD, Gorsuch RL, Lushene RE. Manual for the state-trait anxiety inventory. 1970.</mixed-citation></ref><ref id="pbio.2000106.ref029"><label>29</label><mixed-citation publication-type="journal"><name><surname>Costa</surname><given-names>PT</given-names></name>, <name><surname>McCrae</surname><given-names>RR</given-names></name>. <article-title>The revised NEO personality inventory (NEO-PI-R)</article-title>. <source>The SAGE Handbook of Personality Theory and Assessment</source>. <year>2008</year>;<volume>2</volume>:<fpage>179</fpage>&#x02013;<lpage>98</lpage>.</mixed-citation></ref><ref id="pbio.2000106.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Costa</surname><given-names>PT</given-names></name>, <name><surname>McCrae</surname><given-names>RR</given-names></name>. <article-title>Domains and Facets&#x02014;Hierarchical Personality-Assessment Using the Revised NEO Personality-Inventory</article-title>. <source>J Pers Assess</source>. <year>1995</year>;<volume>64</volume>(<issue>1</issue>):<fpage>21</fpage>&#x02013;<lpage>50</lpage>. <pub-id pub-id-type="doi">10.1207/s15327752jpa6401_2</pub-id><comment>.</comment> ISI:A1995QE82600002. <?supplied-pmid 16367732?><pub-id pub-id-type="pmid">16367732</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref031"><label>31</label><mixed-citation publication-type="journal"><name><surname>Jang</surname><given-names>KL</given-names></name>, <name><surname>Livesley</surname><given-names>WJ</given-names></name>, <name><surname>Vernon</surname><given-names>PA</given-names></name>. <article-title>Heritability of the big five personality dimensions and their facets: A twin study</article-title>. <source>J Pers</source>. <year>1996</year>;<volume>64</volume>(<issue>3</issue>):<fpage>577</fpage>&#x02013;<lpage>91</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-6494.1996.tb00522.x</pub-id><comment>.</comment> ISI:A1996VD76400002. <?supplied-pmid 8776880?><pub-id pub-id-type="pmid">8776880</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref032"><label>32</label><mixed-citation publication-type="journal"><name><surname>McCrae</surname><given-names>RR</given-names></name>, <name><surname>Costa</surname><given-names>PT</given-names></name>. <article-title>Personality trait structure as a human universal</article-title>. <source>Am Psychol</source>. <year>1997</year>;<volume>52</volume>(<issue>5</issue>):<fpage>509</fpage>&#x02013;<lpage>16</lpage>. <pub-id pub-id-type="doi">10.1037/0003-066x.52.5.509</pub-id><comment>.</comment> ISI:A1997WW85400001. <?supplied-pmid 9145021?><pub-id pub-id-type="pmid">9145021</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref033"><label>33</label><mixed-citation publication-type="journal"><name><surname>Polyn</surname><given-names>SM</given-names></name>, <name><surname>Natu</surname><given-names>VS</given-names></name>, <name><surname>Cohen</surname><given-names>JD</given-names></name>, <name><surname>Norman</surname><given-names>KA</given-names></name>. <article-title>Category-specific cortical activity precedes retrieval during memory search</article-title>. <source>Science</source>. <year>2005</year>;<volume>310</volume>(<issue>5756</issue>):<fpage>1963</fpage>&#x02013;<lpage>6</lpage>. <pub-id pub-id-type="doi">10.1126/science.1117645</pub-id> .<?supplied-pmid 16373577?><pub-id pub-id-type="pmid">16373577</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref034"><label>34</label><mixed-citation publication-type="journal"><name><surname>Oatley</surname><given-names>K</given-names></name>, <name><surname>Johnson-Laird</surname><given-names>PN</given-names></name>. <article-title>Towards a cognitive theory of emotions</article-title>. <source>Cognition and emotion</source>. <year>1987</year>;<volume>1</volume>(<issue>1</issue>):<fpage>29</fpage>&#x02013;<lpage>50</lpage>.</mixed-citation></ref><ref id="pbio.2000106.ref035"><label>35</label><mixed-citation publication-type="journal"><name><surname>Ekman</surname><given-names>P</given-names></name>, <name><surname>Cordaro</surname><given-names>D</given-names></name>. <article-title>What is Meant by Calling Emotions Basic</article-title>. <source>Emot Rev</source>. <year>2011</year>;<volume>3</volume>(<issue>4</issue>):<fpage>364</fpage>&#x02013;<lpage>70</lpage>. <pub-id pub-id-type="doi">10.1177/1754073911410740</pub-id><comment>.</comment> WOS:000306274900002.</mixed-citation></ref><ref id="pbio.2000106.ref036"><label>36</label><mixed-citation publication-type="journal"><name><surname>Pessoa</surname><given-names>L</given-names></name>. <article-title>On the relationship between emotion and cognition</article-title>. <source>Nat Rev Neurosci</source>. <year>2008</year>;<volume>9</volume>(<issue>2</issue>):<fpage>148</fpage>&#x02013;<lpage>58</lpage>. WOS:000252503300016. <pub-id pub-id-type="doi">10.1038/nrn2317</pub-id>
<?supplied-pmid 18209732?><pub-id pub-id-type="pmid">18209732</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref037"><label>37</label><mixed-citation publication-type="journal"><name><surname>Lindquist</surname><given-names>KA</given-names></name>, <name><surname>Wager</surname><given-names>TD</given-names></name>, <name><surname>Kober</surname><given-names>H</given-names></name>, <name><surname>Bliss-Moreau</surname><given-names>E</given-names></name>, <name><surname>Barrett</surname><given-names>LF</given-names></name>. <article-title>The brain basis of emotion: a meta-analytic review</article-title>. <source>Behav Brain Sci</source>. <year>2012</year>;<volume>35</volume>(<issue>3</issue>):<fpage>121</fpage>&#x02013;<lpage>43</lpage>. Epub 2012/05/24. <pub-id pub-id-type="doi">10.1017/S0140525X11000446</pub-id>
<?supplied-pmid 22617651?><pub-id pub-id-type="pmid">22617651</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref038"><label>38</label><mixed-citation publication-type="journal"><name><surname>Scherer</surname><given-names>KR</given-names></name>. <article-title>Emotions are emergent processes: they require a dynamic computational architecture</article-title>. <source>Philos T R Soc B</source>. <year>2009</year>;<volume>364</volume>(<issue>1535</issue>):<fpage>3459</fpage>&#x02013;<lpage>74</lpage>. WOS:000271333900004.</mixed-citation></ref><ref id="pbio.2000106.ref039"><label>39</label><mixed-citation publication-type="journal"><name><surname>Eryilmaz</surname><given-names>H</given-names></name>, <name><surname>De Ville</surname><given-names>DV</given-names></name>, <name><surname>Schwartz</surname><given-names>S</given-names></name>, <name><surname>Vuilleumier</surname><given-names>P</given-names></name>. <article-title>Lasting Impact of Regret and Gratification on Resting Brain Activity and Its Relation to Depressive Traits</article-title>. <source>Journal of Neuroscience</source>. <year>2014</year>;<volume>34</volume>(<issue>23</issue>):<fpage>7825</fpage>&#x02013;<lpage>35</lpage>. WOS:000337630700011. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0065-14.2014</pub-id>
<?supplied-pmid 24899706?><pub-id pub-id-type="pmid">24899706</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref040"><label>40</label><mixed-citation publication-type="journal"><name><surname>Eryilmaz</surname><given-names>H</given-names></name>, <name><surname>Van De Ville</surname><given-names>D</given-names></name>, <name><surname>Schwartz</surname><given-names>S</given-names></name>, <name><surname>Vuilleumier</surname><given-names>P</given-names></name>. <article-title>Impact of transient emotions on functional connectivity during subsequent resting state: A wavelet correlation approach</article-title>. <source>Neuroimage</source>. <year>2011</year>;<volume>54</volume>(<issue>3</issue>):<fpage>2481</fpage>&#x02013;<lpage>91</lpage>. WOS:000286302000070. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.10.021</pub-id>
<?supplied-pmid 20955802?><pub-id pub-id-type="pmid">20955802</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref041"><label>41</label><mixed-citation publication-type="journal"><name><surname>Kragel</surname><given-names>PA</given-names></name>, <name><surname>LaBar</surname><given-names>KS</given-names></name>. <article-title>Decoding the Nature of Emotion in the Brain</article-title>. <source>Trends Cogn Sci</source>. <year>2016</year>
<pub-id pub-id-type="doi">10.1016/j.tics.2016.03.011</pub-id> .<?supplied-pmid 27133227?><pub-id pub-id-type="pmid">27133227</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref042"><label>42</label><mixed-citation publication-type="journal"><name><surname>Touroutoglou</surname><given-names>A</given-names></name>, <name><surname>Lindquist</surname><given-names>KA</given-names></name>, <name><surname>Dickerson</surname><given-names>BC</given-names></name>, <name><surname>Barrett</surname><given-names>LF</given-names></name>. <article-title>Intrinsic connectivity in the human brain does not reveal networks for &#x02018;basic&#x02019; emotions</article-title>. <source>Social Cognitive and Affective Neuroscience</source>. <year>2015</year>;<volume>10</volume>(<issue>9</issue>):<fpage>1257</fpage>&#x02013;<lpage>65</lpage>. <pub-id pub-id-type="doi">10.1093/scan/nsv013</pub-id>
<?supplied-pmid 25680990?><pub-id pub-id-type="pmid">25680990</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref043"><label>43</label><mixed-citation publication-type="journal"><name><surname>Vytal</surname><given-names>K</given-names></name>, <name><surname>Hamann</surname><given-names>S</given-names></name>. <article-title>Neuroimaging support for discrete neural correlates of basic emotions: a voxel-based meta-analysis</article-title>. <source>J Cogn Neurosci</source>. <year>2010</year>;<volume>22</volume>(<issue>12</issue>):<fpage>2864</fpage>&#x02013;<lpage>85</lpage>. Epub 2009/11/26. <pub-id pub-id-type="doi">10.1162/jocn.2009.21366</pub-id> .<?supplied-pmid 19929758?><pub-id pub-id-type="pmid">19929758</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref044"><label>44</label><mixed-citation publication-type="journal"><name><surname>Seeley</surname><given-names>WW</given-names></name>, <name><surname>Menon</surname><given-names>V</given-names></name>, <name><surname>Schatzberg</surname><given-names>AF</given-names></name>, <name><surname>Keller</surname><given-names>J</given-names></name>, <name><surname>Glover</surname><given-names>GH</given-names></name>, <name><surname>Kenna</surname><given-names>H</given-names></name>, <etal>et al</etal>
<article-title>Dissociable intrinsic connectivity networks for salience processing and executive control</article-title>. <source>J Neurosci</source>. <year>2007</year>;<volume>27</volume>(<issue>9</issue>):<fpage>2349</fpage>&#x02013;<lpage>56</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.5587-06.2007</pub-id>
<?supplied-pmid 17329432?><pub-id pub-id-type="pmid">17329432</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref045"><label>45</label><mixed-citation publication-type="journal"><name><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name><surname>Cusack</surname><given-names>R</given-names></name>, <name><surname>Bandettini</surname><given-names>P</given-names></name>. <article-title>How does an fMRI voxel sample the neuronal activity pattern: Compact-kernel or complex spatiotemporal filter?</article-title>
<source>Neuroimage</source>. <year>2010</year>;<volume>49</volume>(<issue>3</issue>):<fpage>1965</fpage>&#x02013;<lpage>76</lpage>. WOS:000273626400005. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2009.09.059</pub-id>
<?supplied-pmid 19800408?><pub-id pub-id-type="pmid">19800408</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref046"><label>46</label><mixed-citation publication-type="journal"><name><surname>Woo</surname><given-names>CW</given-names></name>, <name><surname>Koban</surname><given-names>L</given-names></name>, <name><surname>Kross</surname><given-names>E</given-names></name>, <name><surname>Lindquist</surname><given-names>MA</given-names></name>, <name><surname>Banich</surname><given-names>MT</given-names></name>, <name><surname>Ruzic</surname><given-names>L</given-names></name>, <etal>et al</etal>
<article-title>Separate neural representations for physical pain and social rejection</article-title>. <source>Nature communications</source>. <year>2014</year>;<volume>5</volume>:<fpage>5380</fpage>
<pub-id pub-id-type="doi">10.1038/ncomms6380</pub-id>
<?supplied-pmid 25400102?><pub-id pub-id-type="pmid">25400102</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref047"><label>47</label><mixed-citation publication-type="journal"><name><surname>Baumeister</surname><given-names>RF</given-names></name>. <article-title>A Self-Presentational View of Social Phenomena</article-title>. <source>Psychological Bulletin</source>. <year>1982</year>;<volume>91</volume>(<issue>1</issue>):<fpage>3</fpage>&#x02013;<lpage>26</lpage>. WOS:A1982NF12700001.</mixed-citation></ref><ref id="pbio.2000106.ref048"><label>48</label><mixed-citation publication-type="journal"><name><surname>Kassam</surname><given-names>KS</given-names></name>, <name><surname>Mendes</surname><given-names>WB</given-names></name>. <article-title>The effects of measuring emotion: physiological reactions to emotional situations depend on whether someone is asking</article-title>. <source>PLoS ONE</source>. <year>2013</year>;<volume>8</volume>(<issue>7</issue>):<fpage>e64959</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0064959</pub-id>
<?supplied-pmid 23785407?><pub-id pub-id-type="pmid">23785407</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref049"><label>49</label><mixed-citation publication-type="journal"><name><surname>Salzman</surname><given-names>CD</given-names></name>, <name><surname>Fusi</surname><given-names>S</given-names></name>. <article-title>Emotion, cognition, and mental state representation in amygdala and prefrontal cortex</article-title>. <source>Annu Rev Neurosci</source>. <year>2010</year>;<volume>33</volume>:<fpage>173</fpage>&#x02013;<lpage>202</lpage>. <pub-id pub-id-type="doi">10.1146/annurev.neuro.051508.135256</pub-id>
<?supplied-pmid 20331363?><pub-id pub-id-type="pmid">20331363</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref050"><label>50</label><mixed-citation publication-type="journal"><name><surname>Sheehan</surname><given-names>DV</given-names></name>, <name><surname>Lecrubier</surname><given-names>Y</given-names></name>, <name><surname>Sheehan</surname><given-names>KH</given-names></name>, <name><surname>Amorim</surname><given-names>P</given-names></name>, <name><surname>Janavs</surname><given-names>J</given-names></name>, <name><surname>Weiller</surname><given-names>E</given-names></name>, <etal>et al</etal>
<article-title>The Mini-International Neuropsychiatric Interview (M.I.N.I.): the development and validation of a structured diagnostic psychiatric interview for DSM-IV and ICD-10</article-title>. <source>The Journal of clinical psychiatry</source>. <year>1998</year>;<volume>59</volume>
<issue>Suppl 20</issue>:<fpage>22</fpage>&#x02013;<lpage>33</lpage>;quiz 4&#x02013;57. .<?supplied-pmid 9881538?><pub-id pub-id-type="pmid">9881538</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref051"><label>51</label><mixed-citation publication-type="book"><name><surname>M</surname><given-names>B</given-names><suffix>First</suffix></name>, <name><surname>Spitzer, Robert</surname><given-names>L</given-names></name>, <name><surname>Gibbon</surname><given-names>Miriam</given-names></name>, and <name><surname>Williams, Janet</surname><given-names>B.W</given-names></name>. <source>Structured Clinical Interview for DSM-IV Axis I Disorders, Clinician Version (SCID-CV)</source>. <publisher-loc>Washington, D.C.</publisher-loc>: <publisher-name>American Psychiatric Press, Inc.</publisher-name>; <year>1996</year>.</mixed-citation></ref><ref id="pbio.2000106.ref052"><label>52</label><mixed-citation publication-type="journal"><name><surname>Chikazoe</surname><given-names>J</given-names></name>, <name><surname>Lee</surname><given-names>DH</given-names></name>, <name><surname>Kriegeskorte</surname><given-names>N</given-names></name>, <name><surname>Anderson</surname><given-names>AK</given-names></name>. <article-title>Population coding of affect across stimuli, modalities and individuals</article-title>. <source>Nat Neurosci</source>. <year>2014</year>;<volume>17</volume>(<issue>8</issue>):<fpage>1114</fpage>&#x02013;<lpage>22</lpage>. Epub 2014/06/24. <pub-id pub-id-type="doi">10.1038/nn.3749</pub-id>
<?supplied-pmid 24952643?><pub-id pub-id-type="pmid">24952643</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref053"><label>53</label><mixed-citation publication-type="journal"><name><surname>Tusche</surname><given-names>A</given-names></name>, <name><surname>Smallwood</surname><given-names>J</given-names></name>, <name><surname>Bernhardt</surname><given-names>BC</given-names></name>, <name><surname>Singer</surname><given-names>T</given-names></name>. <article-title>Classifying the wandering mind: revealing the affective content of thoughts during task-free rest periods</article-title>. <source>Neuroimage</source>. <year>2014</year>;<volume>97</volume>:<fpage>107</fpage>&#x02013;<lpage>16</lpage>. Epub 2014/04/08. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2014.03.076</pub-id> .<?supplied-pmid 24705200?><pub-id pub-id-type="pmid">24705200</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref054"><label>54</label><mixed-citation publication-type="journal"><name><surname>Scherer</surname><given-names>KR</given-names></name>. <article-title>What are emotions? And how can they be measured?</article-title>
<source>Social Science Information</source>. <year>2005</year>;<volume>44</volume>(<issue>4</issue>):<fpage>695</fpage>&#x02013;<lpage>729</lpage>. <pub-id pub-id-type="doi">10.1177/0539018405058216</pub-id><comment>.</comment> ISI:000233359100005.</mixed-citation></ref><ref id="pbio.2000106.ref055"><label>55</label><mixed-citation publication-type="journal"><name><surname>Wold</surname><given-names>S</given-names></name>, <name><surname>Sjostrom</surname><given-names>M</given-names></name>, <name><surname>Eriksson</surname><given-names>L</given-names></name>. <article-title>PLS-regression: a basic tool of chemometrics</article-title>. <source>Chemometr Intell Lab</source>. <year>2001</year>;<volume>58</volume>(<issue>2</issue>):<fpage>109</fpage>&#x02013;<lpage>30</lpage>. <pub-id pub-id-type="doi">10.1016/S0169-7439(01)00155-1</pub-id><comment>.</comment> ISI:000172360800006.</mixed-citation></ref><ref id="pbio.2000106.ref056"><label>56</label><mixed-citation publication-type="journal"><name><surname>Bullmore</surname><given-names>E</given-names></name>, <name><surname>Long</surname><given-names>C</given-names></name>, <name><surname>Suckling</surname><given-names>J</given-names></name>, <name><surname>Fadili</surname><given-names>J</given-names></name>, <name><surname>Calvert</surname><given-names>G</given-names></name>, <name><surname>Zelaya</surname><given-names>F</given-names></name>, <etal>et al</etal>
<article-title>Colored noise and computational inference in neurophysiological (fMRI) time series analysis: resampling methods in time and wavelet domains</article-title>. <source>Hum Brain Mapp</source>. <year>2001</year>;<volume>12</volume>(<issue>2</issue>):<fpage>61</fpage>&#x02013;<lpage>78</lpage>. .<?supplied-pmid 11169871?><pub-id pub-id-type="pmid">11169871</pub-id></mixed-citation></ref><ref id="pbio.2000106.ref057"><label>57</label><mixed-citation publication-type="journal"><name><surname>Benjamini</surname><given-names>Y</given-names></name>, <name><surname>Hochberg</surname><given-names>Y</given-names></name>. <article-title>Controlling the False Discovery Rate&#x02014;a Practical and Powerful Approach to Multiple Testing</article-title>. <source>J Roy Stat Soc B Met</source>. <year>1995</year>;<volume>57</volume>(<issue>1</issue>):<fpage>289</fpage>&#x02013;<lpage>300</lpage>. ISI:A1995QE45300017.</mixed-citation></ref><ref id="pbio.2000106.ref058"><label>58</label><mixed-citation publication-type="journal"><name><surname>Yekutieli</surname><given-names>D</given-names></name>, <name><surname>Benjamini</surname><given-names>Y</given-names></name>. <article-title>Resampling-based false discovery rate controlling multiple test procedures for correlated test statistics</article-title>. <source>J Stat Plan Infer</source>. <year>1999</year>;<volume>82</volume>(<issue>1&#x02013;2</issue>):<fpage>171</fpage>&#x02013;<lpage>96</lpage>. WOS:000083580500015.</mixed-citation></ref><ref id="pbio.2000106.ref059"><label>59</label><mixed-citation publication-type="journal"><name><surname>Landis</surname><given-names>JR</given-names></name>, <name><surname>Koch</surname><given-names>GG</given-names></name>. <article-title>The Measurement of Observer Agreement for Categorical Data</article-title>. <source>Biometrics</source>. <year>1977</year>;<volume>33</volume>(<issue>1</issue>):<fpage>159</fpage>&#x02013;<lpage>74</lpage>. <pub-id pub-id-type="doi">10.2307/2529310</pub-id>
<?supplied-pmid 843571?><pub-id pub-id-type="pmid">843571</pub-id></mixed-citation></ref></ref-list></back></article>