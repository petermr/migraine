<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.1d3 20150301//EN" "JATS-archivearticle1.dtd"> 
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><?DTDIdentifier.IdentifierValue -//NLM//DTD Journal Publishing DTD v2.3 20070202//EN?><?DTDIdentifier.IdentifierType public?><?SourceDTD.DTDName journalpublishing.dtd?><?SourceDTD.Version 2.3?><?ConverterInfo.XSLTName jp2nlmx2.xsl?><?ConverterInfo.Version 2?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Neuroscience</journal-title></journal-title-group><issn pub-type="ppub">1662-4548</issn><issn pub-type="epub">1662-453X</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">4591427</article-id><article-id pub-id-type="doi">10.3389/fnins.2015.00354</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Methods</subject></subj-group></subj-group></article-categories><title-group><article-title>Musical neurofeedback for treating depression in elderly people</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Ramirez</surname><given-names>Rafael</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/218839/overview"/></contrib><contrib contrib-type="author"><name><surname>Palencia-Lefler</surname><given-names>Manel</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/278340/overview"/></contrib><contrib contrib-type="author"><name><surname>Giraldo</surname><given-names>Sergio</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/278220/overview"/></contrib><contrib contrib-type="author"><name><surname>Vamvakousis</surname><given-names>Zacharias</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/278112/overview"/></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Department of Information and Communication Technologies, Universitat Pompeu Fabra</institution><country>Barcelona, Spain</country></aff><aff id="aff2"><sup>2</sup><institution>Department of Communication, Universitat Pompeu Fabra</institution><country>Barcelona, Spain</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Julian O'Kelly, Royal Hospital for Neuro-disability, UK</p></fn><fn fn-type="edited-by"><p>Reviewed by: Lutz J&#x000e4;ncke, University of Zurich, Switzerland; Eric Miller, Montclair State University, USA</p></fn><corresp id="fn001">*Correspondence: Rafael Ramirez, Department of Information and Communication Technologies, Universitat Pompeu Fabra, Roc Boronat 138, 08018 Barcelona, Spain <email xlink:type="simple">rafael.ramirez@upf.edu</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Auditory Cognitive Neuroscience, a section of the journal Frontiers in Neuroscience</p></fn></author-notes><pub-date pub-type="epub"><day>02</day><month>10</month><year>2015</year></pub-date><pub-date pub-type="collection"><year>2015</year></pub-date><volume>9</volume><elocation-id>354</elocation-id><history><date date-type="received"><day>01</day><month>5</month><year>2015</year></date><date date-type="accepted"><day>17</day><month>9</month><year>2015</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2015 Ramirez, Palencia, Giraldo and Vamvakousis.</copyright-statement><copyright-year>2015</copyright-year><copyright-holder>Ramirez, Palencia-Lefler, Giraldo and Vamvakousis</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p></license></permissions><abstract><p>We introduce a new neurofeedback approach, which allows users to manipulate expressive parameters in music performances using their emotional state, and we present the results of a pilot clinical experiment applying the approach to alleviate depression in elderly people. Ten adults (9 female and 1 male, mean = 84, SD = 5.8) with normal hearing participated in the neurofeedback study consisting of 10 sessions (2 sessions per week) of 15 min each. EEG data was acquired using the Emotiv EPOC EEG device. In all sessions, subjects were asked to sit in a comfortable chair facing two loudspeakers, to close their eyes, and to avoid moving during the experiment. Participants listened to music pieces preselected according to their music preferences, and were encouraged to increase the loudness and tempo of the pieces, based on their <italic>arousal</italic> and <italic>valence</italic> levels. The neurofeedback system was tuned so that increased arousal, computed as beta to alpha activity ratio in the frontal cortex corresponded to increased loudness, and increased <italic>valence</italic>, computed as relative frontal alpha activity in the right lobe compared to the left lobe, corresponded to increased tempo. Pre and post evaluation of six participants was performed using the BDI depression test, showing an average improvement of 17.2% (1.3) in their BDI scores at the end of the study. In addition, an analysis of the collected EEG data of the participants showed a significant decrease of relative alpha activity in their left frontal lobe (<italic>p</italic> = 0.00008), which may be interpreted as an improvement of their depression condition.</p></abstract><kwd-group><kwd>music</kwd><kwd>neurofeedback</kwd><kwd>emotions</kwd><kwd>expressive performance</kwd><kwd>depression</kwd><kwd>electroencephalography</kwd><kwd>elderly patients</kwd></kwd-group><funding-group><award-group><funding-source id="cn001">Ministerio de Econom&#x000ed;a y Competitividad<named-content content-type="fundref-id">10.13039/501100003329</named-content></funding-source><award-id rid="cn001">TIN2013-48152-C2-2-R</award-id></award-group></funding-group><counts><fig-count count="7"/><table-count count="2"/><equation-count count="2"/><ref-count count="65"/><page-count count="10"/><word-count count="6819"/></counts></article-meta></front><body><sec sec-type="intro" id="s1"><title>Introduction</title><p>There is ample literature reporting on the importance and benefits of music for older adults (Ruud, <xref rid="B53" ref-type="bibr">1997</xref>; Cohen et al., <xref rid="B6" ref-type="bibr">2002</xref>; McCaffrey, <xref rid="B39" ref-type="bibr">2008</xref>). Some studies suggest that music contributes to positive aging by promoting self-esteem, feelings of competence and independence while diminishing the feelings of isolation (Hays and Minichiello, <xref rid="B26" ref-type="bibr">2005</xref>). Listening to music appears to be rated as a very pleasant experience by older adults since it promotes relaxation, decreases anxiety, and distracts people from unpleasant experiences (Cutshall et al., <xref rid="B8" ref-type="bibr">2007</xref>; Ziv et al., <xref rid="B65" ref-type="bibr">2007</xref>; Fukui and Toyoshima, <xref rid="B16" ref-type="bibr">2008</xref>). It can also evoke very strong feelings, both positive and negative, which very often result in physiological changes (Lundqvist et al., <xref rid="B34" ref-type="bibr">2009</xref>). These positive effects seem to be also experienced by people with dementia (S&#x000e4;rk&#x000e4;m&#x000f6; et al., <xref rid="B54" ref-type="bibr">2012</xref>, <xref rid="B56" ref-type="bibr">2014</xref>; Hsu et al., <xref rid="B28" ref-type="bibr">2015</xref>). All these findings have led many researchers to be interested in the topic of the contribution of music to the quality of life and to life satisfaction of older people (Vanderak et al., <xref rid="B63" ref-type="bibr">1983</xref>). Music activities (both passive and active) can affect older adults' perceptions of their quality of life, valuing highly the non-musical dimensions of being involved in music activities such as physical, psychological, and social aspects (Coffman, <xref rid="B5" ref-type="bibr">2002</xref>; Cohen-Mansfield et al., <xref rid="B7" ref-type="bibr">2011</xref>). Music experiences, led by music therapists or by other caregivers, besides being a source of entertainment, seem to provide older people the mentioned benefits (Hays and Minichiello, <xref rid="B26" ref-type="bibr">2005</xref>; Sol&#x000e9; et al., <xref rid="B58" ref-type="bibr">2010</xref>). Music has been shown to be beneficial in patients with different medical conditions. S&#x000e4;rk&#x000e4;m&#x000f6; et al. (<xref rid="B57" ref-type="bibr">2010</xref>) demonstrated that stroke patients merely listening to music and speech after neural damage can induce long-term plastic changes in early sensory processing, which, in turn, may facilitate the recovery of higher cognitive functions. The Cochrane review by Maratos et al. (<xref rid="B36" ref-type="bibr">2008</xref>) highlighted the potential benefits of music therapy for improving mood in those with depression. Erkkil&#x000e4; et al. (<xref rid="B14" ref-type="bibr">2011</xref>) showed that music therapy combined with standard care is effective for depression among working-age people with depression. In their study, patients receiving music therapy plus standard care showed greater improvement in depression symptoms than those receiving standard care only.</p><p>Neurofeedback has been found to be effective in producing significant improvements in medical conditions such as depression (Kumano et al., <xref rid="B33" ref-type="bibr">1996</xref>; Rosenfeld, <xref rid="B51" ref-type="bibr">2000</xref>; Hammond, <xref rid="B24" ref-type="bibr">2004</xref>), anxiety (Vanathy et al., <xref rid="B62" ref-type="bibr">1998</xref>; Kerson et al., <xref rid="B30" ref-type="bibr">2009</xref>), migraine (Walker, <xref rid="B64" ref-type="bibr">2011</xref>), epilepsy (Swingle, <xref rid="B60" ref-type="bibr">1998</xref>), attention deficit/hyperactivity disorder (Moriyama et al., <xref rid="B43" ref-type="bibr">2012</xref>), alcoholism/substance abuse (Peniston and Kulkosky, <xref rid="B45" ref-type="bibr">1990</xref>), and chronic pain (Jensen et al., <xref rid="B29" ref-type="bibr">2007</xref>), among many others (Kropotov, <xref rid="B32" ref-type="bibr">2009</xref>). For instance, Sterman (<xref rid="B59" ref-type="bibr">2000</xref>) reports that 82% of the most severe, uncontrolled epileptics demonstrated a significant reduction in seizure frequency, with an average of a 70% reduction in seizures. The benefits of neurofeedback in this context were shown to lead to significant normalization of brain activity even when patients were asleep. The effectiveness of neurofeedback was validated compared to medication and placebo (Kotchoubey et al., <xref rid="B31" ref-type="bibr">2001</xref>). Similarly, Monastra et al.'s (<xref rid="B42" ref-type="bibr">2002</xref>) research found neurofeedback to be significantly more effective than ritalin in changing ADD/ADHD, without having to remain on drugs. Other studies (Fuchs et al., <xref rid="B15" ref-type="bibr">2003</xref>) have found comparable improvements with 20 h of neurofeedback training (forty 30-min sessions) to those produced by ritalin, even after only twenty 30-min sessions of neurofeedback (Rossiter and La Vaque, <xref rid="B52" ref-type="bibr">1995</xref>). In the context of depression treatment, there are several clinical protocols used to apply neurofeedback such as shifting the alpha predominance in the left hemisphere to the right by decreasing left-hemispheric alpha activity, or increasing right hemispheric alpha activity, shifting an asymmetry index toward the right in order to rebalance activation levels in favor of the left hemisphere, and the reduction of Theta activity (4&#x02013;8 Hz) in relation to Beta (15&#x02013;28 Hz) in the left prefrontal cortex (i.e., decrease in the Theta/Beta ratio on the left prefrontal cortex) (Gruzelier and Egner, <xref rid="B23" ref-type="bibr">2005</xref>; Michael et al., <xref rid="B40" ref-type="bibr">2005</xref>; Ali et al., <xref rid="B1" ref-type="bibr">2015</xref>). Dias and van Deusen (<xref rid="B13" ref-type="bibr">2011</xref>) applied a neurofeedback protocol that is simultaneously capable of providing the training demands of Alpha asymmetry and increased Beta/Theta relationship in the left prefrontal cortex.</p><p>A still relatively new field of research in affective computing attempts to detect emotion states in users using electroencephalogram (EEG) data (Chanel et al., <xref rid="B3" ref-type="bibr">2006</xref>). Alpha and beta wave activity may be used in different ways for detecting emotional (arousal and valence) states of mind in humans. For instance, Choppin (<xref rid="B4" ref-type="bibr">2000</xref>) propose to use EEG signals for classifying six emotions using neural networks. Choppin's approach is based on emotional valence and arousal by characterizing valence, arousal and dominance from EEG signals. He characterizes positive emotions by a high frontal coherence in alpha, and high right parietal beta power. Higher arousal (excitation) is characterized by a higher beta power and coherence in the parietal lobe, plus lower alpha activity, while dominance (strength) of an emotion is characterized as an increase in the beta/alpha activity ratio in the frontal lobe, plus an increase in beta activity at the parietal lobe. Ramirez and Vamvakousis (<xref rid="B49" ref-type="bibr">2012</xref>) characterize emotional states by computing arousal levels as the prefrontal cortex beta to alpha ratio and valence levels as the alpha asymmetry between lobes. They show that by applying machine learning techniques (support vector machines with different kernels) to the computed arousal and valence values it is possible to classify the user emotion into high/low arousal and positive/negative valence emotional states, with average accuracies of 77.82, and 80.11%, respectively. These results show that the computed arousal and valence values indeed contain meaningful user's emotional information.</p><p>In this paper we investigate the potential benefits of combining music (therapy), neurofeedback and emotion detection for improving elderly people's mental health. Specifically, our main goal is to investigate the emotional reinforcement capacity of automatic music neurofeedback systems, and its effects for improving depression in elderly people. With this aim, we propose a new neurofeedback approach, which allows users to manipulate expressive parameters in music performances using their emotional state. The users' instantaneous emotional state is characterized by a coordinate in the arousal-valence plane decoded from their EEG activity. The resulting coordinate is then used to change expressive aspects of music such as tempo, dynamics, and articulation. We present the results of a pilot clinical experiment applying our neurofeedback approach to a group of 10 elderly people with depression.</p></sec><sec sec-type="materials|methods" id="s2"><title>Materials and methods</title><sec><title>Participants</title><p>Ten adults (9 female and 1 male, mean = 84, SD = 5.8) with normal hearing participated in the neurofeedback study consisting of 10 sessions (2 sessions per week) of 15 min each. Participants granted their written consent and procedures were positively evaluated by the Clinical Research Ethical Committee of the Parc de Salut Mar (CEIC-Parc de Salut Mar), Barcelona, Spain, under the reference number: 2015/6343/I. EEG data was acquired using the Emotiv EPOC EEG device. Participants were either residents or day users in an elderly home in Barcelona and were selected according to their cognitive capacities, sensitivity to music and depression condition: all of them declared to regularly listen to music and presented with a primary complaint of depression, which was confirmed by the psychologist of the center. Informed consent was obtained from all participants. There were four people who abandoned the study toward the end of it due to illness.</p></sec><sec><title>Materials</title><sec><title>Music material</title><p>Prior to the first session, the participants in the study were interviewed in order to determine the music they liked and to identify particular pieces to be included in their feedback sessions. Following the interviews, for each participant a set of 5&#x02013;6 music pieces was collected from commercial audio CDs. During each session a subset of the selected pieces was played to the participant. Table <xref ref-type="table" rid="T1">1</xref> shows the selected pieces for each participant.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>Selected pieces for each participant</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Participant</bold></th><th valign="top" align="left" rowspan="1" colspan="1"><bold>Music pieces</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Subject 1</td><td valign="top" align="left" rowspan="1" colspan="1">Por una cabeza (tango)/15 a&#x000f1;os tiene mi amor (D&#x000fa;o Din&#x000e1;mico)/Memorias de &#x000c1;frica/Historia de un amor (Lucho Gatica)/La balanguera (Marina Rosell)/Maria (3 tenors)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Subject 2</td><td valign="top" align="left" rowspan="1" colspan="1">Largo (H&#x000e4;endel)/Doctor Zhivago/Una rosa y una flor (Nino Bravo)/Claro de luna (Beethoven)/Abr&#x000e1;zame (Julio Iglesias)/La leyenda del beso</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Subject 3</td><td valign="top" align="left" rowspan="1" colspan="1">Por una cabeza (tango)/Vals de las flores (Tchaikovsky)/La tabernera del puerto &#x02013;zarzuela (3 tenores)/El lago de los cisnes (Tchaikovsky)/La balanguera (Marina Rosell)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Subject 4</td><td valign="top" align="left" rowspan="1" colspan="1">Va pensiero (G.Verdi)/El meu avi (habanera)/Canci&#x000f3;n del ruise&#x000f1;or &#x02013;zarzuela Do&#x000f1;a Francisquita/La sardana de les monges/El lago de los cisnes (Tchaikovsky)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Subject 5</td><td valign="top" align="left" rowspan="1" colspan="1">Qu&#x000e9; tiempo tan feliz (Jos&#x000e9; Guardiola)/Mira que eres linda (A. Machin)/Paraules d'amor (Serrat)/Toda una vida/El d&#x000ed;a que me quieras (C.Gardel)/Angelitos negros (A.Machin)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Subject 6</td><td valign="top" align="left" rowspan="1" colspan="1">La balanguera (Marina Rosell)/Amparito Roca (pasodoble)/El meu avi (habanera)/Paquito el chocolatero (pasodoble)/El Danubio azul (Strauss)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Subject 7</td><td valign="top" align="left" rowspan="1" colspan="1">Concierto Piano n.1 (Tchaikovsky)/Olas del Danubio (Ivanovici)/Only you (The Platters)/Claro de luna (Beethoven)/Largo (H&#x000e4;endel)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Subject 8</td><td valign="top" align="left" rowspan="1" colspan="1">Himno del amor (Francisco)/Vals d'Am&#x000e9;lie/Torna Asurriento (3 tenores)/Vals de las flores (Tchaikovsky)/De qu&#x000e9; hablas &#x02013;habanera (Marina Rosell)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Subject 9</td><td valign="top" align="left" rowspan="1" colspan="1">Mi gran amor (Nino Bravo)/Nessum Dorma -3 tenors (G.Puccini)/De qu&#x000e9; hablas &#x02013;habanera (Marina Rosell)/Himno del amor (Francisco)/Vals d'Am&#x000e9;lie/Torna Asurriento (3 tenores)</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Subject 10</td><td valign="top" align="left" rowspan="1" colspan="1">Mira que eres linda (A. Machin)/Paquito el chocolatero (pasodoble)/Cambalache &#x02013;tango (C.Gardel)/Perd&#x000f3;n (Los Panchos)/Lacrimosa &#x02013;Requiem (Mozart)/Aquellas peque&#x000f1;as cosas (Serrat)</td></tr></tbody></table></table-wrap></sec><sec><title>Data acquisition and processing</title><p>The Emotiv EPOC EEG system (Emotiv, 2014<xref ref-type="fn" rid="fn0001"><sup>1</sup></xref>) was used for acquiring the EEG data. It consists of 16 wet saline electrodes, providing 14 EEG channels, and a wireless amplifier. The electrodes were located at the positions AF3, F7, F3, FC5, T7, P7, O1, O2, P8, T8, FC6, F4, F8, AF4 according to the international 10&#x02013;20 system (see Figure <xref ref-type="fig" rid="F1">1</xref>). Two electrodes located just above the subject's ears (P3, P4) were used as reference. The data were digitized using the embedded 16-bit ADC with 128 Hz sampling frequency per channel and sent to the computer via Bluetooth. The EEG signals were band-pass filtered with Butterworth 8&#x02013;12 Hz and 12&#x02013;28 Hz filters. The impedance of the electrode contact to the scalp was visually monitored using Emotiv Control Panel software.</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Positions of the Emotiv EPOC electrodes aligned with positions in the 10&#x02013;20 system</bold>.</p></caption><graphic xlink:href="fnins-09-00354-g0001"/></fig><p>The Emotiv EPOC EEG system is part of a number of low-cost EEG systems, which have been recently commercialized [a usability review of some of them can be found in (10)]. These systems are mainly marketed as gaming devices and the quality of the signal they capture is lower than the signal captured by more expensive equipment. However, recent research on evaluating the reliability of some of these low-cost EEG devices for research purposes has suggested that they are reliable for measuring EEG signals (Debener et al., <xref rid="B12" ref-type="bibr">2012</xref>; Thie et al., <xref rid="B61" ref-type="bibr">2012</xref>; Badcock et al., <xref rid="B2" ref-type="bibr">2013</xref>). In the case of our study, the Emotiv EPOC device has provided several important pragmatic advantages compared with more expensive equipment: the setting up time of the Emotiv EPOC system at the beginning of each session is considerably shorter than that of an expensive EEG system (for which an experienced clinical professional can take up to an hour to place the electrodes on the patient's scalp, which results in long and tedious sessions). Furthermore, expensive EEG systems typically require the application of conductive gel in order to create a reliable connection between each electrode and the patient's scalp (the gel attaches to the patient's hair and can only be properly removed by washing the entire head at the end of each session). The setting up time of the Emotiv EPOC takes a few minutes (typically 3&#x02013;5 min) and conductive gel is not necessary for the Emotiv EPOC's wet saline electrodes. However, the inferior signal quality of the Emotiv EPOC device is a limitation of this study, and thus it should be emphasized that future studies should involve the use of a more accurate EEG device.</p><p>We collected and processed the data using the OpenViBE platform (Renard et al., <xref rid="B50" ref-type="bibr">2010</xref>). In order to play and transform the music feedback through the OpenVibe platform, a VRPN (Virtual-Reality Peripheral Network) to OSC (Open Sound Control protocol) gateway was implemented and used to communicate OpenViBE with Pure Data (Puckette, <xref rid="B46" ref-type="bibr">1996</xref>). OSC is a protocol for networking sound synthesizers, computers, and other multimedia devices for purposes such as musical performance, while VRPN is a device-independent and network-transparent system for accessing virtual reality peripherals in applications. The VRPN-OSC-Gateway connects to a VRPN server, converts the tracking data and sends it to an OSC server. Music feedback was played by AudioMulch VST-host application, which received MIDI messages from Pure Data, and in which a <italic>tempo transformation plugin</italic> (Mayor et al., <xref rid="B38" ref-type="bibr">2011</xref>) was installed. The plugin allows performing pitch-independent real-time tempo transformations (i.e., time stretch transformations) using audio spectral analysis-synthesis techniques. The plugin parameters were controlled using the MIDI messages sent by Pure Data. Music tempo and loudness were controlled assigning the corresponding MIDI control message coming from Pure Data. Both data acquisition and music playback were performed on a laptop with an Intel Core i5 2.53 Ghz processor with 4 GB of RAM, running windows 7 64-bit Operating System and using the laptop's internal sound card (Realtek ALC269). Music was amplified by two loudspeakers Roland MA150U.</p></sec></sec><sec><title>Methods</title><p>Participants were treated individually. At the beginning of each feedback session, participants were informed about the experiment procedure, were asked to sit in a comfortable chair facing two loudspeakers, to close their eyes, and avoid moving during the experiment. Participants listened to preselected music pieces according to their music preferences for 15 min. Within these 15 min music pieces were separated by a pause of 1 s. Participants were encouraged to increase the loudness and tempo of the pieces so the pieces sounded &#x0201c;happier.&#x0201d; As the system was tuned so that increased <italic>arousal</italic> corresponded to increased loudness, and increased <italic>valence</italic> corresponded to increased tempo, participants were encouraged to increase their arousal and valence, in other words to direct their emotional state to the high-arousal/positive-valence quadrant in the arousal-valence plane (see Figure <xref ref-type="fig" rid="F2">2</xref>). At the end of each session, participants were asked if they perceived they were able to modify the music tempo and volume. Pre and post evaluation of participants was performed using the BDI depression test.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Arousal-valence plane</bold>. By encouraging participants to increase the loudness and tempo of musical pieces, they were encouraged to increase their arousal and valence, and thus direct their emotional state to the top-right quadrant in the arousal-valence plane.</p></caption><graphic xlink:href="fnins-09-00354-g0002"/></fig><p>No artifact detection/elimination method was applied to the measured EEG signal. Both electrooculographic (EOG) and electromyographic (EMG) artifacts were minimized by asking participants to close their eyes and avoid movement. No control of the interface through eye or muscle movement was observed during the experimental sessions. However, it must be noted that it is important to extend/redo the reported study using artifact detection methods.</p><p>The EEG data processing was adapted from Ramirez and Vamvakousis (<xref rid="B49" ref-type="bibr">2012</xref>). Based on the EEG signal of a person, the arousal level was determined by computing the ratio of the beta (12&#x02013;28 Hz) and alpha (8&#x02013;12 Hz) brainwaves. EEG signal was measured in four locations (i.e., electrodes) in the prefrontal cortex: AF3, AF4, F3, and F4 (see Figure <xref ref-type="fig" rid="F1">1</xref>). Beta waves &#x003b2; are associated with an alert or excited state of mind, whereas alpha waves &#x003b1; are more dominant in a relaxed state. Alpha activity has also been associated to brain inactivation. Thus, the beta/alpha ratio is a reasonable indicator of the arousal state of a person. Concretely, arousal level was computed as following:<disp-formula id="E1"><label>(1)</label><mml:math id="M1"><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mi>A</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mi>F</mml:mi><mml:mn>3</mml:mn><mml:mo>+</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mi>F</mml:mi><mml:mn>4</mml:mn><mml:mo>+</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mi>A</mml:mi><mml:mi>F</mml:mi><mml:mn>3</mml:mn><mml:mo>+</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mi>A</mml:mi><mml:mi>F</mml:mi><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>/</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mi>F</mml:mi><mml:mn>3</mml:mn><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mi>F</mml:mi><mml:mn>4</mml:mn><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mi>A</mml:mi><mml:mi>F</mml:mi><mml:mn>3</mml:mn></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;&#x02009;</mml:mtext><mml:mo>+</mml:mo><mml:mtext>&#x02009;</mml:mtext><mml:mi>&#x003b1;</mml:mi><mml:mi>A</mml:mi><mml:mi>F</mml:mi><mml:mn>4</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mtd></mml:mtr></mml:mtable></mml:math></disp-formula></p><p>In order to determine the valence level, activation levels of the two cortical hemispheres were compared. A large number of EEG studies (Henriques and Davidson, <xref rid="B27" ref-type="bibr">1991</xref>; Davidson, <xref rid="B9" ref-type="bibr">1992</xref>, <xref rid="B10" ref-type="bibr">1995</xref>, <xref rid="B11" ref-type="bibr">1998</xref>), have demonstrated that the left frontal area is associated with more positive affect and memories, and the right hemisphere is more involved in negative emotion. F3 and F4 are the most used positions for looking at this alpha/beta activity related to valence, as they are located in the prefrontal lobe, which plays a crucial role in emotion regulation and conscious experience. Valence values were computed by comparing the alpha power &#x003b1; in channels F3 and F4. Concretely, valence level was computed as following:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2"><mml:mrow><mml:mi>V</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mi>F</mml:mi><mml:mn>4</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mi>F</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:math></disp-formula></p><p>Valence and arousal computation was adapted from Ramirez and Vamvakousis (<xref rid="B49" ref-type="bibr">2012</xref>), where the authors show that the computed arousal and valence values indeed contain meaningful user's emotional information.</p><p>Computed arousal and valence values are fed into an expressive music performance system which calculates appropriate expressive transformations on timing, loudness and articulation (however, in the present study only timing and loudness transformations are considered). The expressive performance system is based on a music performance model, which was obtained by training four models using machine learning techniques (Mitchell, <xref rid="B41" ref-type="bibr">1997</xref>) applied to recordings of musical pieces in four emotions: <italic>happy, relaxed, sad</italic>, and <italic>angry</italic> (each corresponding to a quadrant in the arousal-valence plane). The coefficients of the four models were interpolated in order to obtain intermediate models (in addition to the four trained models) and corresponding performance predictions (Figure <xref ref-type="fig" rid="F3">3</xref>). Details about the expressive music performance system and our approach to expressive performance modeling can be found in (Ramirez et al., <xref rid="B47" ref-type="bibr">2010</xref>; Giraldo, <xref rid="B19" ref-type="bibr">2012</xref>; Ramirez et al., <xref rid="B48" ref-type="bibr">2012</xref>; Giraldo and Ramirez, <xref rid="B20" ref-type="bibr">2013</xref>; Marchini et al., <xref rid="B37" ref-type="bibr">2014</xref>). In order to model expression in music performances we characterized each performed note by a set of inter-note features representing both properties of the note itself and aspects of the musical context in which the note appears (Figure <xref ref-type="fig" rid="F4">4</xref>). Information about the note included note pitch (<italic>Pitch</italic>), note duration (<italic>dur</italic>), and note metrical strenght (<italic>MetrStr</italic>), while information about its melodic context included the relative pitch and duration of the neighboring notes (<italic>PrevPitch, PrevDur, NextPitch, NextDur</italic>), i.e., previous and following notes, as well as the music structure (i.e., Narmour groups) in which the note appears (Narmour, <xref rid="B44" ref-type="bibr">1991</xref>). We also extracted the amount of legato with the previous note, the amount of legato with the following note, and mean energy. We applied machine learning techniques to train a linear regression models for predicting duration, and energy deviations expressed as a ratio of the values specified in the score (for energy which is not specified in the score we take the score value as the average of the energy of all the notes in the piece). For instance, for duration a predicted value of 1.14 represents a prediction of 14% lengthening of the note with respect to the score. In the case of energy it indicates that the note should be played a 14% louder than the average energy in the piece.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Overview of the expressive music performance system</bold>. Happy, relaxed, sad, and angry models were learnt from music recordings with these emotions using machine learning techniques and interpolated in order to obtain intermediate models and corresponding performance predictions.</p></caption><graphic xlink:href="fnins-09-00354-g0003"/></fig><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Note characterization in performances</bold>.</p></caption><graphic xlink:href="fnins-09-00354-g0004"/></fig><p>The general proposed emotion-based musical neurofeedback system is depicted in Figure <xref ref-type="fig" rid="F5">5</xref>. The system consisted of a real-time feedback loop in which the brain activity of participants was processed to estimate their emotional state, which in turn was used to control an expressive rendition of the music piece. The user's EEG activity is mapped into a coordinate in the arousal-valence space that is fed to a pre-trained expressive music model in order to trigger appropriate expressive transformations to a given music piece (audio or MIDI).</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Neurofeedback system Overview: real-time feedback loop in which the brain activity of a person is processed to produce an expressive rendition of a music piece according to the person's estimated emotional state</bold>.</p></caption><graphic xlink:href="fnins-09-00354-g0005"/></fig></sec></sec><sec sec-type="results" id="s3"><title>Results</title><p>Seven participants completed training, requiring a total of ten 15 min sessions (2.5 h) of neurofeedback, with no other psychotherapy provided. There were four people who abandoned the study toward the end of it due to health problems. Pre and post evaluation of 6 participants was performed using the BDI depression test (One participant was not able to respond to the BDI depression test at the end of the treatment due to serious health reasons). The BDI evaluation performed using the BDI depression test, showed an average improvement of 17.2% (1.3) in BDI scores at the end of the study. Pre&#x02013;post changes on the BDI test are shown in Figure <xref ref-type="fig" rid="F6">6</xref>.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Pre and post BDI depression test results for six participants</bold>.</p></caption><graphic xlink:href="fnins-09-00354-g0006"/></fig><p>We computed average valence and arousal values at the beginning of the first session and the beginning of the last session of the study. The obtained average valence values were 0.74 (0.22) and 0.83 (0.26) for the beginning of the first session and the beginning of the last session, respectively, while the obtained average arousal values were 0.97 (0.14) and 0.98 (0.21) for the beginning of the first session and the beginning of the last session, respectively (Table <xref ref-type="table" rid="T2">2</xref>).</p><table-wrap id="T2" position="float"><label>Table 2</label><caption><p><bold>Arousal and valence values at the beginning and at the end of the study</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th valign="top" align="left" rowspan="1" colspan="1"><bold>Indicators</bold></th><th valign="top" align="center" colspan="2" style="border-bottom: thin solid #000000;" rowspan="1"><bold>Beginning</bold></th><th valign="top" align="center" colspan="2" style="border-bottom: thin solid #000000;" rowspan="1"><bold>End</bold></th></tr><tr><th rowspan="1" colspan="1"/><th valign="top" align="center" rowspan="1" colspan="1"><bold>Average</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>SD</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>Average</bold></th><th valign="top" align="center" rowspan="1" colspan="1"><bold>SD</bold></th></tr></thead><tbody><tr><td valign="top" align="left" rowspan="1" colspan="1">Arousal</td><td valign="top" align="center" rowspan="1" colspan="1">0.97</td><td valign="top" align="center" rowspan="1" colspan="1">0.14</td><td valign="top" align="center" rowspan="1" colspan="1">0.98</td><td valign="top" align="center" rowspan="1" colspan="1">0.21</td></tr><tr><td valign="top" align="left" rowspan="1" colspan="1">Valence</td><td valign="top" align="center" rowspan="1" colspan="1">0.74</td><td valign="top" align="center" rowspan="1" colspan="1">0.22</td><td valign="top" align="center" rowspan="1" colspan="1">0.83</td><td valign="top" align="center" rowspan="1" colspan="1">0.26</td></tr></tbody></table></table-wrap><p>Figure <xref ref-type="fig" rid="F7">7</xref> shows the correlation within sessions between the computed arousal and valence values, and time (1 min periods) within sessions. For valence we obtained a correlation of <italic>r</italic> = 0.919 (<italic>p</italic> = 0.000171) while for arousal we obtained a correlation of <italic>r</italic> = 0.315 (<italic>p</italic> = 0.375335).</p><fig id="F7" position="float"><label>Figure 7</label><caption><p><bold>Within session arousal and valence (normalized) values across ten 1 min periods</bold>.</p></caption><graphic xlink:href="fnins-09-00354-g0007"/></fig></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>Five out of six participants who responded to the BDI test made improvements in their BDI, and one patient improved from depressed to slight perturbation in the BDI scale. One participant, who initially scored as not depressed in the BDI pre-test (score = 1), did not show any improvement in her BDI post-score (score = 4), which was also in the non-depressed range. Either the participant was not depressed at the beginning of the study, or her responses to the BDI tests were not reliable. Excluding her from the BDI test analysis, the mean decrease in BDI scores was 20.6% (0.06). These differences were found significant (<italic>p</italic> = 0.018).</p><p>EEG data obtained during the course of the study showed that overall valence level increased at the end of the treatment compared to the starting level. The difference between valence values at the beginning and end of the study is statistically significant (<italic>p</italic> = 0.00008). This result should be interpreted as a decrease of relative alpha activity in the left frontal lobe, which may be interpreted as an improvement of the depression condition (Henriques and Davidson, <xref rid="B27" ref-type="bibr">1991</xref>; Gotlib et al., <xref rid="B21" ref-type="bibr">1999</xref>). Arousal values at the beginning and at the end of the study showed no significant difference (<italic>p</italic> = 0.33). However, in this study the most important indicator was valence since it reflects changes in negative/positive emotional states, which are directly related to depression conditions.</p><p>Correlation between valence values and time within sessions was found significant (<italic>p</italic> &#x0003c; 0.00018) but that was not the case for the correlation between arousal values and time. The fact that arousal-time correlation was not significant is not a negative result since valence is the most relevant indicator for depression.</p><p>Taking into account the obtained within- and cross-session improvements in valence levels and the limited duration of both each session (i.e., 15 min) and the complete treatment (i.e., 10 sessions), it may be reasonable to think that further improvements in valence could have been reached if sessions and/or treatment had been longer. We plan to investigate the impact of treatments with longer duration in the future.</p><p>Very few studies in the literature have examined the long-term effect of neurofeedback, but the few studies that did it found promising results (Gani et al., <xref rid="B17" ref-type="bibr">2008</xref>; Gevensleben et al., <xref rid="B18" ref-type="bibr">2010</xref>). Both Gani et al. (<xref rid="B17" ref-type="bibr">2008</xref>) and Gevensleben et al. (<xref rid="B18" ref-type="bibr">2010</xref>) showed that after the end of their studies, improvements were maintained and some additional benefits could be noted, suggesting that patients were still improving even after the end of treatment. In the current study, in addition to the post study BDI test, no follow-up for the participants was conducted in order to examine the long-term effect of our approach. This issue should be investigated in the future.</p><p>As it is the case of most of the literature on the use of neurofeedback to treat depression, which mainly represent uncontrolled case study reports, no control group has been considered in this pilot study. In order to quantify the benefits of combining music and neurofeedback compared to other approaches, ideally 3 groups should have been considered: one group with music therapy, one group with neurofeedback, and one group with the proposed approach combining music therapy and neurofeedback. In this way it would have been possible to quantify the added value of combining music therapy and neurofeedback. However, due to the limited number of participants this was not possible.</p><p>Some researchers have showed that listening to music regularly during the early stages of rehabilitation can aid the recovery maintaining attention, and preventing depressed and confused moods in stroke patients (S&#x000e4;rk&#x000e4;m&#x000f6; et al., <xref rid="B55" ref-type="bibr">2008</xref>). S&#x000e4;rk&#x000e4;m&#x000f6; et al. conclude that in addition to these effects, music listening may also have general effects on brain plasticity, as the activation it causes in the brain is in both hemispheres, and more widely distributed than that caused by verbal material alone. In the current study, we propose a new neurofeedback approach, which combines emotion-driven neurofeedback with (active) music listening. In the light of the mentioned benefits of music listening/receptive music therapy (Grocke et al., <xref rid="B22" ref-type="bibr">2007</xref>), it is reasonable to think that incorporating music listening in a neurofeedback setting can only improve the benefits of traditional neurofeedback systems. Furthermore, we argue that the combination of neurofeedback and receptive music therapy provides the benefits of both techniques, while eliminating potential drawbacks of each separate technique. When considered as separate methods, the advantages of receptive music therapy and neurofeedback are clear: they both provide a noninvasive method with a lack of contraindications. In addition, neurofeedback is oriented to encourage patients to self-regulate their brain activity in order to promote beneficial activity patterns, while receptive music therapy relies on the emotional therapeutic effects of listening to music. These positive properties of both techniques are clearly preserved by the proposed approach. On the other hand, neurofeedback procedures often can be tedious and consist of tasks involving visual or auditory feedback with little or no emotional content (e.g., moving a car on a computer screen). Furthermore, a drawback of neurofeedback is that it is based on traditional EEG-rhythms (e.g., theta, alpha, beta), which are functionally heterogeneous and individual (Hammond, <xref rid="B25" ref-type="bibr">2010</xref>). Receptive music therapy methods are combined with the difficulty of selecting music material corresponding to the individual needs of the patient (MacDonald, <xref rid="B35" ref-type="bibr">2013</xref>). These shortcomings are avoided by the proposed system: The system provides attractive feedback consisting of music material specially selected by the individual participants, and it is based on high-level descriptors (i.e., arousal and valence) representing the emotional state of users.</p><p>The results obtained in the current study seem to indicate that music has the potential to be a useful component in neurofeedback treatment. However, future research needs to explore the effect of individual responses' variables to music through direct experimental comparison. Future investigation of individual variables, such as music sensibility (e.g., music experience/familiarity) and the impact of depression severity, in addition to more stringent methodology, is required.</p><p>In summary, we have introduced a new neurofeedback approach, which allows users to manipulate expressive parameters in music performances using their emotional state, and presented the results of a neurofeedback clinical pilot study for treating depression in elderly people. The neurofeedback study consisted of 10 sessions (2 sessions per week) of 15 min each initially involving 10 participants from a residential home for the elderly in Barcelona. Participants were asked to listen to music pieces preselected by them according to their music preferences, and were encouraged to increase the loudness and tempo of the pieces, based on their arousal and valence levels, respectively: <italic>arousal</italic> was computed as beta to alpha activity ratio in the frontal cortex, and <italic>valence</italic> was computed as relative frontal alpha activity in the right lobe compared to the left lobe. Pre and post evaluation of 6 participants was performed using the BDI depression test, showing an average improvement of 17.2% (1.3) in their BDI scores at the end of the study. Analysis of the participants' EEG data showed a decrease of relative alpha activity in their left frontal lobe, which may be interpreted as an improvement of their depression condition. The positive results of our clinical experiment, suggest that new research with the proposed music neurofeedback approach is worthwhile.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>This work has been partly sponsored by the Ministerio de Economia y Competitividad under Grant TIN2013-48152-C2-2-R (TIMuL Project).</p></ack><fn-group><fn id="fn0001"><p><sup>1</sup>Emotiv Systems Inc. Researchers. (2014). Available online at: <ext-link ext-link-type="uri" xlink:href="http://www.emotiv.com/researchers/">http://www.emotiv.com/researchers/</ext-link></p></fn></fn-group><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ali</surname><given-names>Y.</given-names></name><name><surname>Mahmud</surname><given-names>N. A.</given-names></name><name><surname>Samaneh</surname><given-names>R.</given-names></name></person-group> (<year>2015</year>). <article-title>Current advances in neurofeedback techniques for the treatment of ADHD</article-title>. <source>Biomed. Pharma. J.</source>
<volume>8</volume>, <fpage>65</fpage>&#x02013;<lpage>177</lpage>. <pub-id pub-id-type="doi">10.13005/bpj/573</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Badcock</surname><given-names>N. A.</given-names></name><name><surname>Mousikou</surname><given-names>P.</given-names></name><name><surname>Mahajan</surname><given-names>Y.</given-names></name><name><surname>de Lissa</surname><given-names>P.</given-names></name><name><surname>Johnson</surname><given-names>T.</given-names></name><name><surname>McArthur</surname><given-names>G.</given-names></name></person-group> (<year>2013</year>). <article-title>Validation of the Emotiv EPOC&#x000ae; EEG gaming system for measuring research quality auditory ERPs</article-title>. <source>Peer J.</source>
<volume>1</volume>:<fpage>e38</fpage>. <pub-id pub-id-type="doi">10.7717/peerj.38</pub-id><?supplied-pmid 23638374?><pub-id pub-id-type="pmid">23638374</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Chanel</surname><given-names>G.</given-names></name><name><surname>Kronegg</surname><given-names>J.</given-names></name><name><surname>Grandjean</surname><given-names>D.</given-names></name><name><surname>Pun</surname><given-names>T.</given-names></name></person-group> (<year>2006</year>). <article-title>Emotion assessment: arousal evaluation using eeg's and peripheral physiological signals</article-title>, in <source>MRCS 2006. LNCS</source>, <volume>Vol. 4105</volume>, eds <person-group person-group-type="editor"><name><surname>Gunsel</surname><given-names>B.</given-names></name><name><surname>Jain</surname><given-names>A. K.</given-names></name><name><surname>Tekalp</surname><given-names>A. M.</given-names></name><name><surname>Sankur</surname><given-names>B.</given-names></name></person-group> (<publisher-loc>Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>530</fpage>&#x02013;<lpage>537</lpage>.</mixed-citation></ref><ref id="B4"><mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Choppin</surname><given-names>A.</given-names></name></person-group> (<year>2000</year>). <source>EEG-based Human Interface for Disabled Individuals: Emotion Expression with Neural Networks</source>. Masters thesis, Tokyo Institute of Technology, Yokohama, Japan.</mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Coffman</surname><given-names>D. D.</given-names></name></person-group> (<year>2002</year>). <article-title>Banding together: new horizons in lifelong music making</article-title>. <source>J. Aging Identity</source>
<volume>7</volume>, <fpage>133</fpage>&#x02013;<lpage>143</lpage>. <pub-id pub-id-type="doi">10.1023/A:1015491202347</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen</surname><given-names>A.</given-names></name><name><surname>Bailey</surname><given-names>B.</given-names></name><name><surname>Nilsson</surname><given-names>T.</given-names></name></person-group> (<year>2002</year>). <article-title>The importance of music to seniors</article-title>. <source>Psychomusicology</source>
<volume>18</volume>, <fpage>89</fpage>&#x02013;<lpage>102</lpage>. <pub-id pub-id-type="doi">10.1037/h0094049</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cohen-Mansfield</surname><given-names>J.</given-names></name><name><surname>Marx</surname><given-names>M. S.</given-names></name><name><surname>Thein</surname><given-names>K.</given-names></name><name><surname>Dakheel-Ali</surname><given-names>M.</given-names></name></person-group> (<year>2011</year>). <article-title>The impact of stimuli on affect in persons with dementia</article-title>. <source>J. Clin. Psychiatry</source>
<volume>72</volume>, <fpage>480</fpage>&#x02013;<lpage>486</lpage>. <pub-id pub-id-type="doi">10.4088/JCP.09m05694oli</pub-id><?supplied-pmid 21527124?><pub-id pub-id-type="pmid">21527124</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cutshall</surname><given-names>S. M.</given-names></name><name><surname>Fenske</surname><given-names>L. L.</given-names></name><name><surname>Kelly</surname><given-names>R. F.</given-names></name><name><surname>Phillips</surname><given-names>B. R.</given-names></name><name><surname>Sundt</surname><given-names>T. M.</given-names></name><name><surname>Bauer</surname><given-names>B. A.</given-names></name></person-group> (<year>2007</year>). <article-title>Creation of a healing program at an academic medical center</article-title>. <source>Complement. Ther. Clin. Pract.</source>
<volume>13</volume>, <fpage>217</fpage>&#x02013;<lpage>223</lpage>. <pub-id pub-id-type="doi">10.1016/j.ctcp.2007.02.001</pub-id><?supplied-pmid 17950176?><pub-id pub-id-type="pmid">17950176</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>R. J.</given-names></name></person-group> (<year>1992</year>). <article-title>Emotion and affective style: hemispheric substrates</article-title>. <source>Psychol. Sci.</source>
<volume>3</volume>, <fpage>39</fpage>&#x02013;<lpage>43</lpage>. <pub-id pub-id-type="doi">10.1111/j.1467-9280.1992.tb00254.x</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>R. J.</given-names></name></person-group> (<year>1995</year>). <article-title>Cerebral asymmetry, emotion and affective style</article-title>, in <source>Brain asymmetry</source>, eds <person-group person-group-type="editor"><name><surname>Davidson</surname><given-names>R. J.</given-names></name><name><surname>Hugdahl</surname><given-names>K.</given-names></name></person-group> (<publisher-loc>Boston, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>), <fpage>361</fpage>&#x02013;<lpage>387</lpage>.</mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Davidson</surname><given-names>R. J.</given-names></name></person-group> (<year>1998</year>). <article-title>Affective style and affective disorders: perspectives from affective neuroscience</article-title>. <source>Cogn. Emot.</source>
<volume>12</volume>, <fpage>307</fpage>&#x02013;<lpage>330</lpage>. <pub-id pub-id-type="doi">10.1080/026999398379628</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Debener</surname><given-names>S.</given-names></name><name><surname>Minow</surname><given-names>F.</given-names></name><name><surname>Emkes</surname><given-names>R.</given-names></name><name><surname>Gandras</surname><given-names>G.</given-names></name><name><surname>de Vos</surname><given-names>M.</given-names></name></person-group> (<year>2012</year>). <article-title>How about taking a low-cost, small, and wireless EEG for a walk?</article-title>
<source>Psychophysiology</source>
<volume>49</volume>, <fpage>1617</fpage>&#x02013;<lpage>1621</lpage>. <pub-id pub-id-type="doi">10.1111/j.1469-8986.2012.01471.x</pub-id><?supplied-pmid 23013047?><pub-id pub-id-type="pmid">23013047</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dias</surname><given-names>A. M.</given-names></name><name><surname>van Deusen</surname><given-names>A.</given-names></name></person-group> (<year>2011</year>). <article-title>A new neurofeedback protocol for depression</article-title>. <source>Span. J. Psychol.</source>
<volume>14</volume>, <fpage>374</fpage>&#x02013;<lpage>384</lpage>. <pub-id pub-id-type="doi">10.5209/rev_SJOP.2011.v14.n1.34</pub-id><?supplied-pmid 21568194?><pub-id pub-id-type="pmid">21568194</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Erkkil&#x000e4;</surname><given-names>J.</given-names></name><name><surname>Punkanen</surname><given-names>M.</given-names></name><name><surname>Fachner</surname><given-names>J.</given-names></name><name><surname>Ala-Ruona</surname><given-names>E.</given-names></name><name><surname>P&#x000f6;nti&#x000f6;</surname><given-names>I.</given-names></name><name><surname>Tervaniemi</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2011</year>). <article-title>Individual music therapy for depression: randomised controlled trial</article-title>. <source>Br. J. Psychiatry</source>
<volume>199</volume>, <fpage>132</fpage>&#x02013;<lpage>139</lpage>. <pub-id pub-id-type="doi">10.1192/bjp.bp.110.085431</pub-id><?supplied-pmid 21474494?><pub-id pub-id-type="pmid">21474494</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fuchs</surname><given-names>T.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Lutzenberger</surname><given-names>W.</given-names></name><name><surname>Gruzelier</surname><given-names>J. H.</given-names></name><name><surname>Kaiser</surname><given-names>J.</given-names></name></person-group> (<year>2003</year>). <article-title>Neurofeedback treatment for attention-deficit/hyperactivity disorder in children: a comparison with methylphenidate</article-title>. <source>Appl. Psychophysiol. Biofeedback</source>
<volume>28</volume>, <fpage>1</fpage>&#x02013;<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1023/A:1022353731579</pub-id><?supplied-pmid 12737092?><pub-id pub-id-type="pmid">12737092</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fukui</surname><given-names>H.</given-names></name><name><surname>Toyoshima</surname><given-names>K.</given-names></name></person-group> (<year>2008</year>). <article-title>Music facilitates the neurogenesis, regeneration and repairof neurons</article-title>. <source>Med. Hypotheses</source>
<volume>71</volume>, <fpage>765</fpage>&#x02013;<lpage>769</lpage>. <pub-id pub-id-type="doi">10.1016/j.mehy.2008.06.019</pub-id><?supplied-pmid 18692321?><pub-id pub-id-type="pmid">18692321</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gani</surname><given-names>C.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Strehl</surname><given-names>U.</given-names></name></person-group> (<year>2008</year>). <article-title>Long term effects after feedback of slow cortical potentials and of theta-beta-amplitudes in children with attention-deficit/hyperactivity disorder (ADHD)</article-title>. <source>Int. J. Bioelectromagn.</source>
<volume>10</volume>, <fpage>209</fpage>&#x02013;<lpage>232</lpage>.</mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gevensleben</surname><given-names>H.</given-names></name><name><surname>Holl</surname><given-names>B.</given-names></name><name><surname>Albrecht</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>Neurofeedback training in children with ADHD: 6-month follow-up of a randomized controlled trial</article-title>. <source>Eur. Child Adolesc. Psychiatry</source>
<volume>19</volume>, <fpage>715</fpage>&#x02013;<lpage>724</lpage>. <pub-id pub-id-type="doi">10.1007/s00787-010-0109-5</pub-id><?supplied-pmid 20499120?><pub-id pub-id-type="pmid">20499120</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="other"><person-group person-group-type="author"><name><surname>Giraldo</surname><given-names>S.</given-names></name></person-group> (<year>2012</year>). <source>Modeling Embellishment, Duration and Energy Expressive Transformations in Jazz Guitar</source>. Masters thesis, Pompeu Fabra University, Barcelona, Spain.</mixed-citation></ref><ref id="B20"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Giraldo</surname><given-names>S.</given-names></name><name><surname>Ramirez</surname><given-names>R.</given-names></name></person-group> (<year>2013</year>). <article-title>Real Time Modeling of Emotions by Linear Regression</article-title>, in <source>International Workshop on Machine Learning and Music, International Conference on Machine Leaning</source> (<publisher-loc>Edinburgh</publisher-loc>).</mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gotlib</surname><given-names>I. H.</given-names></name><name><surname>Ranganath</surname><given-names>C.</given-names></name><name><surname>Rosenfeld</surname><given-names>J. P.</given-names></name></person-group> (<year>1999</year>). <article-title>Frontal EEG alpha asymmetry, depression, and cognitive functioning</article-title>. <source>Cogn. Emot.</source>
<volume>12</volume>, <fpage>449</fpage>&#x02013;<lpage>478</lpage>. <pub-id pub-id-type="doi">10.1080/026999398379673</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Grocke</surname><given-names>D. E.</given-names></name><name><surname>Grocke</surname><given-names>D.</given-names></name><name><surname>Wigram</surname><given-names>T.</given-names></name></person-group> (<year>2007</year>). <source>Receptive Methods in Music Therapy: Techniques and Clinical Applications for Music Therapy Clinicians, Educators and Students</source>. <publisher-loc>London, UK</publisher-loc>: <publisher-name>Jessica Kingsley Publishers</publisher-name>.</mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gruzelier</surname><given-names>J.</given-names></name><name><surname>Egner</surname><given-names>T.</given-names></name></person-group> (<year>2005</year>). <article-title>Critical validation studies of neurofeedback</article-title>. <source>Child Adolesc. Psychiatr. Clin. N. Am.</source>
<volume>14</volume>, <fpage>83</fpage>&#x02013;<lpage>104</lpage>. <pub-id pub-id-type="doi">10.1016/j.chc.2004.07.002</pub-id><?supplied-pmid 15564053?><pub-id pub-id-type="pmid">15564053</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hammond</surname><given-names>D. C.</given-names></name></person-group> (<year>2004</year>). <article-title>Neurofeedback treatment of depression and anxiety</article-title>. <source>J. Adult Dev.</source>
<volume>4</volume>, <fpage>45</fpage>&#x02013;<lpage>56</lpage>. <pub-id pub-id-type="doi">10.1007/s10804-005-7029-5</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hammond</surname><given-names>D. C.</given-names></name></person-group> (<year>2010</year>). <article-title>The need for individualization in neurofeedback: heterogeneity in QEEG patterns associated with diagnoses and symptoms</article-title>. <source>Appl. Psychophysiol. Biofeedback</source>
<volume>35</volume>, <fpage>31</fpage>&#x02013;<lpage>36</lpage>. <pub-id pub-id-type="doi">10.1007/s10484-009-9106-1</pub-id><?supplied-pmid 19760143?><pub-id pub-id-type="pmid">19760143</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hays</surname><given-names>T.</given-names></name><name><surname>Minichiello</surname><given-names>V.</given-names></name></person-group> (<year>2005</year>). <article-title>The meaning of music in the lives of older people: a qualitative study</article-title>. <source>Psychol. Music</source>
<volume>33</volume>, <fpage>437</fpage>&#x02013;<lpage>451</lpage>. <pub-id pub-id-type="doi">10.1177/0305735605056160</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Henriques</surname><given-names>J. B.</given-names></name><name><surname>Davidson</surname><given-names>R. J.</given-names></name></person-group> (<year>1991</year>). <article-title>Left frontal hypoactivation in depression</article-title>. <source>J. Abnorm. Psychol.</source>
<volume>100</volume>, <fpage>534</fpage>&#x02013;<lpage>545</lpage>. <pub-id pub-id-type="doi">10.1037/0021-843X.100.4.535</pub-id><?supplied-pmid 1757667?><pub-id pub-id-type="pmid">1757667</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hsu</surname><given-names>M. H.</given-names></name><name><surname>Flowerdew</surname><given-names>R.</given-names></name><name><surname>Parker</surname><given-names>M.</given-names></name><name><surname>Fachner</surname><given-names>J.</given-names></name><name><surname>Odell-Miller</surname><given-names>H.</given-names></name></person-group> (<year>2015</year>). <article-title>Individual music therapy for managing neuropsychiatric symptoms for people with dementia and their carers: a cluster randomised controlled feasibility study</article-title>. <source>BMC Geriatr.</source>
<volume>15</volume>:<fpage>84</fpage>. <pub-id pub-id-type="doi">10.1186/s12877-015-0082-4</pub-id><?supplied-pmid 26183582?><pub-id pub-id-type="pmid">26183582</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jensen</surname><given-names>M. P.</given-names></name><name><surname>Grierson</surname><given-names>R. N.</given-names></name><name><surname>Tracy-Smith</surname><given-names>V.</given-names></name><name><surname>Bacigalupi</surname><given-names>S. C.</given-names></name><name><surname>Othmer</surname><given-names>S. F.</given-names></name></person-group> (<year>2007</year>). <article-title>Neurofeedback treatment for pain associated with complex regional pain syndrome type I</article-title>. <source>J. Neurother.</source>
<volume>11</volume>, <fpage>45</fpage>&#x02013;<lpage>53</lpage>. <pub-id pub-id-type="doi">10.1300/J184v11n01_04</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kerson</surname><given-names>C.</given-names></name><name><surname>Sherman</surname><given-names>R. A.</given-names></name><name><surname>Kozlowski</surname><given-names>G. P.</given-names></name></person-group> (<year>2009</year>). <article-title>Alpha suppression and symmetry training for generalized anxiety symptoms</article-title>. <source>J. Neurother.</source>
<volume>13</volume>, <fpage>146</fpage>&#x02013;<lpage>155</lpage>. <pub-id pub-id-type="doi">10.1080/10874200903107405</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kotchoubey</surname><given-names>B.</given-names></name><name><surname>Strehl</surname><given-names>U.</given-names></name><name><surname>Uhlmann</surname><given-names>C.</given-names></name><name><surname>Holzapfel</surname><given-names>S.</given-names></name><name><surname>K&#x000f6;nig</surname><given-names>M.</given-names></name><name><surname>Fr&#x000f6;scher</surname><given-names>W.</given-names></name><etal/></person-group>. (<year>2001</year>). <article-title>Modification of slow cortical potentials in patients with refractory epilepsy: a controlled outcome study</article-title>. <source>Epilepsia</source>
<volume>42</volume>, <fpage>406</fpage>&#x02013;<lpage>416</lpage>. <pub-id pub-id-type="doi">10.1046/j.1528-1157.2001.22200.x</pub-id><?supplied-pmid 11442161?><pub-id pub-id-type="pmid">11442161</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kropotov</surname><given-names>J. D.</given-names></name></person-group> (<year>2009</year>). <source>Quantitative EEG, Event-related Potentials and Neurotherapy.</source>
<publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Elsevier</publisher-name>
<publisher-name>Academic Press</publisher-name>.</mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kumano</surname><given-names>H.</given-names></name><name><surname>Horie</surname><given-names>H.</given-names></name><name><surname>Shidara</surname><given-names>T.</given-names></name><name><surname>Kuboki</surname><given-names>T.</given-names></name><name><surname>Suematsu</surname><given-names>H.</given-names></name><name><surname>Yasushi</surname><given-names>M.</given-names></name></person-group> (<year>1996</year>). <article-title>Treatment of a depressive disorder patient with EEG-driven photic stimulation</article-title>. <source>Biofeedback Self Regul.</source>
<volume>21</volume>, <fpage>323</fpage>&#x02013;<lpage>334</lpage>. <pub-id pub-id-type="doi">10.1007/BF02214432</pub-id><?supplied-pmid 9031711?><pub-id pub-id-type="pmid">9031711</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lundqvist</surname><given-names>L.-O.</given-names></name><name><surname>Carlsson</surname><given-names>F.</given-names></name><name><surname>Hilmersson</surname><given-names>P.</given-names></name><name><surname>Juslin</surname><given-names>P. N.</given-names></name></person-group> (<year>2009</year>). <article-title>Emotional responses to music: experience, expression, and physiology</article-title>. <source>Psychol. Music</source>
<volume>37</volume>, <fpage>61</fpage>&#x02013;<lpage>90</lpage>. <pub-id pub-id-type="doi">10.1177/0305735607086048</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>MacDonald</surname><given-names>R. A.</given-names></name></person-group> (<year>2013</year>). <article-title>Music, health, and well-being: a review</article-title>. <source>Int. J. Qual. Stud. Health Well-being</source>
<volume>8</volume>:<fpage>20635</fpage>. <pub-id pub-id-type="doi">10.3402/qhw.v8i0.20635</pub-id><?supplied-pmid 23930991?><pub-id pub-id-type="pmid">23930991</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maratos</surname><given-names>A. S.</given-names></name><name><surname>Gold</surname><given-names>C.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Crawford</surname><given-names>M. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Music therapy for depression</article-title>. <source>Cochrane Database Syst. Rev.</source>
<volume>1</volume>:<fpage>CD004517</fpage>. <pub-id pub-id-type="doi">10.1002/14651858.CD004517.pub2</pub-id><?supplied-pmid 18254052?><pub-id pub-id-type="pmid">18254052</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marchini</surname><given-names>M.</given-names></name><name><surname>Ramirez</surname><given-names>R.</given-names></name><name><surname>Maestre</surname><given-names>M.</given-names></name><name><surname>Papiotis</surname><given-names>P.</given-names></name></person-group> (<year>2014</year>). <article-title>The sense of ensemble: a machine learning approach to expressive performance modelling in string quartets</article-title>. <source>J. New Music Res.</source>
<volume>43</volume>, <fpage>303</fpage>&#x02013;<lpage>317</lpage>. <pub-id pub-id-type="doi">10.1080/09298215.2014.922999</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mayor</surname><given-names>O.</given-names></name><name><surname>Bonada</surname><given-names>J.</given-names></name><name><surname>Janer</surname><given-names>J.</given-names></name></person-group> (<year>2011</year>). <article-title>Audio transformation technologies applied to video games</article-title> in <source>Audio Engineering Society Conference: 41st International Conference: Audio for Games</source> (<publisher-loc>London, UK</publisher-loc>).</mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McCaffrey</surname><given-names>R.</given-names></name></person-group> (<year>2008</year>). <article-title>Music listening: its effects in creating a healing environment</article-title>. <source>J. Psychosoc. Nurs.</source>
<volume>46</volume>, <fpage>39</fpage>&#x02013;<lpage>45</lpage>. <pub-id pub-id-type="doi">10.3928/02793695-20081001-08</pub-id><?supplied-pmid 18935935?><pub-id pub-id-type="pmid">18935935</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Michael</surname><given-names>A. J.</given-names></name><name><surname>Krishnaswamy</surname><given-names>S.</given-names></name><name><surname>Mohamed</surname><given-names>J.</given-names></name></person-group> (<year>2005</year>). <article-title>An open label study of the use of EEG biofeedback using beta training to reduce anxiety for patients with cardiac events</article-title>. <source>Neuropsychiatr. Dis. Treat</source>. <volume>1</volume>:<fpage>357</fpage>. <?supplied-pmid 18568116?><pub-id pub-id-type="pmid">18568116</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Mitchell</surname><given-names>T. M.</given-names></name></person-group> (<year>1997</year>). <source>Machine Learning</source>. <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>McGraw-Hill</publisher-name>.</mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Monastra</surname><given-names>V. J.</given-names></name><name><surname>Monsatra</surname><given-names>D. M.</given-names></name><name><surname>George</surname><given-names>S.</given-names></name></person-group> (<year>2002</year>). <article-title>The effects of stimulant therapy, EEG biofeedback and parenting style on the primary symptoms of attention deficit/hyperactivity disorder</article-title>. <source>Appl. Psychophysiol. Biofeedback</source>
<volume>27</volume>, <fpage>231</fpage>&#x02013;<lpage>246</lpage>
<pub-id pub-id-type="doi">10.1023/A:1021018700609</pub-id><?supplied-pmid 12557451?><pub-id pub-id-type="pmid">12557451</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moriyama</surname><given-names>T. S.</given-names></name><name><surname>Polanczyk</surname><given-names>G.</given-names></name><name><surname>Caye</surname><given-names>A.</given-names></name><name><surname>Banaschewski</surname><given-names>T.</given-names></name><name><surname>Brandeis</surname><given-names>D.</given-names></name><name><surname>Rohde</surname><given-names>L. A.</given-names></name></person-group> (<year>2012</year>). <article-title>Evidence-based information on the clinical use of neurofeedback for ADHD</article-title>. <source>Neurotherapeutics</source>
<volume>9</volume>, <fpage>588</fpage>&#x02013;<lpage>598</lpage>
<pub-id pub-id-type="doi">10.1007/s13311-012-0136-7</pub-id><?supplied-pmid 22930416?><pub-id pub-id-type="pmid">22930416</pub-id></mixed-citation></ref><ref id="B44"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Narmour</surname><given-names>E.</given-names></name></person-group> (<year>1991</year>). <source>The Analysis and Cognition of Melodic Complexity: The Implication Realization Model</source>. <publisher-loc>Chicago, IL</publisher-loc>: <publisher-name>University of Chicago Press</publisher-name>.</mixed-citation></ref><ref id="B45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peniston</surname><given-names>E. G.</given-names></name><name><surname>Kulkosky</surname><given-names>P. J.</given-names></name></person-group> (<year>1990</year>). <article-title>Alcoholic personality and alpha-theta brainwave training</article-title>. <source>Med. Psychother.</source>
<volume>3</volume>, <fpage>37</fpage>&#x02013;<lpage>55</lpage>.</mixed-citation></ref><ref id="B46"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Puckette</surname><given-names>M.</given-names></name></person-group> (<year>1996</year>). <article-title>Pure Data: another integrated computer music environment</article-title> in <source>Proceedings of the Second Intercollege Computer Music Concerts</source> (<publisher-loc>Tachikawa</publisher-loc>), <fpage>37</fpage>&#x02013;<lpage>41</lpage>.</mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramirez</surname><given-names>R.</given-names></name><name><surname>Maestre</surname><given-names>E.</given-names></name><name><surname>Serra</surname><given-names>X.</given-names></name></person-group> (<year>2010</year>). <article-title>Automatic performer identification in commercial monophonic Jazz performances</article-title>. <source>Pattern Recognit. Lett.</source>
<volume>31</volume>, <fpage>1514</fpage>&#x02013;<lpage>1523</lpage>. <pub-id pub-id-type="doi">10.1016/j.patrec.2009.12.032</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ramirez</surname><given-names>R.</given-names></name><name><surname>Maestre</surname><given-names>E.</given-names></name><name><surname>Serra</surname><given-names>X.</given-names></name></person-group> (<year>2012</year>). <article-title>A rule-based evolutionary approach to music performance modeling</article-title>. <source>IEEE Trans. Evol. Comput.</source>
<volume>16</volume>, <fpage>96</fpage>&#x02013;<lpage>107</lpage>. <pub-id pub-id-type="doi">10.1109/TEVC.2010.2077299</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ramirez</surname><given-names>R.</given-names></name><name><surname>Vamvakousis</surname><given-names>Z.</given-names></name></person-group> (<year>2012</year>). <article-title>Detecting emotion from EEG signals using the emotive epoc device</article-title> in <source>Proceedings of the 2012 International Conference on Brain Informatics, LNCS 7670</source> (<publisher-loc>Macau</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>175</fpage>&#x02013;<lpage>184</lpage>.</mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Renard</surname><given-names>Y.</given-names></name><name><surname>Lotte</surname><given-names>F.</given-names></name><name><surname>Gibert</surname><given-names>G.</given-names></name><name><surname>Congedo</surname><given-names>M.</given-names></name><name><surname>Maby</surname><given-names>E.</given-names></name><name><surname>Delannoy</surname><given-names>V.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>An open-source software platform to design, test, and use brain-computer interfaces in real and virtual environments</article-title>. <source>MIT Press J. Presence</source>
<volume>19</volume>, <fpage>35</fpage>&#x02013;<lpage>53</lpage>. <pub-id pub-id-type="doi">10.1162/pres.19.1.35</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rosenfeld</surname><given-names>J. P.</given-names></name></person-group> (<year>2000</year>). <article-title>An EEG biofeedback protocol for affective disorders</article-title>. <source>Clin. Electroencephalogr.</source>
<volume>31</volume>, <fpage>7</fpage>&#x02013;<lpage>12</lpage>. <pub-id pub-id-type="doi">10.1177/155005940003100106</pub-id><?supplied-pmid 10638347?><pub-id pub-id-type="pmid">10638347</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rossiter</surname><given-names>T. R.</given-names></name><name><surname>La Vaque</surname><given-names>T. J.</given-names></name></person-group> (<year>1995</year>). <article-title>A comparison of EEG biofeedback and psychostimulants in treating attention deficit/hyperactivity disorders</article-title>. <source>J. Neurother.</source>
<volume>1</volume>, <fpage>48</fpage>&#x02013;<lpage>59</lpage>. <pub-id pub-id-type="doi">10.1300/J184v01n01_07</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ruud</surname><given-names>E.</given-names></name></person-group> (<year>1997</year>). <article-title>Music and the quality of life</article-title>. <source>Nord. J. Music Ther.</source>
<volume>6</volume>, <fpage>86</fpage>&#x02013;<lpage>97</lpage>. <pub-id pub-id-type="doi">10.1080/08098139709477902</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>S&#x000e4;rk&#x000e4;m&#x000f6;</surname><given-names>T.</given-names></name><name><surname>Laitinen</surname><given-names>S.</given-names></name><name><surname>Tervaniemi</surname><given-names>M.</given-names></name><name><surname>Numminen</surname><given-names>A.</given-names></name><name><surname>Kurki</surname><given-names>M.</given-names></name><name><surname>Rantanen</surname><given-names>P.</given-names></name></person-group> (<year>2012</year>). <article-title>Music, emotion, and dementia insight from neuroscientific and clinical research</article-title>. <source>Music Med.</source>
<volume>4</volume>, <fpage>153</fpage>&#x02013;<lpage>162</lpage>. <pub-id pub-id-type="doi">10.1177/1943862112445323</pub-id></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>S&#x000e4;rk&#x000e4;m&#x000f6;</surname><given-names>T.</given-names></name><name><surname>Tervaniemi</surname><given-names>M.</given-names></name><name><surname>Laitinen</surname><given-names>S.</given-names></name><name><surname>Forsblom</surname><given-names>A.</given-names></name><name><surname>Soinila</surname><given-names>S.</given-names></name><name><surname>Mikkonen</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2008</year>). <article-title>Music listening enhances cognitive recovery and mood after middle cerebral artery stroke</article-title>. <source>Brain</source>
<volume>131</volume>, <fpage>866</fpage>&#x02013;<lpage>876</lpage>. <pub-id pub-id-type="doi">10.1093/brain/awn013</pub-id><?supplied-pmid 18287122?><pub-id pub-id-type="pmid">18287122</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>S&#x000e4;rk&#x000e4;m&#x000f6;</surname><given-names>T.</given-names></name><name><surname>Tervaniemi</surname><given-names>M.</given-names></name><name><surname>Laitinen</surname><given-names>S.</given-names></name><name><surname>Numminen</surname><given-names>A.</given-names></name><name><surname>Kurki</surname><given-names>M.</given-names></name><name><surname>Johnson</surname><given-names>J. K.</given-names></name><etal/></person-group>. (<year>2014</year>). <article-title>Cognitive, emotional, and social benefits of regular musical activities in early dementia: randomized controlled study</article-title>. <source>Gerontologist</source>
<volume>54</volume>, <fpage>634</fpage>&#x02013;<lpage>650</lpage>. <pub-id pub-id-type="doi">10.1093/geront/gnt100</pub-id><?supplied-pmid 24009169?><pub-id pub-id-type="pmid">24009169</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>S&#x000e4;rk&#x000e4;m&#x000f6;</surname><given-names>T.</given-names></name><name><surname>Tervaniemi</surname><given-names>M.</given-names></name><name><surname>Soinila</surname><given-names>S.</given-names></name><name><surname>Autti</surname><given-names>T.</given-names></name><name><surname>Silvennoinen</surname><given-names>H. M.</given-names></name><name><surname>Laine</surname><given-names>M.</given-names></name><etal/></person-group>. (<year>2010</year>). <article-title>Auditory and cognitive deficits associated with acquired amusia after stroke: a magnetoencephalography and neuropsychological follow-up study</article-title>. <source>PLoS ONE</source>
<volume>5</volume>:<fpage>e15157</fpage>. <pub-id pub-id-type="doi">10.1371/journal.pone.0015157</pub-id><?supplied-pmid 21152040?><pub-id pub-id-type="pmid">21152040</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sol&#x000e9;</surname><given-names>C.</given-names></name><name><surname>Mercadal</surname><given-names>M.</given-names></name><name><surname>Gallego</surname><given-names>S.</given-names></name><name><surname>Riera</surname><given-names>M. A.</given-names></name></person-group> (<year>2010</year>). <article-title>Quality of life of older people: contributions of music</article-title>. <source>J. Music Ther.</source>
<volume>42</volume>, <fpage>264</fpage>&#x02013;<lpage>261</lpage>. <pub-id pub-id-type="doi">10.1093/jmt/47.3.264</pub-id><pub-id pub-id-type="pmid">21275335</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sterman</surname><given-names>M. B.</given-names></name></person-group> (<year>2000</year>). <article-title>Basic concepts and clinical findings in the treatment of seizure disorders with EEG operant conditioning</article-title>. <source>Clin. Electroencephalogr.</source>
<volume>31</volume>, <fpage>45</fpage>&#x02013;<lpage>55</lpage>. <pub-id pub-id-type="doi">10.1177/155005940003100111</pub-id><?supplied-pmid 10638352?><pub-id pub-id-type="pmid">10638352</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Swingle</surname><given-names>P. G.</given-names></name></person-group> (<year>1998</year>). <article-title>Neurofeedback treatment of pseudoseizure disorder</article-title>. <source>Biol. Psychiatry</source>
<volume>44</volume>, <fpage>1196</fpage>&#x02013;<lpage>1199</lpage>. <pub-id pub-id-type="doi">10.1016/S0006-3223(97)00541-6</pub-id><?supplied-pmid 9836025?><pub-id pub-id-type="pmid">9836025</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thie</surname><given-names>J.</given-names></name><name><surname>Klistorner</surname><given-names>A.</given-names></name><name><surname>Graham</surname><given-names>S. L.</given-names></name></person-group> (<year>2012</year>). <article-title>Biomedical signal acquisition with streaming wireless communication for recording evoked potentials</article-title>. <source>Doc. Ophthalmol.</source>
<volume>125</volume>, <fpage>149</fpage>&#x02013;<lpage>159</lpage>. <pub-id pub-id-type="doi">10.1007/s10633-012-9345-y</pub-id><?supplied-pmid 22843193?><pub-id pub-id-type="pmid">22843193</pub-id></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanathy</surname><given-names>S.</given-names></name><name><surname>Sharma</surname><given-names>P. S. V. N.</given-names></name><name><surname>Kumar</surname><given-names>K. B.</given-names></name></person-group> (<year>1998</year>). <article-title>The efficacy of alpha and theta neurofeedback training in treatment of generalized anxiety disorder</article-title>. <source>Indian J. Clin. Psychol.</source>
<volume>25</volume>, <fpage>136</fpage>&#x02013;<lpage>143</lpage>.</mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vanderak</surname><given-names>S.</given-names></name><name><surname>Newman</surname><given-names>I.</given-names></name><name><surname>Bell</surname><given-names>S.</given-names></name></person-group> (<year>1983</year>). <article-title>The effects of music participation on quality of life of the elderly</article-title>. <source>Music Ther.</source>
<volume>3</volume>, <fpage>71</fpage>&#x02013;<lpage>81</lpage>. <pub-id pub-id-type="doi">10.1093/mt/3.1.71</pub-id></mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker</surname><given-names>J. E.</given-names></name></person-group> (<year>2011</year>). <article-title>QEEG-guided neurofeedback for recurrent migraine headaches</article-title>. <source>Clin. EEG Neurosci.</source>
<volume>42</volume>, <fpage>59</fpage>&#x02013;<lpage>61</lpage>. <pub-id pub-id-type="doi">10.1177/155005941104200112</pub-id><?supplied-pmid 21309444?><pub-id pub-id-type="pmid">21309444</pub-id></mixed-citation></ref><ref id="B65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ziv</surname><given-names>N.</given-names></name><name><surname>Granot</surname><given-names>A.</given-names></name><name><surname>Hai</surname><given-names>S.</given-names></name><name><surname>Dassa</surname><given-names>A.</given-names></name><name><surname>Haimov</surname><given-names>I.</given-names></name></person-group> (<year>2007</year>). <article-title>The effect of backgroundstimulative music in behavior of Alzheimer's patients</article-title>. <source>J. Music Ther.</source>
<volume>44</volume>, <fpage>329</fpage>&#x02013;<lpage>343</lpage>. <pub-id pub-id-type="doi">10.1093/jmt/44.4.329</pub-id><?supplied-pmid 17997624?><pub-id pub-id-type="pmid">17997624</pub-id></mixed-citation></ref></ref-list></back></article>